{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c9f7a1f4",
   "metadata": {},
   "source": [
    "## Installing Libraries Needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1412325e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: pandas in c:\\users\\juanp\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (2.3.3)\n",
      "Requirement already satisfied: numpy>=1.26.0 in c:\\users\\juanp\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas) (2.3.5)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\juanp\\appdata\\roaming\\python\\python314\\site-packages (from pandas) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\juanp\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\juanp\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\juanp\\appdata\\roaming\\python\\python314\\site-packages (from python-dateutil>=2.8.2->pandas) (1.17.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1826ca83",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: openpyxl in c:\\users\\juanp\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (3.1.5)\n",
      "Requirement already satisfied: et-xmlfile in c:\\users\\juanp\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from openpyxl) (2.0.0)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "[notice] A new release of pip is available: 25.2 -> 25.3\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "!python -m pip install openpyxl\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "77e0cc41",
   "metadata": {},
   "source": [
    "## Dataset Inventory Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce43a75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected year folders: ['2018', '2019', '2022', '2023', '2024']\n",
      "\n",
      "=== DATASET INVENTORY SUMMARY ===\n",
      "\n",
      "Year 2018:\n",
      "  January:\n",
      "    JANUARY_2018_METADATA.xlsx (metadata)\n",
      "    JANUARY_2018.CSV (survey)\n",
      "  April:\n",
      "    APRIL_2018.CSV (survey)\n",
      "    APRIL_2018_METADATA.xlsx (metadata)\n",
      "  July:\n",
      "    JULY_2018.CSV (survey)\n",
      "    JULY_2018_METADATA.xlsx (metadata)\n",
      "  October:\n",
      "    OCTOBER_2018.CSV (survey)\n",
      "    OCTOBER_2018_METADATA.xlsx (metadata)\n",
      "\n",
      "Year 2019:\n",
      "  January:\n",
      "    JANUARY_2019.CSV (survey)\n",
      "    JANUARY_2019_METADATA.xlsx (metadata)\n",
      "  April:\n",
      "    APRIL_2019.CSV (survey)\n",
      "    APRIL_2019_METADATA.xlsx (metadata)\n",
      "  July:\n",
      "    JULY_2019.CSV (survey)\n",
      "    JULY_2019_METADATA.xlsx (metadata)\n",
      "  October:\n",
      "    OCTOBER_2019.CSV (survey)\n",
      "    OCTOBER_2019_METADATA.xlsx (metadata)\n",
      "\n",
      "Year 2022:\n",
      "  January:\n",
      "    JANUARY_2022.csv (survey)\n",
      "    JANUARY_2022_METADATA.xlsx (metadata)\n",
      "  February:\n",
      "    FEBRUARY_2022.csv (survey)\n",
      "    FEBRUARY_2022_METADATA.xlsx (metadata)\n",
      "  March:\n",
      "    MARCH_2022.csv (survey)\n",
      "    MARCH_2022_METADATA.xlsx (metadata)\n",
      "  April:\n",
      "    APRIL_2022.csv (survey)\n",
      "    APRIL_2022_METADATA.xlsx (metadata)\n",
      "  May:\n",
      "    MAY_2022.csv (survey)\n",
      "    MAY_2022_METADATA.xlsx (metadata)\n",
      "  June:\n",
      "    JUNE_2022.csv (survey)\n",
      "    JUNE_2022_METADATA.xlsx (metadata)\n",
      "  July:\n",
      "    JULY_2022.CSV (survey)\n",
      "    JULY_2022_METADATA.xlsx (metadata)\n",
      "  August:\n",
      "    AUGUST_2022.CSV (survey)\n",
      "    AUGUST_2022_METADATA.xlsx (metadata)\n",
      "  September:\n",
      "    SEPTEMBER_2022.CSV (survey)\n",
      "    SEPTEMBER_2022_METADATA.xlsx (metadata)\n",
      "  October:\n",
      "    OCTOBER_2022.CSV (survey)\n",
      "    OCTOBER_2022_METADATA.xlsx (metadata)\n",
      "  November:\n",
      "    NOVEMBER_2022.CSV (survey)\n",
      "    NOVEMBER_2022_METADATA.xlsx (metadata)\n",
      "  December:\n",
      "    DECEMBER_2022.CSV (survey)\n",
      "    DECEMBER_2022_METADATA.xlsx (metadata)\n",
      "\n",
      "Year 2023:\n",
      "  January:\n",
      "    JANUARY_2023.CSV (survey)\n",
      "    JANUARY_2023_METADATA.xlsx (metadata)\n",
      "  February:\n",
      "    FEBRUARY_2023.CSV (survey)\n",
      "    FEBRUARY_2023_METADATA.xlsx (metadata)\n",
      "  March:\n",
      "    MARCH_2023.CSV (survey)\n",
      "    MARCH_2023_METADATA.xlsx (metadata)\n",
      "  April:\n",
      "    APRIL_2023.CSV (survey)\n",
      "    APRIL_2023_METADATA.xlsx (metadata)\n",
      "  May:\n",
      "    MAY_2023.CSV (survey)\n",
      "    MAY_2023_METADATA.xlsx (metadata)\n",
      "  June:\n",
      "    JUNE_2023.CSV (survey)\n",
      "    JUNE_2023_METADATA.xlsx (metadata)\n",
      "  July:\n",
      "    JULY_2023.CSV (survey)\n",
      "    JULY_2023_METADATA.xlsx (metadata)\n",
      "  August:\n",
      "    AUGUST_2023.CSV (survey)\n",
      "    AUGUST_2023_METADATA.xlsx (metadata)\n",
      "  September:\n",
      "    SEPTEMBER_2023.CSV (survey)\n",
      "    SEPTEMBER_2023_METADATA.xlsx (metadata)\n",
      "  October:\n",
      "    OCTOBER_2023.CSV (survey)\n",
      "    OCTOBER_2023_METADATA.xlsx (metadata)\n",
      "  November:\n",
      "    NOVEMBER_2023.CSV (survey)\n",
      "    NOVEMBER_2023_METADATA.xlsx (metadata)\n",
      "  December:\n",
      "    DECEMBER_2023.CSV (survey)\n",
      "    DECEMBER_2023_METADATA.xlsx (metadata)\n",
      "\n",
      "Year 2024:\n",
      "  January:\n",
      "    JANUARY_2024.CSV (survey)\n",
      "    JANUARY_2024_METADATA.xlsx (metadata)\n",
      "  February:\n",
      "    FEBRUARY_2024.CSV (survey)\n",
      "    FEBRUARY_2024_METADATA.xlsx (metadata)\n",
      "  March:\n",
      "    MARCH_2024.CSV (survey)\n",
      "    MARCH_2024_METADATA.xlsx (metadata)\n",
      "  April:\n",
      "    APRIL_2024.CSV (survey)\n",
      "    APRIL_2024_METADATA.xlsx (metadata)\n",
      "  May:\n",
      "    MAY_2024.CSV (survey)\n",
      "    MAY_2024_METADATA.xlsx (metadata)\n",
      "  June:\n",
      "    JUNE_2024.CSV (survey)\n",
      "    JUNE_2024_METADATA.xlsx (metadata)\n",
      "  July:\n",
      "    JULY_2024.CSV (survey)\n",
      "    JULY_2024_METADATA.xlsx (metadata)\n",
      "  August:\n",
      "    AUGUST_2024.CSV (survey)\n",
      "    AUGUST_2024_METADATA.xlsx (metadata)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "base_path = r\"G:\\My Drive\\Labor Force Survey\"\n",
    "\n",
    "# Month ordering\n",
    "month_order = {\n",
    "    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4,\n",
    "    \"May\": 5, \"June\": 6, \"July\": 7, \"August\": 8,\n",
    "    \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n",
    "}\n",
    "\n",
    "# Patterns\n",
    "month_pattern = re.compile(\n",
    "    r\"(JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "year_pattern = re.compile(r\"(20\\d{2})\")\n",
    "\n",
    "# Detect year folders from drive\n",
    "year_folders = [\n",
    "    f for f in os.listdir(base_path)\n",
    "    if os.path.isdir(os.path.join(base_path, f)) and f.isdigit()\n",
    "]\n",
    "\n",
    "print(\"Detected year folders:\", sorted(year_folders))\n",
    "\n",
    "inventory = {}\n",
    "\n",
    "for year in sorted(year_folders):\n",
    "    year_path = os.path.join(base_path, year)\n",
    "\n",
    "    # Accept both CSV and XLSX\n",
    "    data_files = [\n",
    "        f for f in os.listdir(year_path)\n",
    "        if f.lower().endswith(\".csv\") or f.lower().endswith(\".xlsx\")\n",
    "    ]\n",
    "\n",
    "    inventory[year] = {}\n",
    "\n",
    "    for file in data_files:\n",
    "        upper = file.upper()\n",
    "\n",
    "        # Detect type\n",
    "        if upper.endswith(\".XLSX\"):\n",
    "            filetype = \"metadata\"  # XLSX = metadata\n",
    "        else:\n",
    "            filetype = \"survey\"    # CSV = survey\n",
    "\n",
    "        # Detect month\n",
    "        month_match = month_pattern.search(upper)\n",
    "        month = (\n",
    "            month_match.group(1).capitalize()\n",
    "            if month_match\n",
    "            else \"Unmatched\"\n",
    "        )\n",
    "\n",
    "        # Detect year inside filename\n",
    "        year_match = year_pattern.search(upper)\n",
    "        file_year = year_match.group(1) if year_match else \"UNKNOWN\"\n",
    "\n",
    "        # Store into inventory\n",
    "        if month not in inventory[year]:\n",
    "            inventory[year][month] = []\n",
    "\n",
    "        inventory[year][month].append({\n",
    "            \"filename\": file,\n",
    "            \"filetype\": filetype,\n",
    "            \"file_year\": file_year\n",
    "        })\n",
    "\n",
    "# Print clean summary\n",
    "print(\"\\n=== DATASET INVENTORY SUMMARY ===\\n\")\n",
    "\n",
    "for yr in sorted(inventory.keys()):\n",
    "    print(f\"Year {yr}:\")\n",
    "\n",
    "    sorted_months = sorted(\n",
    "        inventory[yr].keys(),\n",
    "        key=lambda m: month_order.get(m, 99)\n",
    "    )\n",
    "\n",
    "    for month in sorted_months:\n",
    "        print(f\"  {month}:\")\n",
    "        for item in inventory[yr][month]:\n",
    "            print(f\"    {item['filename']} ({item['filetype']})\")\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98339b",
   "metadata": {},
   "source": [
    "## Load Dataset Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "4f63c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(year, month, filetype=\"survey\", sheet_number=None):\n",
    "    \"\"\"\n",
    "    Load a dataset from the inventory.\n",
    "\n",
    "    year: str, e.g., \"2018\"\n",
    "    month: str, e.g., \"January\"\n",
    "    filetype: \"survey\" or \"metadata\"\n",
    "    sheet_number: 0(sheet 1) or 1(sheet 2)\n",
    "    \"\"\"\n",
    "    file_info = next(\n",
    "        (f for f in inventory[year][month] if f[\"filetype\"] == filetype),\n",
    "        None\n",
    "    )\n",
    "    if not file_info:\n",
    "        raise ValueError(f\"No {filetype} file found for {month} {year}\")\n",
    "\n",
    "    file_path = os.path.join(base_path, year, file_info[\"filename\"])\n",
    "    \n",
    "    if filetype == \"survey\":\n",
    "        return pd.read_csv(file_path, low_memory=False)\n",
    "    \n",
    "    if sheet_number is not None:\n",
    "        return pd.read_excel(file_path, sheet_name=sheet_number)\n",
    "    \n",
    "    return pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ebb318",
   "metadata": {},
   "source": [
    "Sample: January 2018 Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "04853487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUFREG</th>\n",
       "      <th>PUFPRV</th>\n",
       "      <th>PUFPRRCD</th>\n",
       "      <th>PUFHHNUM</th>\n",
       "      <th>PUFURB2K10</th>\n",
       "      <th>PUFPWGTPRV</th>\n",
       "      <th>PUFSVYMO</th>\n",
       "      <th>PUFSVYYR</th>\n",
       "      <th>PUFPSU</th>\n",
       "      <th>PUFRPL</th>\n",
       "      <th>...</th>\n",
       "      <th>PUFC33_WEEKS</th>\n",
       "      <th>PUFC34_WYNOT</th>\n",
       "      <th>PUFC35_LTLOOKW</th>\n",
       "      <th>PUFC36_AVAIL</th>\n",
       "      <th>PUFC37_WILLING</th>\n",
       "      <th>PUFC38_PREVJOB</th>\n",
       "      <th>PUFC40_POCC</th>\n",
       "      <th>PUFC41_WQTR</th>\n",
       "      <th>PUFC43_QKB</th>\n",
       "      <th>PUFNEWEMPSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>124.9425</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>131.2126</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>142.0464</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138.2958</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>195.4152</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PUFREG  PUFPRV  PUFPRRCD  PUFHHNUM  PUFURB2K10  PUFPWGTPRV  PUFSVYMO  \\\n",
       "0      14       1       100         1           2    124.9425         1   \n",
       "1      14       1       100         1           2    131.2126         1   \n",
       "2      14       1       100         1           2    142.0464         1   \n",
       "3      14       1       100         1           2    138.2958         1   \n",
       "4      14       1       100         2           2    195.4152         1   \n",
       "\n",
       "   PUFSVYYR  PUFPSU  PUFRPL  ...  PUFC33_WEEKS  PUFC34_WYNOT  PUFC35_LTLOOKW  \\\n",
       "0      2018     140      32  ...                           6                   \n",
       "1      2018     140      32  ...                                               \n",
       "2      2018     140      32  ...                                               \n",
       "3      2018     140      32  ...                                               \n",
       "4      2018     140      32  ...                                               \n",
       "\n",
       "   PUFC36_AVAIL  PUFC37_WILLING PUFC38_PREVJOB PUFC40_POCC PUFC41_WQTR  \\\n",
       "0                                            1          52           2   \n",
       "1                                                                    1   \n",
       "2                                                                    1   \n",
       "3                                                                        \n",
       "4                                                                    1   \n",
       "\n",
       "  PUFC43_QKB PUFNEWEMPSTAT  \n",
       "0                        3  \n",
       "1         01             1  \n",
       "2         01             1  \n",
       "3                           \n",
       "4         41             1  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the survey sheet of January 2018 metadata\n",
    "jan_2018_survey = load_dataset(\"2018\", \"January\",\"survey\")\n",
    "\n",
    "# View the first few rows\n",
    "jan_2018_survey.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f7b8a",
   "metadata": {},
   "source": [
    "## Metadata Sheet 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937d5752",
   "metadata": {},
   "source": [
    "<H5> Sample: January 2018 Metadata Sheet 1 (Raw) </H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "498a73c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== January 2018 Metadata Sheet 1 (Raw) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUEST</th>\n",
       "      <th>Questionnaire</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_IDS0</td>\n",
       "      <td>(Id Items)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUFREG</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUFPRV</td>\n",
       "      <td>Province</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUFPRRCD</td>\n",
       "      <td>Province Recode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUFHHNUM</td>\n",
       "      <td>Household Unique Sequential Number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QUEST  Questionnaire Unnamed: 2  Unnamed: 3 Unnamed: 4  \\\n",
       "0    NaN            NaN      _IDS0  (Id Items)        NaN   \n",
       "1    NaN            NaN        NaN         NaN     PUFREG   \n",
       "2    NaN            NaN        NaN         NaN     PUFPRV   \n",
       "3    NaN            NaN        NaN         NaN   PUFPRRCD   \n",
       "4    NaN            NaN        NaN         NaN   PUFHHNUM   \n",
       "\n",
       "                           Unnamed: 5  \n",
       "0                                 NaN  \n",
       "1                              Region  \n",
       "2                            Province  \n",
       "3                     Province Recode  \n",
       "4  Household Unique Sequential Number  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the first sheet of January 2018 metadata\n",
    "january_2018_metadata_sheet1 = load_dataset(\"2018\", \"January\", \"metadata\", 0)\n",
    "\n",
    "# View the first few rows\n",
    "print(\"=== January 2018 Metadata Sheet 1 (Raw) ===\")\n",
    "january_2018_metadata_sheet1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b67ba5",
   "metadata": {},
   "source": [
    "#### Reshaping Metadata Sheet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "39c15d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_variables(df):\n",
    "    \"\"\"\n",
    "    Extract variable names and descriptions from metadata Sheet 1 (variable dictionary).\n",
    "    Automatically reads the 4th and 5th columns (E and F in Excel) where variables and descriptions reside.\n",
    "    \n",
    "    Returns a clean DataFrame with columns ['Variable', 'Description'].\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select the 4th and 5th columns (index 4 and 5)\n",
    "    df_vars = df.iloc[:, 4:6].copy()\n",
    "    \n",
    "    # Rename columns\n",
    "    df_vars.columns = ['Variable', 'Description']\n",
    "    \n",
    "    # Drop rows where 'Variable' is empty or NaN\n",
    "    df_vars = df_vars[df_vars['Variable'].notna() & (df_vars['Variable'].astype(str).str.strip() != '')]\n",
    "    \n",
    "    # Strip whitespace from values\n",
    "    df_vars['Variable'] = df_vars['Variable'].astype(str).str.strip()\n",
    "    df_vars['Description'] = df_vars['Description'].astype(str).str.strip()\n",
    "    \n",
    "    # Reset index\n",
    "    df_vars = df_vars.reset_index(drop=True)\n",
    "    \n",
    "    return df_vars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c6c97a",
   "metadata": {},
   "source": [
    "### Metadata Sheet 1 Reshaped Saving Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "92803ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def batch_process_sheet1_metadata(inventory, base_output_path):\n",
    "    \"\"\"\n",
    "    Loops through the entire inventory, loads Sheet 1 of the metadata,\n",
    "    reshapes it, and saves it into a structured folder hierarchy.\n",
    "    \n",
    "    Provides a text-based summary report for assurance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Counters for the summary report\n",
    "    success_count = 0\n",
    "    failure_count = 0\n",
    "    skipped_count = 0\n",
    "    errors_log = []\n",
    "\n",
    "    # 1. Define and Create the Main Parent Folder\n",
    "    main_folder_name = \"Metadata Sheet 1 CSV's\"\n",
    "    main_folder_path = os.path.join(base_output_path, main_folder_name)\n",
    "    os.makedirs(main_folder_path, exist_ok=True)\n",
    "    \n",
    "    print(\"--- STARTING BATCH PROCESS ---\")\n",
    "    print(f\"Target Directory: {main_folder_path}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 2. Iterate through Years in the Inventory\n",
    "    for year, months_data in inventory.items():\n",
    "        \n",
    "        # Create the Year Subfolder\n",
    "        year_folder_path = os.path.join(main_folder_path, year)\n",
    "        os.makedirs(year_folder_path, exist_ok=True)\n",
    "        \n",
    "        # 3. Iterate through Months in that Year\n",
    "        for month, files_list in months_data.items():\n",
    "            \n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "            \n",
    "            # Check for metadata file existence\n",
    "            has_metadata = any(f.get('filetype') == 'metadata' for f in files_list)\n",
    "            \n",
    "            if has_metadata:\n",
    "                try:\n",
    "                    # A. Load the Data (Sheet 0 = Sheet 1)\n",
    "                    raw_df = load_dataset(year, month, \"metadata\", 0)\n",
    "                    \n",
    "                    # B. Reshape the Data\n",
    "                    clean_df = extract_variables(raw_df)\n",
    "                    \n",
    "                    # C. Save to CSV\n",
    "                    filename = f\"Sheet1_{month}_{year}.csv\"\n",
    "                    full_save_path = os.path.join(year_folder_path, filename)\n",
    "                    \n",
    "                    clean_df.to_csv(full_save_path, index=False)\n",
    "                    \n",
    "                    # Print confirmation for this specific file\n",
    "                    print(f\"[OK] Saved: {year}/{filename}\")\n",
    "                    success_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Failed {month} {year}: {e}\")\n",
    "                    errors_log.append(f\"{month} {year}: {str(e)}\")\n",
    "                    failure_count += 1\n",
    "            else:\n",
    "                skipped_count += 1\n",
    "\n",
    "    # 4. Final Assurance Report\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"      PROCESSING SUMMARY REPORT\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total Successfully Saved: {success_count}\")\n",
    "    print(f\"Total Failed:             {failure_count}\")\n",
    "    print(f\"Total Skipped (No File):  {skipped_count}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if failure_count == 0:\n",
    "        print(\"STATUS: COMPLETE SUCCESS\")\n",
    "        print(f\"All files are now located in: {main_folder_path}\")\n",
    "        print(\"Google Drive is syncing these files now.\")\n",
    "    else:\n",
    "        print(\"STATUS: COMPLETED WITH ERRORS\")\n",
    "        print(\"Check the errors log above.\")\n",
    "        if errors_log:\n",
    "            print(\"\\nError Details:\")\n",
    "            for err in errors_log:\n",
    "                print(f\" - {err}\")\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b56256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING BATCH PROCESS ---\n",
      "Target Directory: G:\\My Drive\\Labor Force Survey\\Metadata Sheet 1 CSV's\n",
      "--------------------------------------------------\n",
      "[OK] Saved: 2018/Sheet1_January_2018.csv\n",
      "[OK] Saved: 2018/Sheet1_July_2018.csv\n",
      "[OK] Saved: 2018/Sheet1_April_2018.csv\n",
      "[OK] Saved: 2018/Sheet1_October_2018.csv\n",
      "[OK] Saved: 2019/Sheet1_April_2019.csv\n",
      "[OK] Saved: 2019/Sheet1_January_2019.csv\n",
      "[OK] Saved: 2019/Sheet1_July_2019.csv\n",
      "[OK] Saved: 2019/Sheet1_October_2019.csv\n",
      "[OK] Saved: 2022/Sheet1_April_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_August_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_December_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_February_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_January_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_July_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_June_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_March_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_May_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_November_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_October_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_September_2022.csv\n",
      "[OK] Saved: 2023/Sheet1_April_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_August_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_December_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_February_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_January_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_July_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_June_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_March_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_November_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_October_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_September_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_May_2023.csv\n",
      "[OK] Saved: 2024/Sheet1_February_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_April_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_January_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_August_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_July_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_March_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_May_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_June_2024.csv\n",
      "\n",
      "========================================\n",
      "      PROCESSING SUMMARY REPORT\n",
      "========================================\n",
      "Total Successfully Saved: 40\n",
      "Total Failed:             0\n",
      "Total Skipped (No File):  0\n",
      "----------------------------------------\n",
      "STATUS: COMPLETE SUCCESS\n",
      "All files are now located in: G:\\My Drive\\Labor Force Survey\\Metadata Sheet 1 CSV's\n",
      "Google Drive is syncing these files now.\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Run the processor\n",
    "batch_process_sheet1_metadata(inventory, base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c5d72",
   "metadata": {},
   "source": [
    "#### Verifying if the variable and description counts of Reshaped Metadata Sheet 1 and Original matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ef001d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_verify_sheet1_variable_and_description_count_verbose(inventory, base_path):\n",
    "    \"\"\"\n",
    "    Iterates through all years and months in the inventory and compares\n",
    "    total variables and descriptions in raw vs reshaped Sheet 1 metadata.\n",
    "    Prints mismatches immediately, and returns a DataFrame with all results.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for year, months_data in inventory.items():\n",
    "        for month, files_list in months_data.items():\n",
    "            if month == \"Unmatched\":\n",
    "                continue  # Skip unmatched files\n",
    "\n",
    "            # --- Load raw Sheet 1 ---\n",
    "            try:\n",
    "                raw_df = load_dataset(year, month, \"metadata\", sheet_number=0)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {month} {year}: Could not load raw Sheet 1 ({e})\")\n",
    "                results.append({\n",
    "                    'Year': year,\n",
    "                    'Month': month,\n",
    "                    'Raw Variable Count': 'ERROR',\n",
    "                    'Reshaped Variable Count': 'ERROR',\n",
    "                    'Raw Description Count': 'ERROR',\n",
    "                    'Reshaped Description Count': 'ERROR',\n",
    "                    'Status': f'FAIL (Raw load error: {e})'\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            # --- Load reshaped CSV Sheet 1 ---\n",
    "            reshaped_file_path = os.path.join(\n",
    "                base_path, \"Metadata Sheet 1 CSV's\", year, f\"Sheet1_{month}_{year}.csv\"\n",
    "            )\n",
    "            if not os.path.exists(reshaped_file_path):\n",
    "                print(f\"[ERROR] {month} {year}: Reshaped Sheet 1 CSV missing!\")\n",
    "                results.append({\n",
    "                    'Year': year,\n",
    "                    'Month': month,\n",
    "                    'Raw Variable Count': 'ERROR',\n",
    "                    'Reshaped Variable Count': 'ERROR',\n",
    "                    'Raw Description Count': 'ERROR',\n",
    "                    'Reshaped Description Count': 'ERROR',\n",
    "                    'Status': 'FAIL (Reshaped CSV missing)'\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            reshaped_df = pd.read_csv(reshaped_file_path)\n",
    "\n",
    "            # --- Count non-empty variables & descriptions ---\n",
    "            raw_vars = raw_df.iloc[:, 4].dropna().astype(str).str.strip()\n",
    "            raw_vars = raw_vars[raw_vars != '']\n",
    "            raw_descs = raw_df.iloc[:, 5].dropna().astype(str).str.strip()\n",
    "            raw_descs = raw_descs[raw_descs != '']\n",
    "\n",
    "            reshaped_vars = reshaped_df['Variable'].astype(str).str.strip()\n",
    "            reshaped_vars = reshaped_vars[reshaped_vars != '']\n",
    "            reshaped_descs = reshaped_df['Description'].astype(str).str.strip()\n",
    "            reshaped_descs = reshaped_descs[reshaped_descs != '']\n",
    "\n",
    "            # --- PASS / FAIL ---\n",
    "            status = \"PASS\" if (len(raw_vars) == len(reshaped_vars) and len(raw_descs) == len(reshaped_descs)) else \"FAIL\"\n",
    "\n",
    "            if status == \"FAIL\":\n",
    "                print(f\"[MISMATCH] {month} {year} - Variables: {len(raw_vars)} vs {len(reshaped_vars)}, \"\n",
    "                      f\"Descriptions: {len(raw_descs)} vs {len(reshaped_descs)}\")\n",
    "\n",
    "            results.append({\n",
    "                'Year': year,\n",
    "                'Month': month,\n",
    "                'Raw Variable Count': len(raw_vars),\n",
    "                'Reshaped Variable Count': len(reshaped_vars),\n",
    "                'Raw Description Count': len(raw_descs),\n",
    "                'Reshaped Description Count': len(reshaped_descs),\n",
    "                'Status': status\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values(['Year', 'Month']).reset_index(drop=True)\n",
    "\n",
    "    # ---------- NEW SUCCESS MESSAGE ----------\n",
    "    total = len(df)\n",
    "    passed = (df['Status'] == 'PASS').sum()\n",
    "    failed = total - passed\n",
    "\n",
    "    if failed == 0:\n",
    "        print(\"\\nSUCCESS: All variables and descriptions have been reshaped correctly!\\n\")\n",
    "    else:\n",
    "        print(f\"\\nCompleted with issues: {passed} PASS, {failed} FAIL.\\n\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a3fe858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUCCESS: All variables and descriptions have been reshaped correctly!\n",
      "\n",
      "=== Sheet 1 Metadata Variables and Descriptions (Raw vs Reshaped) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Raw Variable Count</th>\n",
       "      <th>Reshaped Variable Count</th>\n",
       "      <th>Raw Description Count</th>\n",
       "      <th>Reshaped Description Count</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>July</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>April</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>January</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>July</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>October</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022</td>\n",
       "      <td>April</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>August</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022</td>\n",
       "      <td>December</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022</td>\n",
       "      <td>February</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022</td>\n",
       "      <td>January</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022</td>\n",
       "      <td>July</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022</td>\n",
       "      <td>June</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022</td>\n",
       "      <td>March</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022</td>\n",
       "      <td>May</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022</td>\n",
       "      <td>November</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022</td>\n",
       "      <td>October</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022</td>\n",
       "      <td>September</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023</td>\n",
       "      <td>April</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023</td>\n",
       "      <td>August</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023</td>\n",
       "      <td>December</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023</td>\n",
       "      <td>February</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023</td>\n",
       "      <td>January</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023</td>\n",
       "      <td>July</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023</td>\n",
       "      <td>June</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023</td>\n",
       "      <td>March</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023</td>\n",
       "      <td>May</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023</td>\n",
       "      <td>November</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023</td>\n",
       "      <td>October</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023</td>\n",
       "      <td>September</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2024</td>\n",
       "      <td>April</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2024</td>\n",
       "      <td>August</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2024</td>\n",
       "      <td>February</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2024</td>\n",
       "      <td>January</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024</td>\n",
       "      <td>July</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2024</td>\n",
       "      <td>June</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2024</td>\n",
       "      <td>March</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year      Month  Raw Variable Count  Reshaped Variable Count  \\\n",
       "0   2018      April                  50                       50   \n",
       "1   2018    January                  50                       50   \n",
       "2   2018       July                  51                       51   \n",
       "3   2018    October                  51                       51   \n",
       "4   2019      April                  49                       49   \n",
       "5   2019    January                  49                       49   \n",
       "6   2019       July                  49                       49   \n",
       "7   2019    October                  49                       49   \n",
       "8   2022      April                  52                       52   \n",
       "9   2022     August                  42                       42   \n",
       "10  2022   December                  42                       42   \n",
       "11  2022   February                  41                       41   \n",
       "12  2022    January                  52                       52   \n",
       "13  2022       July                  52                       52   \n",
       "14  2022       June                  42                       42   \n",
       "15  2022      March                  41                       41   \n",
       "16  2022        May                  42                       42   \n",
       "17  2022   November                  42                       42   \n",
       "18  2022    October                  52                       52   \n",
       "19  2022  September                  42                       42   \n",
       "20  2023      April                  52                       52   \n",
       "21  2023     August                  41                       41   \n",
       "22  2023   December                  41                       41   \n",
       "23  2023   February                  42                       42   \n",
       "24  2023    January                  52                       52   \n",
       "25  2023       July                  52                       52   \n",
       "26  2023       June                  42                       42   \n",
       "27  2023      March                  42                       42   \n",
       "28  2023        May                  42                       42   \n",
       "29  2023   November                  41                       41   \n",
       "30  2023    October                  52                       52   \n",
       "31  2023  September                  41                       41   \n",
       "32  2024      April                  51                       51   \n",
       "33  2024     August                  40                       40   \n",
       "34  2024   February                  41                       41   \n",
       "35  2024    January                  52                       52   \n",
       "36  2024       July                  51                       51   \n",
       "37  2024       June                  40                       40   \n",
       "38  2024      March                  41                       41   \n",
       "39  2024        May                  40                       40   \n",
       "\n",
       "    Raw Description Count  Reshaped Description Count Status  \n",
       "0                      50                          50   PASS  \n",
       "1                      50                          50   PASS  \n",
       "2                      51                          51   PASS  \n",
       "3                      51                          51   PASS  \n",
       "4                      49                          49   PASS  \n",
       "5                      49                          49   PASS  \n",
       "6                      49                          49   PASS  \n",
       "7                      49                          49   PASS  \n",
       "8                      52                          52   PASS  \n",
       "9                      42                          42   PASS  \n",
       "10                     42                          42   PASS  \n",
       "11                     41                          41   PASS  \n",
       "12                     52                          52   PASS  \n",
       "13                     52                          52   PASS  \n",
       "14                     42                          42   PASS  \n",
       "15                     41                          41   PASS  \n",
       "16                     42                          42   PASS  \n",
       "17                     42                          42   PASS  \n",
       "18                     52                          52   PASS  \n",
       "19                     42                          42   PASS  \n",
       "20                     52                          52   PASS  \n",
       "21                     41                          41   PASS  \n",
       "22                     41                          41   PASS  \n",
       "23                     42                          42   PASS  \n",
       "24                     52                          52   PASS  \n",
       "25                     52                          52   PASS  \n",
       "26                     42                          42   PASS  \n",
       "27                     42                          42   PASS  \n",
       "28                     42                          42   PASS  \n",
       "29                     41                          41   PASS  \n",
       "30                     52                          52   PASS  \n",
       "31                     41                          41   PASS  \n",
       "32                     51                          51   PASS  \n",
       "33                     40                          40   PASS  \n",
       "34                     41                          41   PASS  \n",
       "35                     52                          52   PASS  \n",
       "36                     51                          51   PASS  \n",
       "37                     40                          40   PASS  \n",
       "38                     41                          41   PASS  \n",
       "39                     40                          40   PASS  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verification_df = batch_verify_sheet1_variable_and_description_count_verbose(inventory, base_path)\n",
    "\n",
    "print(\"=== Sheet 1 Metadata Variables and Descriptions (Raw vs Reshaped) ===\")\n",
    "verification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "58ce0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_verify_sheet1_variable_and_description_count_verbose(inventory, base_path):\n",
    "    \"\"\"\n",
    "    Iterates through all years and months in the inventory and compares\n",
    "    total variables and descriptions in raw vs reshaped Sheet 1 metadata.\n",
    "    Prints mismatches immediately, and returns a DataFrame with all results.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for year, months_data in inventory.items():\n",
    "        for month, files_list in months_data.items():\n",
    "            if month == \"Unmatched\":\n",
    "                continue  # Skip unmatched files\n",
    "\n",
    "            # --- Load raw Sheet 1 ---\n",
    "            try:\n",
    "                raw_df = load_dataset(year, month, \"metadata\", sheet_number=0)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {month} {year}: Could not load raw Sheet 1 ({e})\")\n",
    "                results.append({\n",
    "                    'Year': year,\n",
    "                    'Month': month,\n",
    "                    'Raw Variable Count': 'ERROR',\n",
    "                    'Reshaped Variable Count': 'ERROR',\n",
    "                    'Raw Description Count': 'ERROR',\n",
    "                    'Reshaped Description Count': 'ERROR',\n",
    "                    'Status': f'FAIL (Raw load error: {e})'\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            # --- Load reshaped CSV Sheet 1 ---\n",
    "            reshaped_file_path = os.path.join(\n",
    "                base_path, \"Metadata Sheet 1 CSV's\", year, f\"Sheet1_{month}_{year}.csv\"\n",
    "            )\n",
    "            if not os.path.exists(reshaped_file_path):\n",
    "                print(f\"[ERROR] {month} {year}: Reshaped Sheet 1 CSV missing!\")\n",
    "                results.append({\n",
    "                    'Year': year,\n",
    "                    'Month': month,\n",
    "                    'Raw Variable Count': 'ERROR',\n",
    "                    'Reshaped Variable Count': 'ERROR',\n",
    "                    'Raw Description Count': 'ERROR',\n",
    "                    'Reshaped Description Count': 'ERROR',\n",
    "                    'Status': 'FAIL (Reshaped CSV missing)'\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            reshaped_df = pd.read_csv(reshaped_file_path)\n",
    "\n",
    "            # --- Count non-empty variables and descriptions ---\n",
    "            raw_vars = raw_df.iloc[:, 4].dropna().astype(str).str.strip()\n",
    "            raw_vars = raw_vars[raw_vars != '']\n",
    "            raw_descs = raw_df.iloc[:, 5].dropna().astype(str).str.strip()\n",
    "            raw_descs = raw_descs[raw_descs != '']\n",
    "\n",
    "            reshaped_vars = reshaped_df['Variable'].astype(str).str.strip()\n",
    "            reshaped_vars = reshaped_vars[reshaped_vars != '']\n",
    "            reshaped_descs = reshaped_df['Description'].astype(str).str.strip()\n",
    "            reshaped_descs = reshaped_descs[reshaped_descs != '']\n",
    "\n",
    "            # --- Check if both counts match ---\n",
    "            status = \"PASS\" if (len(raw_vars) == len(reshaped_vars) and len(raw_descs) == len(reshaped_descs)) else \"FAIL\"\n",
    "\n",
    "            if status == \"FAIL\":\n",
    "                # Immediate print for any mismatch\n",
    "                print(f\"[MISMATCH] {month} {year} - Variables: {len(raw_vars)} vs {len(reshaped_vars)}, \"\n",
    "                      f\"Descriptions: {len(raw_descs)} vs {len(reshaped_descs)}\")\n",
    "\n",
    "            results.append({\n",
    "                'Year': year,\n",
    "                'Month': month,\n",
    "                'Raw Variable Count': len(raw_vars),\n",
    "                'Reshaped Variable Count': len(reshaped_vars),\n",
    "                'Raw Description Count': len(raw_descs),\n",
    "                'Reshaped Description Count': len(reshaped_descs),\n",
    "                'Status': status\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values(['Year', 'Month']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "705162ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sheet 1 Metadata Variables and Descriptions (Raw vs Reshaped) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Raw Variable Count</th>\n",
       "      <th>Reshaped Variable Count</th>\n",
       "      <th>Raw Description Count</th>\n",
       "      <th>Reshaped Description Count</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>July</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>April</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year    Month  Raw Variable Count  Reshaped Variable Count  \\\n",
       "0  2018    April                  50                       50   \n",
       "1  2018  January                  50                       50   \n",
       "2  2018     July                  51                       51   \n",
       "3  2018  October                  51                       51   \n",
       "4  2019    April                  49                       49   \n",
       "\n",
       "   Raw Description Count  Reshaped Description Count Status  \n",
       "0                     50                          50   PASS  \n",
       "1                     50                          50   PASS  \n",
       "2                     51                          51   PASS  \n",
       "3                     51                          51   PASS  \n",
       "4                     49                          49   PASS  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Sheet 1 verifier\n",
    "verification_df = batch_verify_sheet1_variable_and_description_count_verbose(inventory, base_path)\n",
    "\n",
    "# Print a header and show the first few rows\n",
    "print(\"=== Sheet 1 Metadata Variables and Descriptions (Raw vs Reshaped) ===\")\n",
    "verification_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90639dd6",
   "metadata": {},
   "source": [
    "Checking January 2018 Metadata Reshaped Sheet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1855dd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PUFREG</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUFPRV</td>\n",
       "      <td>Province</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUFPRRCD</td>\n",
       "      <td>Province Recode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUFHHNUM</td>\n",
       "      <td>Household Unique Sequential Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUFURB2K10</td>\n",
       "      <td>2010Urban-RuralFIES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Variable                         Description\n",
       "0      PUFREG                              Region\n",
       "1      PUFPRV                            Province\n",
       "2    PUFPRRCD                     Province Recode\n",
       "3    PUFHHNUM  Household Unique Sequential Number\n",
       "4  PUFURB2K10                 2010Urban-RuralFIES"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata Sheet 1\n",
    "January_metadata = load_dataset(\"2018\", \"January\", \"metadata\", 0)\n",
    "\n",
    "# Call your function\n",
    "variables_df = extract_variables(January_metadata)\n",
    "\n",
    "# View results\n",
    "variables_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba725a1",
   "metadata": {},
   "source": [
    "Checking August 2024 Metadata Reshaped Sheet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dcaca8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PUFHHNUM</td>\n",
       "      <td>Household Unique Sequential Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUFPWGTPRV</td>\n",
       "      <td>Final Weight Based on Projection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUFSVYMO</td>\n",
       "      <td>Survey Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUFSVYYR</td>\n",
       "      <td>Survey Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUFPSU</td>\n",
       "      <td>Psu Number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Variable                         Description\n",
       "0    PUFHHNUM  Household Unique Sequential Number\n",
       "1  PUFPWGTPRV    Final Weight Based on Projection\n",
       "2    PUFSVYMO                        Survey Month\n",
       "3    PUFSVYYR                         Survey Year\n",
       "4      PUFPSU                          Psu Number"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata Sheet 1\n",
    "August_2024_metadata = load_dataset(\"2024\", \"August\", \"metadata\", 0)\n",
    "\n",
    "# Call your function\n",
    "variables_df = extract_variables(August_2024_metadata)\n",
    "\n",
    "# View results\n",
    "variables_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2765e519",
   "metadata": {},
   "source": [
    "## Metadata Sheet 2 Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf97232",
   "metadata": {},
   "source": [
    "<H5> Sample: January 2018 Metadata Sheet 2 (Raw)</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c0585a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== January 2018 Metadata Sheet 2 (Raw) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUFREG_VS1</th>\n",
       "      <th>Region</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Capital Region</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cordillera Administrative Region</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Region II - Cagayan Valley</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Region III - Central Luzon</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PUFREG_VS1 Region                        Unnamed: 2 Unnamed: 3  Unnamed: 4  \\\n",
       "0        NaN    NaN           National Capital Region         13         NaN   \n",
       "1        NaN    NaN  Cordillera Administrative Region         14         NaN   \n",
       "2        NaN    NaN          Region I - Ilocos Region          1         NaN   \n",
       "3        NaN    NaN        Region II - Cagayan Valley          2         NaN   \n",
       "4        NaN    NaN        Region III - Central Luzon          3         NaN   \n",
       "\n",
       "  Unnamed: 5  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the second sheet of January 2018 metadata\n",
    "january_2018_metadata_sheet2 = load_dataset(\"2018\", \"January\", \"metadata\", 1)\n",
    "\n",
    "# View the first few rows\n",
    "print(\"=== January 2018 Metadata Sheet 2 (Raw) ===\")\n",
    "january_2018_metadata_sheet2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000e17a",
   "metadata": {},
   "source": [
    "### Reshaping Metadata Sheet 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "acb63dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def reshape_sheet2_robust(df):\n",
    "    \"\"\"\n",
    "    Convert metadata Sheet 2 (the values dictionary) into a clean, long-format table.\n",
    "\n",
    "    This function reads the sheet exactly as it appears in Excel, without:\n",
    "    - Assuming any header row\n",
    "    - Auto-filling missing values\n",
    "    - Inferencing min/max values\n",
    "    - Guessing variable names\n",
    "\n",
    "    Sheet 2 typically has this layout:\n",
    "        Column A = Variable name (only appears once per block)\n",
    "        Column B = Variable description (blank except at the start of a block)\n",
    "        Column C = Label for each value (required)\n",
    "        Column D = Minimum value (optional)\n",
    "        Column E = Maximum value (optional)\n",
    "        Column F+ = Additional text or category notes (optional)\n",
    "\n",
    "    The function processes rows in order and:\n",
    "        - Carries forward the most recent non-empty variable name (Column A)\n",
    "        - Carries forward the most recent non-empty description (Column B)\n",
    "        - Creates one output row per value label (Column C)\n",
    "        - Leaves missing min/max/additional values as 0\n",
    "        - Reads extra info (Column F onward) if present\n",
    "\n",
    "    Returns:\n",
    "        A clean pandas DataFrame with columns:\n",
    "            Variable\n",
    "            Description\n",
    "            Label\n",
    "            min_value\n",
    "            max_value\n",
    "            additional_value\n",
    "    \"\"\"\n",
    "\n",
    "    reshaped = []\n",
    "\n",
    "    # Ensure all blanks are handled consistently\n",
    "    df = df.fillna('').astype(str)\n",
    "\n",
    "    # Initialize with the first variable and description\n",
    "    current_var = df.iloc[0, 0].strip() or 'UNKNOWN_VAR'\n",
    "    current_desc = df.iloc[0, 1].strip() or ''\n",
    "\n",
    "    # Iterate row-by-row\n",
    "    for idx, row in df.iterrows():\n",
    "        # ---- Column A: Variable name ----\n",
    "        var_candidate = row.iloc[0].strip()\n",
    "        if var_candidate:\n",
    "            current_var = var_candidate\n",
    "\n",
    "        # ---- Column B: Description ----\n",
    "        desc_candidate = row.iloc[1].strip()\n",
    "        if desc_candidate:\n",
    "            current_desc = desc_candidate\n",
    "\n",
    "        # ---- PRE-READ Columns D, E, F (Values) ----\n",
    "        raw_min = row.iloc[3].strip()\n",
    "        raw_max = row.iloc[4].strip()\n",
    "        \n",
    "        # Look for extra values (Column F+)\n",
    "        extra = '0'\n",
    "        if len(row) > 5:\n",
    "            for j in range(5, len(row)):\n",
    "                extra_candidate = row.iloc[j].strip()\n",
    "                if extra_candidate:\n",
    "                    extra = extra_candidate\n",
    "                    break\n",
    "\n",
    "        # ---- Column C: Label ----\n",
    "        label = row.iloc[2].strip()\n",
    "\n",
    "        # FIX: Don't just continue. Check if values exist.\n",
    "        if not label:\n",
    "            # If label is missing BUT we have min, max, or extra -> It's a valid row\n",
    "            if raw_min or raw_max or extra != '0':\n",
    "                label = '0'  # Assign default label\n",
    "            else:\n",
    "                continue     # Skip only if truly empty\n",
    "\n",
    "        # ---- Finalize Min/Max ----\n",
    "        min_value = raw_min if raw_min else '0'\n",
    "        max_value = raw_max if raw_max else '0'\n",
    "\n",
    "        # ---- Append clean record ----\n",
    "        reshaped.append({\n",
    "            \"Variable\": current_var,\n",
    "            \"Description\": current_desc,\n",
    "            \"Label\": label,\n",
    "            \"min_value\": min_value,\n",
    "            \"max_value\": max_value,\n",
    "            \"additional_value\": extra\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(reshaped)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#   load_dataset()\n",
    "# ============================================================\n",
    "def load_dataset(year, month, filetype=\"survey\", sheet_number=None):\n",
    "    \"\"\"\n",
    "    Load any dataset (survey or metadata) from the file inventory.\n",
    "\n",
    "    â€¢ For SURVEY CSV: normal pandas.read_csv()\n",
    "    â€¢ For METADATA Excel: read with no header, reshape Sheet 2 automatically\n",
    "    \"\"\"\n",
    "    # Retrieve file information from inventory\n",
    "    file_info = next(\n",
    "        (f for f in inventory[year][month] if f[\"filetype\"] == filetype),\n",
    "        None\n",
    "    )\n",
    "\n",
    "    if not file_info:\n",
    "        raise ValueError(f\"No {filetype} file found for {month} {year}\")\n",
    "\n",
    "    file_path = os.path.join(base_path, year, file_info[\"filename\"])\n",
    "\n",
    "    if filetype == \"survey\":\n",
    "        return pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "    # Metadata Excel â€” always read with no header\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_number, header=None)\n",
    "\n",
    "    # Automatic reshaping ONLY for metadata Sheet 2\n",
    "    if sheet_number == 1:\n",
    "        df = reshape_sheet2_robust(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68122521",
   "metadata": {},
   "source": [
    "### Metadata Sheet 2 Reshaped Saving Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "72447c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def batch_process_sheet2_metadata(inventory, base_output_path):\n",
    "    \"\"\"\n",
    "    Loops through the inventory to process 'Sheet 2' (Value Codes).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Counters for the summary report\n",
    "    success_count = 0\n",
    "    failure_count = 0\n",
    "    skipped_count = 0\n",
    "    errors_log = []\n",
    "\n",
    "    # 1. Define Main Folder Name\n",
    "    main_folder_name = \"Metadata Sheet 2 CSV's\"\n",
    "    main_folder_path = os.path.join(base_output_path, main_folder_name)\n",
    "    os.makedirs(main_folder_path, exist_ok=True)\n",
    "    \n",
    "    print(\"--- STARTING BATCH PROCESS (SHEET 2) ---\")\n",
    "    print(f\"Target Directory: {main_folder_path}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 2. Iterate through Inventory\n",
    "    for year, months_data in inventory.items():\n",
    "        \n",
    "        # Create Year Subfolder\n",
    "        year_folder_path = os.path.join(main_folder_path, year)\n",
    "        os.makedirs(year_folder_path, exist_ok=True)\n",
    "        \n",
    "        for month, files_list in months_data.items():\n",
    "            # Skip unmatched files\n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "            \n",
    "            # Check if metadata exists for this month\n",
    "            has_metadata = any(f.get('filetype') == 'metadata' for f in files_list)\n",
    "            \n",
    "            if has_metadata:\n",
    "                try:\n",
    "                    # A. Load & Reshape\n",
    "                    # Your load_dataset function handles the cleaning internally\n",
    "                    clean_df = load_dataset(year, month, \"metadata\", 1)\n",
    "                    \n",
    "                    # B. Generate Filename\n",
    "                    filename = f\"Sheet2_{month}_{year}.csv\"\n",
    "                    full_save_path = os.path.join(year_folder_path, filename)\n",
    "                    \n",
    "                    # C. Save\n",
    "                    clean_df.to_csv(full_save_path, index=False)\n",
    "                    \n",
    "                    print(f\"[OK] Saved: {year}/{filename}\")\n",
    "                    success_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Failed {month} {year}: {e}\")\n",
    "                    errors_log.append(f\"{month} {year}: {str(e)}\")\n",
    "                    failure_count += 1\n",
    "            else:\n",
    "                skipped_count += 1\n",
    "\n",
    "    # 3. Final Report\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"      SHEET 2 PROCESSING SUMMARY\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total Saved:    {success_count}\")\n",
    "    print(f\"Total Failed:   {failure_count}\")\n",
    "    print(f\"Total Skipped:  {skipped_count}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if failure_count == 0:\n",
    "        print(\"STATUS: COMPLETE SUCCESS\")\n",
    "        print(f\"Files are syncing to: {main_folder_path}\")\n",
    "    else:\n",
    "        print(\"STATUS: COMPLETED WITH ERRORS\")\n",
    "        for err in errors_log:\n",
    "            print(f\" - {err}\")\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "aea6147e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING BATCH PROCESS (SHEET 2) ---\n",
      "Target Directory: G:\\My Drive\\Labor Force Survey\\Metadata Sheet 2 CSV's\n",
      "--------------------------------------------------\n",
      "[OK] Saved: 2018/Sheet2_January_2018.csv\n",
      "[OK] Saved: 2018/Sheet2_July_2018.csv\n",
      "[OK] Saved: 2018/Sheet2_April_2018.csv\n",
      "[OK] Saved: 2018/Sheet2_October_2018.csv\n",
      "[OK] Saved: 2019/Sheet2_April_2019.csv\n",
      "[OK] Saved: 2019/Sheet2_January_2019.csv\n",
      "[OK] Saved: 2019/Sheet2_July_2019.csv\n",
      "[OK] Saved: 2019/Sheet2_October_2019.csv\n",
      "[OK] Saved: 2022/Sheet2_April_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_August_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_December_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_February_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_January_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_July_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_June_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_March_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_May_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_November_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_October_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_September_2022.csv\n",
      "[OK] Saved: 2023/Sheet2_April_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_August_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_December_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_February_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_January_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_July_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_June_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_March_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_November_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_October_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_September_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_May_2023.csv\n",
      "[OK] Saved: 2024/Sheet2_February_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_April_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_January_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_August_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_July_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_March_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_May_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_June_2024.csv\n",
      "\n",
      "========================================\n",
      "      SHEET 2 PROCESSING SUMMARY\n",
      "========================================\n",
      "Total Saved:    40\n",
      "Total Failed:   0\n",
      "Total Skipped:  0\n",
      "----------------------------------------\n",
      "STATUS: COMPLETE SUCCESS\n",
      "Files are syncing to: G:\\My Drive\\Labor Force Survey\\Metadata Sheet 2 CSV's\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Run the processor\n",
    "# (Requires 'inventory' and 'load_dataset' to be defined in your environment)\n",
    "batch_process_sheet2_metadata(inventory, base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1009e2b",
   "metadata": {},
   "source": [
    "#### Verifying if the variable counts of Reshaped Metadata Sheet 2 and Original matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "050a0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def batch_verify_sheet2_variable_and_label_count(inventory, base_path):\n",
    "    \"\"\"\n",
    "    Batch verify Sheet 2 metadata (values dictionary) across years/months.\n",
    "    Compares:\n",
    "      â€¢ Unique variable count (raw vs reshaped)\n",
    "      â€¢ Label count per variable (raw vs reshaped)\n",
    "    Prints mismatches immediately and returns a summary DataFrame.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    for year, months_data in inventory.items():\n",
    "        for month, files_list in months_data.items():\n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "\n",
    "            # --- Load raw Sheet 2 ---\n",
    "            # NOTE: Ensure 'load_dataset' is defined in your previous cells\n",
    "            try:\n",
    "                raw_df = load_dataset(year, month, \"metadata\", sheet_number=1)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {month} {year}: Could not load raw Sheet 2 ({e})\")\n",
    "                continue\n",
    "\n",
    "            # --- Load reshaped Sheet 2 CSV ---\n",
    "            reshaped_path = os.path.join(\n",
    "                base_path, \n",
    "                \"Metadata Sheet 2 CSV's\", \n",
    "                year, \n",
    "                f\"Sheet2_{month}_{year}.csv\"\n",
    "            )\n",
    "            \n",
    "            if not os.path.exists(reshaped_path):\n",
    "                print(f\"[ERROR] {month} {year}: Reshaped Sheet 2 CSV missing!\")\n",
    "                continue\n",
    "\n",
    "            reshaped_df = pd.read_csv(reshaped_path, dtype=str).fillna(\"\")\n",
    "\n",
    "            # --- Count unique variables ---\n",
    "            raw_vars = raw_df.iloc[:, 0].astype(str).str.strip()\n",
    "            raw_vars = raw_vars[raw_vars != '']  # ignore empty\n",
    "            raw_unique_vars = pd.Index(raw_vars).unique()\n",
    "\n",
    "            resh_vars = reshaped_df['Variable'].astype(str).str.strip()\n",
    "            resh_unique_vars = pd.Index(resh_vars).unique()\n",
    "\n",
    "            # Check variable count mismatch\n",
    "            variable_mismatch = len(raw_unique_vars) != len(resh_unique_vars)\n",
    "            if variable_mismatch:\n",
    "                print(f\"[VARIABLE COUNT MISMATCH] {month} {year}: Raw={len(raw_unique_vars)}, Reshaped={len(resh_unique_vars)}\")\n",
    "\n",
    "            # --- Count labels per variable ---\n",
    "            label_mismatches = []\n",
    "\n",
    "            for var in raw_unique_vars:\n",
    "                # Raw: select rows matching variable\n",
    "                raw_rows = raw_df[raw_df.iloc[:, 0].astype(str).str.strip() == var]\n",
    "\n",
    "                # Count non-empty label cells safely (cols 2 to 6 usually contain labels/values)\n",
    "                raw_label_count = raw_rows.iloc[:, 2:6].astype(str).apply(\n",
    "                    lambda x: x.str.strip().ne('').any(), axis=1\n",
    "                ).sum()\n",
    "\n",
    "                # Reshaped: count rows per variable\n",
    "                resh_label_count = reshaped_df[reshaped_df['Variable'].astype(str).str.strip() == var].shape[0]\n",
    "\n",
    "                if raw_label_count != resh_label_count:\n",
    "                    label_mismatches.append({\n",
    "                        \"Variable\": var,\n",
    "                        \"Raw_Label_Count\": raw_label_count,\n",
    "                        \"Reshaped_Label_Count\": resh_label_count\n",
    "                    })\n",
    "\n",
    "            # --- Print immediate label mismatches ---\n",
    "            for m in label_mismatches:\n",
    "                print(f\"[LABEL COUNT MISMATCH] {month} {year} - Variable: {m['Variable']} | Raw={m['Raw_Label_Count']} vs Reshaped={m['Reshaped_Label_Count']}\")\n",
    "\n",
    "            # --- Record summary ---\n",
    "            all_results.append({\n",
    "                \"Year\": year,\n",
    "                \"Month\": month,\n",
    "                \"Raw_Variable_Count\": len(raw_unique_vars),\n",
    "                \"Reshaped_Variable_Count\": len(resh_unique_vars),\n",
    "                \"Variable_Count_Status\": \"PASS\" if not variable_mismatch else \"FAIL\",\n",
    "                \"Label_Count_Mismatches\": len(label_mismatches)\n",
    "            })\n",
    "\n",
    "    # --- Final Summary Report ---\n",
    "    df_summary = pd.DataFrame(all_results).sort_values(['Year', 'Month']).reset_index(drop=True)\n",
    "    \n",
    "    var_fails = (df_summary[\"Variable_Count_Status\"] == \"FAIL\").sum()\n",
    "    label_fails = df_summary[\"Label_Count_Mismatches\"].sum()\n",
    "\n",
    "    if var_fails == 0 and label_fails == 0:\n",
    "        print(\"\\nSUCCESS: All Sheet 2 variables and labels have been reshaped correctly across the batch!\\n\")\n",
    "    else:\n",
    "        print(f\"\\nCompleted with issues: {var_fails} variable count mismatches, {label_fails} label mismatches.\\n\")\n",
    "\n",
    "    return df_summary\n",
    "\n",
    "def verify_sheet2_content(original_df, reshaped_df):\n",
    "    \"\"\"\n",
    "    Compare original Sheet 2 with reshaped version.\n",
    "    Checks: Variables, Descriptions, Labels, Min/Max/Additional values.\n",
    "    Ignores row order.\n",
    "    \"\"\"\n",
    "    # Normalize to string\n",
    "    original = original_df.fillna(\"\").astype(str)\n",
    "    reshaped = reshaped_df.fillna(\"\").astype(str)\n",
    "\n",
    "    # --- Extract original as dict ---\n",
    "    def build_original_dict(df):\n",
    "        data = {}\n",
    "        current_var = \"\"\n",
    "        current_desc = \"\"\n",
    "        for _, row in df.iterrows():\n",
    "            colA = row.iloc[0].strip()\n",
    "            colB = row.iloc[1].strip()\n",
    "            colC = row.iloc[2].strip()\n",
    "            \n",
    "            if colA: current_var = colA\n",
    "            if colB: current_desc = colB\n",
    "            \n",
    "            if not colC: continue # Skip if label is empty\n",
    "            \n",
    "            minv = row.iloc[3].strip() if len(row) > 3 else \"\"\n",
    "            maxv = row.iloc[4].strip() if len(row) > 4 else \"\"\n",
    "            extra = \"\"\n",
    "            \n",
    "            # Find extra value if it exists beyond standard columns\n",
    "            if len(row) > 5:\n",
    "                for j in range(5, len(row)):\n",
    "                    if row.iloc[j].strip():\n",
    "                        extra = row.iloc[j].strip()\n",
    "                        break\n",
    "                        \n",
    "            if current_var not in data:\n",
    "                data[current_var] = []\n",
    "            \n",
    "            data[current_var].append({\n",
    "                \"Description\": current_desc,\n",
    "                \"Label\": colC,\n",
    "                \"min_value\": minv,\n",
    "                \"max_value\": maxv,\n",
    "                \"additional_value\": extra\n",
    "            })\n",
    "        return data\n",
    "\n",
    "    orig_dict = build_original_dict(original)\n",
    "\n",
    "    # --- Extract reshaped as dict ---\n",
    "    resh_dict = {\n",
    "        var: group.drop(columns=\"Variable\").to_dict(\"records\")\n",
    "        for var, group in reshaped.groupby(\"Variable\")\n",
    "    }\n",
    "\n",
    "    # --- Verification ---\n",
    "    errors = []\n",
    "    orig_vars = set(orig_dict.keys())\n",
    "    resh_vars = set(resh_dict.keys())\n",
    "\n",
    "    missing_vars = orig_vars - resh_vars\n",
    "    extra_vars = resh_vars - orig_vars\n",
    "    \n",
    "    if missing_vars: errors.append(f\"Missing variables in reshaped: {missing_vars}\")\n",
    "    if extra_vars: errors.append(f\"Extra variables in reshaped: {extra_vars}\")\n",
    "\n",
    "    # Detailed label/content comparison\n",
    "    for var in orig_vars & resh_vars:\n",
    "        orig_records = orig_dict[var]\n",
    "        resh_records = resh_dict[var]\n",
    "        \n",
    "        orig_set = {(d[\"Label\"], d[\"min_value\"], d[\"max_value\"], d[\"additional_value\"]) for d in orig_records}\n",
    "        resh_set = {(d[\"Label\"], d[\"min_value\"], d[\"max_value\"], d[\"additional_value\"]) for d in resh_records}\n",
    "        \n",
    "        missing_rec = orig_set - resh_set\n",
    "        extra_rec = resh_set - orig_set\n",
    "        \n",
    "        if missing_rec: errors.append(f\"[{var}] Missing records: {missing_rec}\")\n",
    "        if extra_rec: errors.append(f\"[{var}] Extra records: {extra_rec}\")\n",
    "\n",
    "    if not errors:\n",
    "        return \"SUCCESS\"\n",
    "    else:\n",
    "        return \"MISMATCH FOUND:\\n\" + \"\\n\".join(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e2de0afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Batch Structure Verification ---\n",
      "\n",
      "SUCCESS: All Sheet 2 variables and labels have been reshaped correctly across the batch!\n",
      "\n",
      "\n",
      "[PASS] Structural batch check passed for all files.\n",
      "\n",
      "--- Starting Deep Content Verification (All Files) ---\n",
      "Verifying: January 2018... OK\n",
      "Verifying: July 2018... OK\n",
      "Verifying: April 2018... OK\n",
      "Verifying: October 2018... OK\n",
      "Verifying: April 2019... OK\n",
      "Verifying: January 2019... OK\n",
      "Verifying: July 2019... OK\n",
      "Verifying: October 2019... OK\n",
      "Verifying: April 2022... OK\n",
      "Verifying: August 2022... OK\n",
      "Verifying: December 2022... OK\n",
      "Verifying: February 2022... OK\n",
      "Verifying: January 2022... OK\n",
      "Verifying: July 2022... OK\n",
      "Verifying: June 2022... OK\n",
      "Verifying: March 2022... OK\n",
      "Verifying: May 2022... OK\n",
      "Verifying: November 2022... OK\n",
      "Verifying: October 2022... OK\n",
      "Verifying: September 2022... OK\n",
      "Verifying: April 2023... OK\n",
      "Verifying: August 2023... OK\n",
      "Verifying: December 2023... OK\n",
      "Verifying: February 2023... OK\n",
      "Verifying: January 2023... OK\n",
      "Verifying: July 2023... OK\n",
      "Verifying: June 2023... OK\n",
      "Verifying: March 2023... OK\n",
      "Verifying: November 2023... OK\n",
      "Verifying: October 2023... OK\n",
      "Verifying: September 2023... OK\n",
      "Verifying: May 2023... OK\n",
      "Verifying: February 2024... OK\n",
      "Verifying: April 2024... OK\n",
      "Verifying: January 2024... OK\n",
      "Verifying: August 2024... OK\n",
      "Verifying: July 2024... OK\n",
      "Verifying: March 2024... OK\n",
      "Verifying: May 2024... OK\n",
      "Verifying: June 2024... OK\n",
      "\n",
      "========================================\n",
      "FINAL VERIFICATION REPORT\n",
      "========================================\n",
      "Total Files Checked: 40\n",
      "Passed: 40\n",
      "Issues: 0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# AUTOMATION START\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Run the Batch Verifier (Counts & Structure)\n",
    "# This quickly checks if the number of variables and labels match.\n",
    "print(\"--- Starting Batch Structure Verification ---\")\n",
    "batch_summary_df = batch_verify_sheet2_variable_and_label_count(inventory, base_path)\n",
    "\n",
    "# Print a quick summary of the batch check\n",
    "if not batch_summary_df.empty:\n",
    "    fails = batch_summary_df[batch_summary_df['Variable_Count_Status'] == 'FAIL']\n",
    "    if not fails.empty:\n",
    "        print(f\"\\n[WARNING] Found {len(fails)} structural failures in the following months:\")\n",
    "        print(fails[['Year', 'Month', 'Variable_Count_Status']])\n",
    "    else:\n",
    "        print(\"\\n[PASS] Structural batch check passed for all files.\")\n",
    "\n",
    "# 2. Run Deep Content Verification (Every Month/Year)\n",
    "# This checks the actual text (labels, descriptions, values) for every file.\n",
    "print(\"\\n--- Starting Deep Content Verification (All Files) ---\")\n",
    "\n",
    "deep_verification_results = []\n",
    "\n",
    "for year, months_data in inventory.items():\n",
    "    for month, files_list in months_data.items():\n",
    "        if month == \"Unmatched\":\n",
    "            continue\n",
    "\n",
    "        print(f\"Verifying: {month} {year}...\", end=\" \")\n",
    "\n",
    "        try:\n",
    "            # --- Load Raw Original ---\n",
    "            # Ensure load_dataset is defined in your environment\n",
    "            original_df = load_dataset(year, month, \"metadata\", sheet_number=1)\n",
    "            \n",
    "            # --- Load Reshaped CSV ---\n",
    "            reshaped_path = os.path.join(\n",
    "                base_path, \n",
    "                \"Metadata Sheet 2 CSV's\", \n",
    "                year, \n",
    "                f\"Sheet2_{month}_{year}.csv\"\n",
    "            )\n",
    "            \n",
    "            if not os.path.exists(reshaped_path):\n",
    "                print(\"SKIPPED (Reshaped file missing)\")\n",
    "                deep_verification_results.append({\"Year\": year, \"Month\": month, \"Status\": \"Missing File\"})\n",
    "                continue\n",
    "\n",
    "            reshaped_df = pd.read_csv(reshaped_path, dtype=str).fillna(\"\")\n",
    "            \n",
    "            # --- Run Verification ---\n",
    "            # Using the verify_sheet2_content function from the first code block\n",
    "            result_message = verify_sheet2_content(original_df, reshaped_df)\n",
    "            \n",
    "            if result_message == \"SUCCESS\":\n",
    "                print(\"OK\")\n",
    "                deep_verification_results.append({\"Year\": year, \"Month\": month, \"Status\": \"PASS\"})\n",
    "            else:\n",
    "                print(\"MISMATCH FOUND\")\n",
    "                print(f\"   -> {result_message}\")\n",
    "                deep_verification_results.append({\"Year\": year, \"Month\": month, \"Status\": \"FAIL\", \"Error\": result_message})\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR ({e})\")\n",
    "            deep_verification_results.append({\"Year\": year, \"Month\": month, \"Status\": \"ERROR\", \"Error\": str(e)})\n",
    "\n",
    "# --- Final Report ---\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"FINAL VERIFICATION REPORT\")\n",
    "print(\"=\"*40)\n",
    "results_df = pd.DataFrame(deep_verification_results)\n",
    "\n",
    "if not results_df.empty:\n",
    "    pass_count = len(results_df[results_df['Status'] == 'PASS'])\n",
    "    fail_count = len(results_df[results_df['Status'] != 'PASS'])\n",
    "    print(f\"Total Files Checked: {len(results_df)}\")\n",
    "    print(f\"Passed: {pass_count}\")\n",
    "    print(f\"Issues: {fail_count}\")\n",
    "\n",
    "    if fail_count > 0:\n",
    "        print(\"\\nFiles with Issues:\")\n",
    "        print(results_df[results_df['Status'] != 'PASS'][['Year', 'Month', 'Status']])\n",
    "else:\n",
    "    print(\"No files were processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39499d9a",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e67a98",
   "metadata": {},
   "source": [
    "## Sheet 1 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "96788a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(year, month, filetype=\"survey\"):\n",
    "    \"\"\"\n",
    "    Locates and loads a dataset file (CSV or Excel) from the global inventory\n",
    "    based on the year, month, and requested type.\n",
    "    \"\"\"\n",
    "    # Relies on the global 'inventory' dictionary existing in your notebook\n",
    "    if year not in inventory or month not in inventory[year]:\n",
    "        raise ValueError(f\"Error: No records found in inventory for {month} {year}.\")\n",
    "\n",
    "\n",
    "    files = inventory[year][month]\n",
    "\n",
    "\n",
    "    # Locate the specific file type\n",
    "    found_file = next((f for f in files if f['filetype'] == filetype), None)\n",
    "\n",
    "\n",
    "    if not found_file:\n",
    "        raise FileNotFoundError(f\"Error: No {filetype} file found for {month} {year}.\")\n",
    "\n",
    "\n",
    "    # Construct the full file path using the global base_path\n",
    "    file_path = os.path.join(base_path, year, found_file['filename'])\n",
    "\n",
    "\n",
    "    # Load appropriate file format based on type\n",
    "    if filetype == \"survey\":\n",
    "        return pd.read_csv(file_path, low_memory=False)\n",
    "    else:\n",
    "        return pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_clean_sheet1(year, month):\n",
    "    \"\"\"\n",
    "    Loads the processed variable definitions (Sheet 1) from the\n",
    "    'Metadata Sheet 1 CSV's' folder in Google Drive.\n",
    "    \"\"\"\n",
    "    folder_name = \"Metadata Sheet 1 CSV's\"\n",
    "    filename = f\"Sheet1_{month}_{year}.csv\"\n",
    "    file_path = os.path.join(base_path, folder_name, year, filename)\n",
    "\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Error: Processed metadata file not found at {file_path}\")\n",
    "\n",
    "\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def apply_metadata_headers(survey_df, metadata_sheet1_df, year=\"Unknown\", month=\"Survey\"):\n",
    "    \"\"\"\n",
    "    Renames the columns of the raw survey dataset to human-readable labels\n",
    "    using the provided metadata definitions. Prints a formal status report.\n",
    "    \"\"\"\n",
    "    # 1. Standardization\n",
    "    metadata_sheet1_df['Variable'] = metadata_sheet1_df['Variable'].astype(str).str.strip()\n",
    "    metadata_sheet1_df['Description'] = metadata_sheet1_df['Description'].astype(str).str.strip()\n",
    "\n",
    "\n",
    "    # 2. Map Generation\n",
    "    header_map = dict(zip(metadata_sheet1_df['Variable'], metadata_sheet1_df['Description']))\n",
    "\n",
    "\n",
    "    # 3. Analysis\n",
    "    original_cols = set(survey_df.columns)\n",
    "    mapped_cols = set(header_map.keys())\n",
    "\n",
    "\n",
    "    translated_cols = original_cols.intersection(mapped_cols)\n",
    "    untranslated_cols = original_cols - mapped_cols\n",
    "\n",
    "\n",
    "    total_columns = len(original_cols)\n",
    "    translated_count = len(translated_cols)\n",
    "    untranslated_count = len(untranslated_cols)\n",
    "\n",
    "\n",
    "    # 4. Execution\n",
    "    renamed_df = survey_df.rename(columns=header_map)\n",
    "\n",
    "\n",
    "    # 5. Reporting\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"METADATA TRANSLATION REPORT: {month.upper()} {year}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total Columns Detected:       {total_columns}\")\n",
    "    print(f\"Successfully Decoded:         {translated_count}\")\n",
    "    print(f\"Remaining as Raw Codes:       {untranslated_count}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "    if untranslated_count == 0:\n",
    "        print(\"Status: SUCCESS (100% Metadata Coverage)\")\n",
    "        print(\"All column headers have been successfully translated to descriptions.\")\n",
    "    else:\n",
    "        print(\"Status: PARTIAL SUCCESS\")\n",
    "        print(\"The following columns retained their original codes because\")\n",
    "        print(\"no matching definition was found in the metadata library:\")\n",
    "        # Sort the list for easier reading\n",
    "        print(f\"\\nList of Untranslated Codes: {sorted(list(untranslated_cols))}\")\n",
    "\n",
    "\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "    return renamed_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb9efd",
   "metadata": {},
   "source": [
    "## Automation for Sheet 1 Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47d6fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch_header_translation(inventory, base_path):\n",
    "    \"\"\"\n",
    "    Iterates through the inventory, applies header translation to all survey CSVs,\n",
    "    and saves the results to a temporary output folder.\n",
    "    \"\"\"\n",
    "    output_folder_name = \"Header Encoded Surveys\"\n",
    "    output_base_path = os.path.join(base_path, output_folder_name)\n",
    "    os.makedirs(output_base_path, exist_ok=True)\n",
    "\n",
    "\n",
    "    print(\"================================================\")\n",
    "    print(\"STARTING BATCH HEADER TRANSLATION\")\n",
    "    print(f\"Output Directory: {output_base_path}\")\n",
    "    print(\"================================================\\n\")\n",
    "\n",
    "\n",
    "    success_count = 0\n",
    "    skip_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "\n",
    "    # Loop through the existing 'inventory' dictionary\n",
    "    for year in sorted(inventory.keys()):\n",
    "       \n",
    "        # Create Year subfolder in output directory\n",
    "        year_output_path = os.path.join(output_base_path, year)\n",
    "        os.makedirs(year_output_path, exist_ok=True)\n",
    "       \n",
    "        for month in inventory[year].keys():\n",
    "            if month == \"Unmatched\": continue\n",
    "           \n",
    "            print(f\"Processing: {month.upper()} {year}...\")\n",
    "           \n",
    "            try:\n",
    "                # 1. Check if a raw survey CSV exists for this month\n",
    "                files_list = inventory[year][month]\n",
    "                survey_file_data = next((f for f in files_list if f['filetype'] == 'survey'), None)\n",
    "               \n",
    "                if not survey_file_data:\n",
    "                    print(\"   [SKIP] No raw survey CSV found.\")\n",
    "                    skip_count += 1\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # 2. Load Data\n",
    "                # We use the load functions defined above\n",
    "                raw_survey = load_dataset(year, month, \"survey\")\n",
    "               \n",
    "                # This will raise FileNotFoundError if the clean sheet 1 doesn't exist\n",
    "                clean_metadata = load_clean_sheet1(year, month)\n",
    "               \n",
    "                # 3. Translate\n",
    "                # We pass year/month explicitly so the report title is correct\n",
    "                decoded_df = apply_metadata_headers(raw_survey, clean_metadata, year, month)\n",
    "               \n",
    "                # 4. Save to \"Temporary\" Folder using ORIGINAL FILENAME\n",
    "                # We extract the actual filename (e.g. \"JANUARY_2018.CSV\") from the inventory data\n",
    "                original_filename = survey_file_data['filename']\n",
    "                save_path = os.path.join(year_output_path, original_filename)\n",
    "               \n",
    "                decoded_df.to_csv(save_path, index=False)\n",
    "                print(f\"   [OK] Saved File: {original_filename}\")\n",
    "                success_count += 1\n",
    "               \n",
    "            except FileNotFoundError:\n",
    "                print(f\"   [SKIP] Missing Metadata Sheet 1 CSV for {month} {year}.\")\n",
    "                skip_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"   [ERROR] Failed to process: {e}\")\n",
    "                error_count += 1\n",
    "           \n",
    "            print(\"-\" * 40)\n",
    "\n",
    "\n",
    "    print(\"\\n================================================\")\n",
    "    print(\"BATCH PROCESS COMPLETE\")\n",
    "    print(f\"   Successful: {success_count}\")\n",
    "    print(f\"   Skipped:    {skip_count}\")\n",
    "    print(f\"   Errors:     {error_count}\")\n",
    "    print(\"================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ea1bef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "STARTING BATCH HEADER TRANSLATION\n",
      "Output Directory: G:\\My Drive\\Labor Force Survey\\Temporary Header Encoded Surveys\n",
      "================================================\n",
      "\n",
      "Processing: JANUARY 2018...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JANUARY 2018\n",
      "============================================================\n",
      "Total Columns Detected:       50\n",
      "Successfully Decoded:         50\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JANUARY_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2018...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JULY 2018\n",
      "============================================================\n",
      "Total Columns Detected:       51\n",
      "Successfully Decoded:         51\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JULY_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2018...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: APRIL 2018\n",
      "============================================================\n",
      "Total Columns Detected:       50\n",
      "Successfully Decoded:         50\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: APRIL_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2018...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: OCTOBER 2018\n",
      "============================================================\n",
      "Total Columns Detected:       51\n",
      "Successfully Decoded:         51\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: OCTOBER_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2019...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: APRIL 2019\n",
      "============================================================\n",
      "Total Columns Detected:       49\n",
      "Successfully Decoded:         49\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: APRIL_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2019...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JANUARY 2019\n",
      "============================================================\n",
      "Total Columns Detected:       49\n",
      "Successfully Decoded:         49\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JANUARY_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2019...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JULY 2019\n",
      "============================================================\n",
      "Total Columns Detected:       49\n",
      "Successfully Decoded:         49\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JULY_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2019...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: OCTOBER 2019\n",
      "============================================================\n",
      "Total Columns Detected:       49\n",
      "Successfully Decoded:         49\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: OCTOBER_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: APRIL 2022\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: APRIL_2022.csv\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: AUGUST 2022\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: AUGUST_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: DECEMBER 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: DECEMBER 2022\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: DECEMBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: FEBRUARY 2022\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: FEBRUARY_2022.csv\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JANUARY 2022\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JANUARY_2022.csv\n",
      "----------------------------------------\n",
      "Processing: JULY 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JULY 2022\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JULY_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: JUNE 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JUNE 2022\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JUNE_2022.csv\n",
      "----------------------------------------\n",
      "Processing: MARCH 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: MARCH 2022\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: MARCH_2022.csv\n",
      "----------------------------------------\n",
      "Processing: MAY 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: MAY 2022\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: MAY_2022.csv\n",
      "----------------------------------------\n",
      "Processing: NOVEMBER 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: NOVEMBER 2022\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: NOVEMBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: OCTOBER 2022\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: OCTOBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: SEPTEMBER 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: SEPTEMBER 2022\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: SEPTEMBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: APRIL 2023\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: APRIL_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: AUGUST 2023\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: AUGUST_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: DECEMBER 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: DECEMBER 2023\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: DECEMBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: FEBRUARY 2023\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: FEBRUARY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JANUARY 2023\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JANUARY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JULY 2023\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JULY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: JUNE 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JUNE 2023\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JUNE_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: MARCH 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: MARCH 2023\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: MARCH_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: NOVEMBER 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: NOVEMBER 2023\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: NOVEMBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: OCTOBER 2023\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: OCTOBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: SEPTEMBER 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: SEPTEMBER 2023\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: SEPTEMBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: MAY 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: MAY 2023\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: MAY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: FEBRUARY 2024\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: FEBRUARY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: APRIL 2024\n",
      "============================================================\n",
      "Total Columns Detected:       51\n",
      "Successfully Decoded:         51\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: APRIL_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JANUARY 2024\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JANUARY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: AUGUST 2024\n",
      "============================================================\n",
      "Total Columns Detected:       40\n",
      "Successfully Decoded:         40\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: AUGUST_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JULY 2024\n",
      "============================================================\n",
      "Total Columns Detected:       51\n",
      "Successfully Decoded:         51\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JULY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: MARCH 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: MARCH 2024\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: MARCH_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: MAY 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: MAY 2024\n",
      "============================================================\n",
      "Total Columns Detected:       40\n",
      "Successfully Decoded:         40\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: MAY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: JUNE 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JUNE 2024\n",
      "============================================================\n",
      "Total Columns Detected:       40\n",
      "Successfully Decoded:         40\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JUNE_2024.CSV\n",
      "----------------------------------------\n",
      "\n",
      "================================================\n",
      "BATCH PROCESS COMPLETE\n",
      "   Successful: 40\n",
      "   Skipped:    0\n",
      "   Errors:     0\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if 'inventory' in locals() and 'base_path' in locals():\n",
    "        run_batch_header_translation(inventory, base_path)\n",
    "    else:\n",
    "        print(\"Skipping execution: 'inventory' or 'base_path' not found in scope.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8396c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_header_decoding_integrity(inventory, base_path):\n",
    "    \"\"\"\n",
    "    Checks if all raw survey columns have been successfully decoded\n",
    "    using metadata Sheet 1.\n",
    "    \n",
    "    Returns a DataFrame with:\n",
    "    Year | Month | Raw Headers Count | Decoded Headers Count | Integrity Status\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for year, months_data in inventory.items():\n",
    "        for month, files_list in months_data.items():\n",
    "\n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # ---- Load raw survey ----\n",
    "                raw_df = load_dataset(year, month, \"survey\")\n",
    "                raw_headers = list(raw_df.columns)\n",
    "                raw_count = len(raw_headers)\n",
    "\n",
    "                # ---- Load decoded metadata Sheet 1 ----\n",
    "                meta_df = load_clean_sheet1(year, month)\n",
    "                meta_df['Variable'] = meta_df['Variable'].astype(str).str.strip()\n",
    "                meta_df['Description'] = meta_df['Description'].astype(str).str.strip()\n",
    "\n",
    "                # Build mapping dict\n",
    "                header_map = dict(zip(meta_df['Variable'], meta_df['Description']))\n",
    "\n",
    "                # ---- Count decoded columns ----\n",
    "                decoded_count = sum(col in header_map for col in raw_headers)\n",
    "\n",
    "                # ---- Determine integrity ----\n",
    "                status = \"PASS\" if raw_count == decoded_count else \"FAIL\"\n",
    "\n",
    "                results.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Raw Headers Count\": raw_count,\n",
    "                    \"Decoded Headers Count\": decoded_count,\n",
    "                    \"Integrity Status\": status\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                # Any error â†’ FAIL\n",
    "                results.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Raw Headers Count\": \"ERROR\",\n",
    "                    \"Decoded Headers Count\": \"ERROR\",\n",
    "                    \"Integrity Status\": f\"FAIL ({e})\"\n",
    "                })\n",
    "                continue\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "    print(\"\\n===== HEADER DECODING INTEGRITY CHECK COMPLETE =====\")\n",
    "    \n",
    "    total_failures = (result_df[\"Integrity Status\"] != \"PASS\").sum()\n",
    "\n",
    "    if total_failures == 0:\n",
    "        print(\"SUCCESS: All survey column headers have been fully decoded.\")\n",
    "    else:\n",
    "        print(f\"Completed with {total_failures} months failing integrity checks.\")\n",
    "\n",
    "    print(\"====================================================\\n\")\n",
    "\n",
    "    return result_df.sort_values([\"Year\", \"Month\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4982484",
   "metadata": {},
   "source": [
    "#### Checking if all column headers were decoded successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "df006e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== HEADER DECODING INTEGRITY CHECK COMPLETE =====\n",
      "SUCCESS: All survey column headers have been fully decoded.\n",
      "====================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Raw Headers Count</th>\n",
       "      <th>Decoded Headers Count</th>\n",
       "      <th>Integrity Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>July</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>April</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>January</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>July</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>October</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022</td>\n",
       "      <td>April</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>August</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022</td>\n",
       "      <td>December</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022</td>\n",
       "      <td>February</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022</td>\n",
       "      <td>January</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022</td>\n",
       "      <td>July</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022</td>\n",
       "      <td>June</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022</td>\n",
       "      <td>March</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022</td>\n",
       "      <td>May</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022</td>\n",
       "      <td>November</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022</td>\n",
       "      <td>October</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022</td>\n",
       "      <td>September</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023</td>\n",
       "      <td>April</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023</td>\n",
       "      <td>August</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023</td>\n",
       "      <td>December</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023</td>\n",
       "      <td>February</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023</td>\n",
       "      <td>January</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023</td>\n",
       "      <td>July</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023</td>\n",
       "      <td>June</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023</td>\n",
       "      <td>March</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023</td>\n",
       "      <td>May</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023</td>\n",
       "      <td>November</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023</td>\n",
       "      <td>October</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023</td>\n",
       "      <td>September</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2024</td>\n",
       "      <td>April</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2024</td>\n",
       "      <td>August</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2024</td>\n",
       "      <td>February</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2024</td>\n",
       "      <td>January</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024</td>\n",
       "      <td>July</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2024</td>\n",
       "      <td>June</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2024</td>\n",
       "      <td>March</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year      Month  Raw Headers Count  Decoded Headers Count Integrity Status\n",
       "0   2018      April                 50                     50             PASS\n",
       "1   2018    January                 50                     50             PASS\n",
       "2   2018       July                 51                     51             PASS\n",
       "3   2018    October                 51                     51             PASS\n",
       "4   2019      April                 49                     49             PASS\n",
       "5   2019    January                 49                     49             PASS\n",
       "6   2019       July                 49                     49             PASS\n",
       "7   2019    October                 49                     49             PASS\n",
       "8   2022      April                 52                     52             PASS\n",
       "9   2022     August                 42                     42             PASS\n",
       "10  2022   December                 42                     42             PASS\n",
       "11  2022   February                 41                     41             PASS\n",
       "12  2022    January                 52                     52             PASS\n",
       "13  2022       July                 52                     52             PASS\n",
       "14  2022       June                 42                     42             PASS\n",
       "15  2022      March                 41                     41             PASS\n",
       "16  2022        May                 42                     42             PASS\n",
       "17  2022   November                 42                     42             PASS\n",
       "18  2022    October                 52                     52             PASS\n",
       "19  2022  September                 42                     42             PASS\n",
       "20  2023      April                 52                     52             PASS\n",
       "21  2023     August                 41                     41             PASS\n",
       "22  2023   December                 41                     41             PASS\n",
       "23  2023   February                 42                     42             PASS\n",
       "24  2023    January                 52                     52             PASS\n",
       "25  2023       July                 52                     52             PASS\n",
       "26  2023       June                 42                     42             PASS\n",
       "27  2023      March                 42                     42             PASS\n",
       "28  2023        May                 42                     42             PASS\n",
       "29  2023   November                 41                     41             PASS\n",
       "30  2023    October                 52                     52             PASS\n",
       "31  2023  September                 41                     41             PASS\n",
       "32  2024      April                 51                     51             PASS\n",
       "33  2024     August                 40                     40             PASS\n",
       "34  2024   February                 41                     41             PASS\n",
       "35  2024    January                 52                     52             PASS\n",
       "36  2024       July                 51                     51             PASS\n",
       "37  2024       June                 40                     40             PASS\n",
       "38  2024      March                 41                     41             PASS\n",
       "39  2024        May                 40                     40             PASS"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrity_df = verify_header_decoding_integrity(inventory, base_path)\n",
    "integrity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b1331",
   "metadata": {},
   "source": [
    "## Sheet 2 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "c16b079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_sheet2(base_path, year, month):\n",
    "    \"\"\"Loads the Clean Sheet 2 Metadata.\"\"\"\n",
    "    path = os.path.join(base_path, \"Metadata Sheet 2 CSV's\", year, f\"Sheet2_{month}_{year}.csv\")\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Metadata not found at: {path}\")\n",
    "    return pd.read_csv(path, dtype=str)\n",
    "\n",
    "\n",
    "def find_target_column(survey_columns, meta_desc):\n",
    "    \"\"\"\n",
    "    Smart Matcher: Handles 'Highest Grade' vs 'C07-Highest Grade Completed'.\n",
    "    \"\"\"\n",
    "    if pd.isna(meta_desc): return None\n",
    "    meta_desc = str(meta_desc).strip()\n",
    "   \n",
    "    # 1. Exact Match\n",
    "    if meta_desc in survey_columns: return meta_desc\n",
    "   \n",
    "    # 2. Metadata has prefix (Meta=\"C06-Status\" -> Survey=\"Status\")\n",
    "    clean_meta = re.sub(r'^C\\d+[\\s\\-_]+', '', meta_desc, flags=re.IGNORECASE).strip()\n",
    "    if clean_meta in survey_columns: return clean_meta\n",
    "       \n",
    "    # 3. Survey has prefix (Meta=\"Status\" -> Survey=\"C06-Status\")\n",
    "    for col in survey_columns:\n",
    "        if col.endswith(meta_desc):\n",
    "            prefix = col[:-len(meta_desc)].strip()\n",
    "            if re.search(r'^C\\d+[\\s\\-_]*$', prefix, re.IGNORECASE) or prefix == \"\":\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "\n",
    "def decode_survey_safe(survey_df, meta_df):\n",
    "    \"\"\"\n",
    "    Decodes the entire survey using the Smart Matcher and Safe Logic.\n",
    "    \"\"\"\n",
    "    unique_vars = meta_df['Variable'].unique()\n",
    "    decoded_count = 0\n",
    "    survey_cols = list(survey_df.columns)\n",
    "   \n",
    "    for var_code in unique_vars:\n",
    "        subset = meta_df[meta_df['Variable'] == var_code].copy()\n",
    "       \n",
    "        if subset['Description'].isnull().all(): continue\n",
    "        raw_desc = subset['Description'].dropna().iloc[0].strip()\n",
    "       \n",
    "        target_col = find_target_column(survey_cols, raw_desc)\n",
    "        if not target_col: continue\n",
    "           \n",
    "        mask_zeros = subset['Label'].astype(str).isin(['0', '0.0', '0.00', 'nan', 'NaN'])\n",
    "        if mask_zeros.all(): continue\n",
    "           \n",
    "        lookup = {}\n",
    "        for _, row in subset.iterrows():\n",
    "            try:\n",
    "                label = row['Label']\n",
    "                if str(label) in ['0', '0.0', 'nan']: continue\n",
    "               \n",
    "                min_v = float(row['min_value'])\n",
    "                max_v = float(row['max_value'])\n",
    "               \n",
    "                if max_v > min_v and max_v != 0:\n",
    "                    for c in range(int(min_v), int(max_v) + 1): lookup[c] = label\n",
    "                else:\n",
    "                    lookup[int(min_v)] = label\n",
    "            except: continue\n",
    "           \n",
    "        if not lookup: continue\n",
    "\n",
    "\n",
    "        def safe_map(val):\n",
    "            try: return lookup.get(int(float(val)), val)\n",
    "            except: return val\n",
    "           \n",
    "        survey_df[target_col] = survey_df[target_col].apply(safe_map)\n",
    "        decoded_count += 1\n",
    "\n",
    "\n",
    "    return survey_df, decoded_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc846431",
   "metadata": {},
   "source": [
    "## Automation for Sheet 2 Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "36b06bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch_decoding(base_path):\n",
    "    \"\"\"\n",
    "    Scans the folder, decodes all files, and saves to Fully Decoded.\n",
    "    \"\"\"\n",
    "    # --- FOLDER CONFIGURATION ---\n",
    "    input_folder_name = \"Header Encoded Surveys\"\n",
    "    output_folder_name = \"Fully Decoded Surveys\"\n",
    "   \n",
    "    input_root = os.path.join(base_path, input_folder_name)\n",
    "    output_root = os.path.join(base_path, output_folder_name)\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "   \n",
    "    print(\"================================================\")\n",
    "    print(\"STARTING BATCH VALUE DECODING\")\n",
    "    print(f\"Source: {input_root}\")\n",
    "    print(f\"Dest:   {output_root}\")\n",
    "    print(\"================================================\\n\")\n",
    "   \n",
    "    month_pattern = re.compile(r\"(JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)\", re.IGNORECASE)\n",
    "   \n",
    "    if not os.path.exists(input_root):\n",
    "        print(f\"Error: Input folder not found: {input_root}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    year_folders = [f for f in os.listdir(input_root) if f.isdigit() and os.path.isdir(os.path.join(input_root, f))]\n",
    "   \n",
    "    success = 0\n",
    "    errors = 0\n",
    "   \n",
    "    for year in sorted(year_folders):\n",
    "        year_in = os.path.join(input_root, year)\n",
    "        year_out = os.path.join(output_root, year)\n",
    "        os.makedirs(year_out, exist_ok=True)\n",
    "       \n",
    "        files = [f for f in os.listdir(year_in) if f.lower().endswith(\".csv\")]\n",
    "       \n",
    "        for filename in files:\n",
    "            match = month_pattern.search(filename)\n",
    "            if not match: continue\n",
    "            month = match.group(1).capitalize()\n",
    "           \n",
    "            print(f\"Processing: {month.upper()} {year}...\")\n",
    "           \n",
    "            try:\n",
    "                # 1. Load Survey\n",
    "                survey_path = os.path.join(year_in, filename)\n",
    "                df_survey = pd.read_csv(survey_path, low_memory=False)\n",
    "               \n",
    "                # 2. Load Metadata\n",
    "                df_meta = load_clean_sheet2(base_path, year, month)\n",
    "               \n",
    "                # 3. Decode (CALLS THE FUNCTION ABOVE)\n",
    "                df_final, count = decode_survey_safe(df_survey, df_meta)\n",
    "               \n",
    "                # 4. Save\n",
    "                save_path = os.path.join(year_out, filename)\n",
    "                df_final.to_csv(save_path, index=False)\n",
    "               \n",
    "                print(f\"   [OK] Decoded {count} columns.\")\n",
    "                print(f\"   [SAVED] {filename}\")\n",
    "                success += 1\n",
    "               \n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"   [SKIP] Metadata missing: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   [ERROR] {e}\")\n",
    "                errors += 1\n",
    "           \n",
    "            print(\"-\" * 40)\n",
    "\n",
    "\n",
    "    print(f\"\\nCOMPLETED. Success: {success} | Errors: {errors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bc76e3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "STARTING BATCH VALUE DECODING\n",
      "Source: G:\\My Drive\\Labor Force Survey\\Header Encoded Surveys\n",
      "Dest:   G:\\My Drive\\Labor Force Survey\\Fully Decoded Surveys\n",
      "================================================\n",
      "\n",
      "Processing: JANUARY 2018...\n",
      "   [OK] Decoded 39 columns.\n",
      "   [SAVED] JANUARY_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2018...\n",
      "   [OK] Decoded 37 columns.\n",
      "   [SAVED] JULY_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2018...\n",
      "   [OK] Decoded 37 columns.\n",
      "   [SAVED] APRIL_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2018...\n",
      "   [OK] Decoded 39 columns.\n",
      "   [SAVED] OCTOBER_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2019...\n",
      "   [OK] Decoded 39 columns.\n",
      "   [SAVED] APRIL_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2019...\n",
      "   [OK] Decoded 38 columns.\n",
      "   [SAVED] JANUARY_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2019...\n",
      "   [OK] Decoded 41 columns.\n",
      "   [SAVED] JULY_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2019...\n",
      "   [OK] Decoded 41 columns.\n",
      "   [SAVED] OCTOBER_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2022...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] APRIL_2022.csv\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2022...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] AUGUST_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: DECEMBER 2022...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] DECEMBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2022...\n",
      "   [OK] Decoded 31 columns.\n",
      "   [SAVED] FEBRUARY_2022.csv\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2022...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] JANUARY_2022.csv\n",
      "----------------------------------------\n",
      "Processing: JULY 2022...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] JULY_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: JUNE 2022...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] JUNE_2022.csv\n",
      "----------------------------------------\n",
      "Processing: MARCH 2022...\n",
      "   [OK] Decoded 31 columns.\n",
      "   [SAVED] MARCH_2022.csv\n",
      "----------------------------------------\n",
      "Processing: MAY 2022...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] MAY_2022.csv\n",
      "----------------------------------------\n",
      "Processing: NOVEMBER 2022...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] NOVEMBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2022...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] OCTOBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: SEPTEMBER 2022...\n",
      "   [OK] Decoded 33 columns.\n",
      "   [SAVED] SEPTEMBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2023...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] APRIL_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2023...\n",
      "   [OK] Decoded 33 columns.\n",
      "   [SAVED] AUGUST_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: DECEMBER 2023...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] DECEMBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2023...\n",
      "   [OK] Decoded 33 columns.\n",
      "   [SAVED] FEBRUARY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2023...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] JANUARY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2023...\n",
      "   [OK] Decoded 45 columns.\n",
      "   [SAVED] JULY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: JUNE 2023...\n",
      "   [OK] Decoded 33 columns.\n",
      "   [SAVED] JUNE_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: MARCH 2023...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] MARCH_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: NOVEMBER 2023...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] NOVEMBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2023...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] OCTOBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: SEPTEMBER 2023...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] SEPTEMBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: MAY 2023...\n",
      "   [OK] Decoded 33 columns.\n",
      "   [SAVED] MAY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2024...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] FEBRUARY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2024...\n",
      "   [OK] Decoded 43 columns.\n",
      "   [SAVED] APRIL_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2024...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] JANUARY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2024...\n",
      "   [OK] Decoded 31 columns.\n",
      "   [SAVED] AUGUST_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2024...\n",
      "   [OK] Decoded 43 columns.\n",
      "   [SAVED] JULY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: MARCH 2024...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] MARCH_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: MAY 2024...\n",
      "   [OK] Decoded 33 columns.\n",
      "   [SAVED] MAY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: JUNE 2024...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] JUNE_2024.CSV\n",
      "----------------------------------------\n",
      "\n",
      "COMPLETED. Success: 40 | Errors: 0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    run_batch_decoding(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "145e4e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def verify_decoded_record_integrity(base_path):\n",
    "    \"\"\"\n",
    "    Checks if all raw survey records (rows) match the fully decoded records.\n",
    "    \n",
    "    Compares:\n",
    "    - Raw Total Records (Header Encoded Surveys)\n",
    "    - Decoded Total Records (Fully Decoded Surveys)\n",
    "    \n",
    "    Returns: DataFrame summary\n",
    "    \"\"\"\n",
    "\n",
    "    raw_root = os.path.join(base_path, \"Header Encoded Surveys\")\n",
    "    decoded_root = os.path.join(base_path, \"Fully Decoded Surveys\")\n",
    "\n",
    "    if not os.path.exists(raw_root):\n",
    "        raise FileNotFoundError(f\"Header Encoded Surveys folder missing: {raw_root}\")\n",
    "    if not os.path.exists(decoded_root):\n",
    "        raise FileNotFoundError(f\"Fully Decoded Surveys folder missing: {decoded_root}\")\n",
    "\n",
    "    # Detect months inside filenames\n",
    "    month_pattern = re.compile(\n",
    "        r\"(JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Loop through year folders\n",
    "    year_folders = [y for y in os.listdir(raw_root) if y.isdigit()]\n",
    "\n",
    "    for year in sorted(year_folders):\n",
    "        year_raw_folder = os.path.join(raw_root, year)\n",
    "        year_dec_folder = os.path.join(decoded_root, year)\n",
    "\n",
    "        if not os.path.exists(year_dec_folder):\n",
    "            # If missing decoded folder, mark all as FAIL\n",
    "            files = [f for f in os.listdir(year_raw_folder) if f.lower().endswith(\".csv\")]\n",
    "            for f in files:\n",
    "                match = month_pattern.search(f)\n",
    "                if not match: continue\n",
    "                month = match.group(1).capitalize()\n",
    "\n",
    "                results.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Raw Total Records\": \"N/A\",\n",
    "                    \"Decoded Total Records\": \"Missing\",\n",
    "                    \"Integrity Status\": \"FAIL\"\n",
    "                })\n",
    "            continue\n",
    "\n",
    "        raw_files = [f for f in os.listdir(year_raw_folder) if f.lower().endswith(\".csv\")]\n",
    "\n",
    "        for filename in raw_files:\n",
    "\n",
    "            match = month_pattern.search(filename)\n",
    "            if not match:\n",
    "                continue\n",
    "\n",
    "            month = match.group(1).capitalize()\n",
    "\n",
    "            raw_path = os.path.join(year_raw_folder, filename)\n",
    "            decoded_path = os.path.join(year_dec_folder, filename)\n",
    "\n",
    "            try:\n",
    "                # Load raw records\n",
    "                raw_df = pd.read_csv(raw_path, low_memory=False)\n",
    "                raw_count = len(raw_df)\n",
    "\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Raw Total Records\": f\"ERROR: {e}\",\n",
    "                    \"Decoded Total Records\": \"N/A\",\n",
    "                    \"Integrity Status\": \"FAIL\"\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            # Load decoded records\n",
    "            if not os.path.exists(decoded_path):\n",
    "                results.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Raw Total Records\": raw_count,\n",
    "                    \"Decoded Total Records\": \"Missing\",\n",
    "                    \"Integrity Status\": \"FAIL\"\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                decoded_df = pd.read_csv(decoded_path, low_memory=False)\n",
    "                dec_count = len(decoded_df)\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Raw Total Records\": raw_count,\n",
    "                    \"Decoded Total Records\": f\"ERROR: {e}\",\n",
    "                    \"Integrity Status\": \"FAIL\"\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            # Determine PASS/FAIL\n",
    "            status = \"PASS\" if raw_count == dec_count else \"FAIL\"\n",
    "\n",
    "            results.append({\n",
    "                \"Year\": year,\n",
    "                \"Month\": month,\n",
    "                \"Raw Total Records\": raw_count,\n",
    "                \"Decoded Total Records\": dec_count,\n",
    "                \"Integrity Status\": status\n",
    "            })\n",
    "\n",
    "    summary_df = pd.DataFrame(results)\n",
    "\n",
    "    print(\"\\n===== RECORD DECODING INTEGRITY CHECK COMPLETE =====\")\n",
    "    fails = (summary_df[\"Integrity Status\"] != \"PASS\").sum()\n",
    "\n",
    "    if fails == 0:\n",
    "        print(\"SUCCESS: All decoded surveys match the raw row counts.\")\n",
    "    else:\n",
    "        print(f\"WARNING: {fails} months failed record integrity checks.\")\n",
    "\n",
    "    print(\"====================================================\\n\")\n",
    "\n",
    "    return summary_df.sort_values([\"Year\", \"Month\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5e73c",
   "metadata": {},
   "source": [
    "#### Checking if all records were decoded successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "0e137378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RECORD DECODING INTEGRITY CHECK COMPLETE =====\n",
      "SUCCESS: All decoded surveys match the raw row counts.\n",
      "====================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Raw Total Records</th>\n",
       "      <th>Decoded Total Records</th>\n",
       "      <th>Integrity Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>179815</td>\n",
       "      <td>179815</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>180262</td>\n",
       "      <td>180262</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>July</td>\n",
       "      <td>182956</td>\n",
       "      <td>182956</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>179204</td>\n",
       "      <td>179204</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>April</td>\n",
       "      <td>172284</td>\n",
       "      <td>172284</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>January</td>\n",
       "      <td>181233</td>\n",
       "      <td>181233</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>July</td>\n",
       "      <td>175438</td>\n",
       "      <td>175438</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>October</td>\n",
       "      <td>178067</td>\n",
       "      <td>178067</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022</td>\n",
       "      <td>April</td>\n",
       "      <td>184237</td>\n",
       "      <td>184237</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>August</td>\n",
       "      <td>45054</td>\n",
       "      <td>45054</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022</td>\n",
       "      <td>December</td>\n",
       "      <td>45687</td>\n",
       "      <td>45687</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022</td>\n",
       "      <td>February</td>\n",
       "      <td>45889</td>\n",
       "      <td>45889</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022</td>\n",
       "      <td>January</td>\n",
       "      <td>736746</td>\n",
       "      <td>736746</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022</td>\n",
       "      <td>July</td>\n",
       "      <td>183856</td>\n",
       "      <td>183856</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022</td>\n",
       "      <td>June</td>\n",
       "      <td>45894</td>\n",
       "      <td>45894</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022</td>\n",
       "      <td>March</td>\n",
       "      <td>46154</td>\n",
       "      <td>46154</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022</td>\n",
       "      <td>May</td>\n",
       "      <td>46264</td>\n",
       "      <td>46264</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022</td>\n",
       "      <td>November</td>\n",
       "      <td>45561</td>\n",
       "      <td>45561</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022</td>\n",
       "      <td>October</td>\n",
       "      <td>183602</td>\n",
       "      <td>183602</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022</td>\n",
       "      <td>September</td>\n",
       "      <td>46261</td>\n",
       "      <td>46261</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023</td>\n",
       "      <td>April</td>\n",
       "      <td>181424</td>\n",
       "      <td>181424</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023</td>\n",
       "      <td>August</td>\n",
       "      <td>44999</td>\n",
       "      <td>44999</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023</td>\n",
       "      <td>December</td>\n",
       "      <td>44141</td>\n",
       "      <td>44141</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023</td>\n",
       "      <td>February</td>\n",
       "      <td>47044</td>\n",
       "      <td>47044</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023</td>\n",
       "      <td>January</td>\n",
       "      <td>184113</td>\n",
       "      <td>184113</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023</td>\n",
       "      <td>July</td>\n",
       "      <td>718567</td>\n",
       "      <td>718567</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023</td>\n",
       "      <td>June</td>\n",
       "      <td>46060</td>\n",
       "      <td>46060</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023</td>\n",
       "      <td>March</td>\n",
       "      <td>46212</td>\n",
       "      <td>46212</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023</td>\n",
       "      <td>May</td>\n",
       "      <td>45505</td>\n",
       "      <td>45505</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023</td>\n",
       "      <td>November</td>\n",
       "      <td>44609</td>\n",
       "      <td>44609</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023</td>\n",
       "      <td>October</td>\n",
       "      <td>179173</td>\n",
       "      <td>179173</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023</td>\n",
       "      <td>September</td>\n",
       "      <td>44659</td>\n",
       "      <td>44659</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2024</td>\n",
       "      <td>April</td>\n",
       "      <td>175511</td>\n",
       "      <td>175511</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2024</td>\n",
       "      <td>August</td>\n",
       "      <td>43375</td>\n",
       "      <td>43375</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2024</td>\n",
       "      <td>February</td>\n",
       "      <td>44598</td>\n",
       "      <td>44598</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2024</td>\n",
       "      <td>January</td>\n",
       "      <td>707981</td>\n",
       "      <td>707981</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024</td>\n",
       "      <td>July</td>\n",
       "      <td>173259</td>\n",
       "      <td>173259</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2024</td>\n",
       "      <td>June</td>\n",
       "      <td>43074</td>\n",
       "      <td>43074</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2024</td>\n",
       "      <td>March</td>\n",
       "      <td>44063</td>\n",
       "      <td>44063</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>43717</td>\n",
       "      <td>43717</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year      Month  Raw Total Records  Decoded Total Records Integrity Status\n",
       "0   2018      April             179815                 179815             PASS\n",
       "1   2018    January             180262                 180262             PASS\n",
       "2   2018       July             182956                 182956             PASS\n",
       "3   2018    October             179204                 179204             PASS\n",
       "4   2019      April             172284                 172284             PASS\n",
       "5   2019    January             181233                 181233             PASS\n",
       "6   2019       July             175438                 175438             PASS\n",
       "7   2019    October             178067                 178067             PASS\n",
       "8   2022      April             184237                 184237             PASS\n",
       "9   2022     August              45054                  45054             PASS\n",
       "10  2022   December              45687                  45687             PASS\n",
       "11  2022   February              45889                  45889             PASS\n",
       "12  2022    January             736746                 736746             PASS\n",
       "13  2022       July             183856                 183856             PASS\n",
       "14  2022       June              45894                  45894             PASS\n",
       "15  2022      March              46154                  46154             PASS\n",
       "16  2022        May              46264                  46264             PASS\n",
       "17  2022   November              45561                  45561             PASS\n",
       "18  2022    October             183602                 183602             PASS\n",
       "19  2022  September              46261                  46261             PASS\n",
       "20  2023      April             181424                 181424             PASS\n",
       "21  2023     August              44999                  44999             PASS\n",
       "22  2023   December              44141                  44141             PASS\n",
       "23  2023   February              47044                  47044             PASS\n",
       "24  2023    January             184113                 184113             PASS\n",
       "25  2023       July             718567                 718567             PASS\n",
       "26  2023       June              46060                  46060             PASS\n",
       "27  2023      March              46212                  46212             PASS\n",
       "28  2023        May              45505                  45505             PASS\n",
       "29  2023   November              44609                  44609             PASS\n",
       "30  2023    October             179173                 179173             PASS\n",
       "31  2023  September              44659                  44659             PASS\n",
       "32  2024      April             175511                 175511             PASS\n",
       "33  2024     August              43375                  43375             PASS\n",
       "34  2024   February              44598                  44598             PASS\n",
       "35  2024    January             707981                 707981             PASS\n",
       "36  2024       July             173259                 173259             PASS\n",
       "37  2024       June              43074                  43074             PASS\n",
       "38  2024      March              44063                  44063             PASS\n",
       "39  2024        May              43717                  43717             PASS"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_integrity_df = verify_decoded_record_integrity(base_path)\n",
    "record_integrity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d8ab8",
   "metadata": {},
   "source": [
    "### Coverage Scanner in Metadata and Survey "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32510426",
   "metadata": {},
   "source": [
    "To check whether columns with values not found in metadata stayed unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "02a4e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFICATION: APRIL 2018\n",
      "======================================================================\n",
      "Total Columns:      50\n",
      "Successful Decodes: 40\n",
      "Correctly Numeric:  10\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JANUARY 2018\n",
      "======================================================================\n",
      "Total Columns:      50\n",
      "Successful Decodes: 41\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JULY 2018\n",
      "======================================================================\n",
      "Total Columns:      51\n",
      "Successful Decodes: 40\n",
      "Correctly Numeric:  11\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: OCTOBER 2018\n",
      "======================================================================\n",
      "Total Columns:      51\n",
      "Successful Decodes: 41\n",
      "Correctly Numeric:  10\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: APRIL 2019\n",
      "======================================================================\n",
      "Total Columns:      49\n",
      "Successful Decodes: 41\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JANUARY 2019\n",
      "======================================================================\n",
      "Total Columns:      49\n",
      "Successful Decodes: 41\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JULY 2019\n",
      "======================================================================\n",
      "Total Columns:      49\n",
      "Successful Decodes: 41\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: OCTOBER 2019\n",
      "======================================================================\n",
      "Total Columns:      49\n",
      "Successful Decodes: 41\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: APRIL 2022\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 45\n",
      "Correctly Numeric:  7\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: AUGUST 2022\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: DECEMBER 2022\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: FEBRUARY 2022\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  8\n",
      "Failures:           1\n",
      "\n",
      "WARNING: 1 columns failed to decode:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column</th>\n",
       "      <th>In_Metadata</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Survey Month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>FAILED (Should be Text)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFICATION: JANUARY 2022\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 44\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JULY 2022\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 45\n",
      "Correctly Numeric:  7\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JUNE 2022\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: MARCH 2022\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 31\n",
      "Correctly Numeric:  9\n",
      "Failures:           1\n",
      "\n",
      "WARNING: 1 columns failed to decode:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column</th>\n",
       "      <th>In_Metadata</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Survey Month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>FAILED (Should be Text)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFICATION: MAY 2022\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: NOVEMBER 2022\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 34\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: OCTOBER 2022\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 44\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: SEPTEMBER 2022\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: APRIL 2023\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 44\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: AUGUST 2023\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: DECEMBER 2023\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: FEBRUARY 2023\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 34\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JANUARY 2023\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 44\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JULY 2023\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 45\n",
      "Correctly Numeric:  7\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JUNE 2023\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: MARCH 2023\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: MAY 2023\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: NOVEMBER 2023\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: OCTOBER 2023\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 44\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: SEPTEMBER 2023\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: APRIL 2024\n",
      "======================================================================\n",
      "Total Columns:      51\n",
      "Successful Decodes: 43\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: AUGUST 2024\n",
      "======================================================================\n",
      "Total Columns:      40\n",
      "Successful Decodes: 31\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: FEBRUARY 2024\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JANUARY 2024\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 44\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JULY 2024\n",
      "======================================================================\n",
      "Total Columns:      51\n",
      "Successful Decodes: 43\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JUNE 2024\n",
      "======================================================================\n",
      "Total Columns:      40\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: MARCH 2024\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: MAY 2024\n",
      "======================================================================\n",
      "Total Columns:      40\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def check_value_decoding_integrity_smart(base_path):\n",
    "    \"\"\"\n",
    "    Verifies if variables were decoded correctly.\n",
    "    \n",
    "    IMPROVEMENT:\n",
    "    - Distinguishes between \"Failed Decoding\" vs \"Quantitative Variables\" (e.g. Household Size).\n",
    "    - If a variable is in metadata but the labels are numbers (or 0), it marks it as OK.\n",
    "    \"\"\"\n",
    "    input_folder = os.path.join(base_path, \"Fully Decoded Surveys\")\n",
    "    meta_root = os.path.join(base_path, \"Metadata Sheet 2 CSV's\")\n",
    "\n",
    "    month_pattern = re.compile(\n",
    "        r\"(JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    # Ensure input folder exists\n",
    "    if not os.path.exists(input_folder):\n",
    "        print(f\"Folder not found: {input_folder}\")\n",
    "        return\n",
    "\n",
    "    for year in sorted(os.listdir(input_folder)):\n",
    "        year_path = os.path.join(input_folder, year)\n",
    "        if not os.path.isdir(year_path): continue\n",
    "\n",
    "        for file in sorted(os.listdir(year_path)):\n",
    "            if not file.lower().endswith(\".csv\"): continue\n",
    "\n",
    "            match = month_pattern.search(file)\n",
    "            if not match: continue\n",
    "\n",
    "            month = match.group(1).capitalize()\n",
    "            survey_path = os.path.join(year_path, file)\n",
    "\n",
    "            # 1. Load Survey\n",
    "            # Read as object (string) initially to check for numeric-ness accurately\n",
    "            df_survey = pd.read_csv(survey_path, low_memory=False)\n",
    "\n",
    "            # 2. Load Metadata\n",
    "            meta_path = os.path.join(meta_root, year, f\"Sheet2_{month}_{year}.csv\")\n",
    "            if not os.path.exists(meta_path):\n",
    "                print(f\"[SKIP] Metadata missing for {month} {year}\")\n",
    "                continue\n",
    "\n",
    "            df_meta = pd.read_csv(meta_path, dtype=str)\n",
    "            \n",
    "            # Create a clean lookup for Description -> Variable Logic\n",
    "            # We need to know WHICH metadata rows correspond to WHICH survey column\n",
    "            # Clean descriptions to match survey headers\n",
    "            df_meta['Description_Clean'] = df_meta['Description'].fillna('').astype(str).str.strip()\n",
    "            \n",
    "            # Get set of descriptions present in metadata\n",
    "            meta_descriptions = set(df_meta[\"Description_Clean\"].unique())\n",
    "\n",
    "            sheet_results = []\n",
    "            decoded_count = 0\n",
    "            unchanged_count = 0 # Correctly unchanged\n",
    "            failed_count = 0    # Should have decoded but didn't\n",
    "\n",
    "            # 3. Check Columns\n",
    "            for col in df_survey.columns:\n",
    "                # A. Check if Data is Numeric\n",
    "                # We drop NA and check if the remaining values look like numbers\n",
    "                col_values = df_survey[col].dropna().astype(str)\n",
    "                if col_values.empty:\n",
    "                    is_numeric_data = False # Empty columns are ambiguous\n",
    "                else:\n",
    "                    # Check if all values are digits (allowing for .0 decimals)\n",
    "                    is_numeric_data = col_values.str.replace(r'\\.0$', '', regex=True).str.isnumeric().all()\n",
    "\n",
    "                # B. Check if in Metadata\n",
    "                # We check if the column header exists in the Metadata Descriptions\n",
    "                exists_in_metadata = col in meta_descriptions\n",
    "\n",
    "                status = \"\"\n",
    "                \n",
    "                if not exists_in_metadata:\n",
    "                    status = \"OK (No Metadata)\"\n",
    "                    unchanged_count += 1\n",
    "                \n",
    "                elif not is_numeric_data:\n",
    "                    # It's in metadata AND it's text (e.g. \"Male\"). Success.\n",
    "                    status = \"OK (Decoded)\"\n",
    "                    decoded_count += 1\n",
    "                    \n",
    "                elif is_numeric_data and exists_in_metadata:\n",
    "                    # --- SMART CHECK: Is it SUPPOSED to be numeric? ---\n",
    "                    # Get the labels for this specific variable\n",
    "                    subset = df_meta[df_meta['Description_Clean'] == col]\n",
    "                    \n",
    "                    # Check labels: Are they '0', empty, or purely numeric strings?\n",
    "                    labels = subset['Label'].astype(str).replace(['0', '0.0', 'nan', 'None'], '')\n",
    "                    \n",
    "                    # Filter out empty labels\n",
    "                    real_labels = labels[labels != '']\n",
    "                    \n",
    "                    if real_labels.empty:\n",
    "                        # All labels are '0' -> Quantitative (e.g., Hours)\n",
    "                        status = \"OK (Quantitative - No Labels)\"\n",
    "                        unchanged_count += 1\n",
    "                    elif real_labels.str.isnumeric().all():\n",
    "                        # All labels are numbers (e.g., \"2018\", \"1\") -> Quantitative (e.g., Year, HH Size)\n",
    "                        status = \"OK (Quantitative - Numeric Labels)\"\n",
    "                        unchanged_count += 1\n",
    "                    else:\n",
    "                        # Labels contain Text (e.g., \"Single\"), but Data is Numeric (1) -> FAIL\n",
    "                        status = \"FAILED (Should be Text)\"\n",
    "                        failed_count += 1\n",
    "\n",
    "                sheet_results.append({\n",
    "                    \"Column\": col,\n",
    "                    \"In_Metadata\": \"Yes\" if exists_in_metadata else \"No\",\n",
    "                    \"Data_Type\": \"Numeric\" if is_numeric_data else \"Text\",\n",
    "                    \"Status\": status\n",
    "                })\n",
    "\n",
    "            # ========== REPORT ==========\n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(f\"VERIFICATION: {month.upper()} {year}\")\n",
    "            print(\"=\"*70)\n",
    "            \n",
    "            # Filter for failures to show them clearly\n",
    "            failures = [res for res in sheet_results if \"FAILED\" in res['Status']]\n",
    "            \n",
    "            print(f\"Total Columns:      {len(df_survey.columns)}\")\n",
    "            print(f\"Successful Decodes: {decoded_count}\")\n",
    "            print(f\"Correctly Numeric:  {unchanged_count}\")\n",
    "            print(f\"Failures:           {failed_count}\")\n",
    "            \n",
    "            if failures:\n",
    "                print(f\"\\nWARNING: {len(failures)} columns failed to decode:\")\n",
    "                df_fail = pd.DataFrame(failures)\n",
    "                display(HTML(df_fail.to_html(index=False)))\n",
    "            else:\n",
    "                print(\"\\nPASSED: All columns accounted for.\")\n",
    "\n",
    "            all_results.extend(sheet_results)\n",
    "\n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# ===================== RUN =====================\n",
    "# Run this in your notebook\n",
    "df_integrity_check = check_value_decoding_integrity_smart(base_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
