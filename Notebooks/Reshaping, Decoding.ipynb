{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "77e0cc41",
   "metadata": {},
   "source": [
    "## Dataset Inventory Loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e9fab1ca",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: rapidfuzz in /opt/anaconda3/lib/python3.12/site-packages (3.14.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install rapidfuzz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce43a75a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Detected year folders: ['2018', '2019', '2022', '2023', '2024']\n",
      "\n",
      "=== DATASET INVENTORY SUMMARY ===\n",
      "\n",
      "Year 2018:\n",
      "  January:\n",
      "    JANUARY_2018_METADATA.xlsx (metadata)\n",
      "    JANUARY_2018.CSV (survey)\n",
      "  April:\n",
      "    APRIL_2018_METADATA.xlsx (metadata)\n",
      "    APRIL_2018.CSV (survey)\n",
      "  July:\n",
      "    JULY_2018_METADATA.xlsx (metadata)\n",
      "    JULY_2018.CSV (survey)\n",
      "  October:\n",
      "    OCTOBER_2018_METADATA.xlsx (metadata)\n",
      "    OCTOBER_2018.CSV (survey)\n",
      "\n",
      "Year 2019:\n",
      "  January:\n",
      "    JANUARY_2019_METADATA.xlsx (metadata)\n",
      "    JANUARY_2019.CSV (survey)\n",
      "  April:\n",
      "    APRIL_2019_METADATA.xlsx (metadata)\n",
      "    APRIL_2019.CSV (survey)\n",
      "  July:\n",
      "    JULY_2019_METADATA.xlsx (metadata)\n",
      "    JULY_2019.CSV (survey)\n",
      "  October:\n",
      "    OCTOBER_2019_METADATA.xlsx (metadata)\n",
      "    OCTOBER_2019.CSV (survey)\n",
      "\n",
      "Year 2022:\n",
      "  January:\n",
      "    JANUARY_2022_METADATA.xlsx (metadata)\n",
      "    JANUARY_2022.csv (survey)\n",
      "  February:\n",
      "    FEBRUARY_2022.csv (survey)\n",
      "    FEBRUARY_2022_METADATA.xlsx (metadata)\n",
      "  March:\n",
      "    MARCH_2022_METADATA.xlsx (metadata)\n",
      "    MARCH_2022.csv (survey)\n",
      "  April:\n",
      "    APRIL_2022_METADATA.xlsx (metadata)\n",
      "    APRIL_2022.csv (survey)\n",
      "  May:\n",
      "    MAY_2022_METADATA.xlsx (metadata)\n",
      "    MAY_2022.csv (survey)\n",
      "  June:\n",
      "    JUNE_2022.csv (survey)\n",
      "    JUNE_2022_METADATA.xlsx (metadata)\n",
      "  July:\n",
      "    JULY_2022.CSV (survey)\n",
      "    JULY_2022_METADATA.xlsx (metadata)\n",
      "  August:\n",
      "    AUGUST_2022_METADATA.xlsx (metadata)\n",
      "    AUGUST_2022.CSV (survey)\n",
      "  September:\n",
      "    SEPTEMBER_2022_METADATA.xlsx (metadata)\n",
      "    SEPTEMBER_2022.CSV (survey)\n",
      "  October:\n",
      "    OCTOBER_2022_METADATA.xlsx (metadata)\n",
      "    OCTOBER_2022.CSV (survey)\n",
      "  November:\n",
      "    NOVEMBER_2022.CSV (survey)\n",
      "    NOVEMBER_2022_METADATA.xlsx (metadata)\n",
      "  December:\n",
      "    DECEMBER_2022_METADATA.xlsx (metadata)\n",
      "    DECEMBER_2022.CSV (survey)\n",
      "\n",
      "Year 2023:\n",
      "  January:\n",
      "    JANUARY_2023_METADATA.xlsx (metadata)\n",
      "    JANUARY_2023.CSV (survey)\n",
      "  February:\n",
      "    FEBRUARY_2023.CSV (survey)\n",
      "    FEBRUARY_2023_METADATA.xlsx (metadata)\n",
      "  March:\n",
      "    MARCH_2023_METADATA.xlsx (metadata)\n",
      "    MARCH_2023.CSV (survey)\n",
      "  April:\n",
      "    APRIL_2023_METADATA.xlsx (metadata)\n",
      "    APRIL_2023.CSV (survey)\n",
      "  May:\n",
      "    MAY_2023_METADATA.xlsx (metadata)\n",
      "    MAY_2023.CSV (survey)\n",
      "  June:\n",
      "    JUNE_2023_METADATA.xlsx (metadata)\n",
      "    JUNE_2023.CSV (survey)\n",
      "  July:\n",
      "    JULY_2023_METADATA.xlsx (metadata)\n",
      "    JULY_2023.CSV (survey)\n",
      "  August:\n",
      "    AUGUST_2023_METADATA.xlsx (metadata)\n",
      "    AUGUST_2023.CSV (survey)\n",
      "  September:\n",
      "    SEPTEMBER_2023.CSV (survey)\n",
      "    SEPTEMBER_2023_METADATA.xlsx (metadata)\n",
      "  October:\n",
      "    OCTOBER_2023_METADATA.xlsx (metadata)\n",
      "    OCTOBER_2023.CSV (survey)\n",
      "  November:\n",
      "    NOVEMBER_2023_METADATA.xlsx (metadata)\n",
      "    NOVEMBER_2023.CSV (survey)\n",
      "  December:\n",
      "    DECEMBER_2023.CSV (survey)\n",
      "    DECEMBER_2023_METADATA.xlsx (metadata)\n",
      "\n",
      "Year 2024:\n",
      "  January:\n",
      "    JANUARY_2024_METADATA.xlsx (metadata)\n",
      "    JANUARY_2024.CSV (survey)\n",
      "  February:\n",
      "    FEBRUARY_2024.CSV (survey)\n",
      "    FEBRUARY_2024_METADATA.xlsx (metadata)\n",
      "  March:\n",
      "    MARCH_2024.CSV (survey)\n",
      "    MARCH_2024_METADATA.xlsx (metadata)\n",
      "  April:\n",
      "    APRIL_2024_METADATA.xlsx (metadata)\n",
      "    APRIL_2024.CSV (survey)\n",
      "  May:\n",
      "    MAY_2024_METADATA.xlsx (metadata)\n",
      "    MAY_2024.CSV (survey)\n",
      "  June:\n",
      "    JUNE_2024_METADATA.xlsx (metadata)\n",
      "    JUNE_2024.CSV (survey)\n",
      "  July:\n",
      "    JULY_2024_METADATA.xlsx (metadata)\n",
      "    JULY_2024.CSV (survey)\n",
      "  August:\n",
      "    AUGUST_2024.CSV (survey)\n",
      "    AUGUST_2024_METADATA.xlsx (metadata)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "base_path = r\"/Users/neilkeannedelavega/Library/CloudStorage/GoogleDrive-shaniakeith23@gmail.com/My Drive/Labor Force Survey\"\n",
    "\n",
    "# Month ordering\n",
    "month_order = {\n",
    "    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4,\n",
    "    \"May\": 5, \"June\": 6, \"July\": 7, \"August\": 8,\n",
    "    \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n",
    "}\n",
    "\n",
    "# Patterns\n",
    "month_pattern = re.compile(\n",
    "    r\"(JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "year_pattern = re.compile(r\"(20\\d{2})\")\n",
    "\n",
    "# Detect year folders from drive\n",
    "year_folders = [\n",
    "    f for f in os.listdir(base_path)\n",
    "    if os.path.isdir(os.path.join(base_path, f)) and f.isdigit()\n",
    "]\n",
    "\n",
    "print(\"Detected year folders:\", sorted(year_folders))\n",
    "\n",
    "inventory = {}\n",
    "\n",
    "for year in sorted(year_folders):\n",
    "    year_path = os.path.join(base_path, year)\n",
    "\n",
    "    # Accept both CSV and XLSX\n",
    "    data_files = [\n",
    "        f for f in os.listdir(year_path)\n",
    "        if f.lower().endswith(\".csv\") or f.lower().endswith(\".xlsx\")\n",
    "    ]\n",
    "\n",
    "    inventory[year] = {}\n",
    "\n",
    "    for file in data_files:\n",
    "        upper = file.upper()\n",
    "\n",
    "        # Detect type\n",
    "        if upper.endswith(\".XLSX\"):\n",
    "            filetype = \"metadata\"  # XLSX = metadata\n",
    "        else:\n",
    "            filetype = \"survey\"    # CSV = survey\n",
    "\n",
    "        # Detect month\n",
    "        month_match = month_pattern.search(upper)\n",
    "        month = (\n",
    "            month_match.group(1).capitalize()\n",
    "            if month_match\n",
    "            else \"Unmatched\"\n",
    "        )\n",
    "\n",
    "        # Detect year inside filename\n",
    "        year_match = year_pattern.search(upper)\n",
    "        file_year = year_match.group(1) if year_match else \"UNKNOWN\"\n",
    "\n",
    "        # Store into inventory\n",
    "        if month not in inventory[year]:\n",
    "            inventory[year][month] = []\n",
    "\n",
    "        inventory[year][month].append({\n",
    "            \"filename\": file,\n",
    "            \"filetype\": filetype,\n",
    "            \"file_year\": file_year\n",
    "        })\n",
    "\n",
    "# Print clean summary\n",
    "print(\"\\n=== DATASET INVENTORY SUMMARY ===\\n\")\n",
    "\n",
    "for yr in sorted(inventory.keys()):\n",
    "    print(f\"Year {yr}:\")\n",
    "\n",
    "    sorted_months = sorted(\n",
    "        inventory[yr].keys(),\n",
    "        key=lambda m: month_order.get(m, 99)\n",
    "    )\n",
    "\n",
    "    for month in sorted_months:\n",
    "        print(f\"  {month}:\")\n",
    "        for item in inventory[yr][month]:\n",
    "            print(f\"    {item['filename']} ({item['filetype']})\")\n",
    "\n",
    "    print()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0f98339b",
   "metadata": {},
   "source": [
    "## Load Dataset Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4f63c045",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(year, month, filetype=\"survey\", sheet_number=None):\n",
    "    \"\"\"\n",
    "    Load a dataset from the inventory.\n",
    "\n",
    "    year: str, e.g., \"2018\"\n",
    "    month: str, e.g., \"January\"\n",
    "    filetype: \"survey\" or \"metadata\"\n",
    "    sheet_number: 0(sheet 1) or 1(sheet 2)\n",
    "    \"\"\"\n",
    "    file_info = next(\n",
    "        (f for f in inventory[year][month] if f[\"filetype\"] == filetype),\n",
    "        None\n",
    "    )\n",
    "    if not file_info:\n",
    "        raise ValueError(f\"No {filetype} file found for {month} {year}\")\n",
    "\n",
    "    file_path = os.path.join(base_path, year, file_info[\"filename\"])\n",
    "    \n",
    "    if filetype == \"survey\":\n",
    "        return pd.read_csv(file_path, low_memory=False)\n",
    "    \n",
    "    if sheet_number is not None:\n",
    "        return pd.read_excel(file_path, sheet_name=sheet_number)\n",
    "    \n",
    "    return pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8ebb318",
   "metadata": {},
   "source": [
    "Sample: January 2018 Survey"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "04853487",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUFREG</th>\n",
       "      <th>PUFPRV</th>\n",
       "      <th>PUFPRRCD</th>\n",
       "      <th>PUFHHNUM</th>\n",
       "      <th>PUFURB2K10</th>\n",
       "      <th>PUFPWGTPRV</th>\n",
       "      <th>PUFSVYMO</th>\n",
       "      <th>PUFSVYYR</th>\n",
       "      <th>PUFPSU</th>\n",
       "      <th>PUFRPL</th>\n",
       "      <th>...</th>\n",
       "      <th>PUFC33_WEEKS</th>\n",
       "      <th>PUFC34_WYNOT</th>\n",
       "      <th>PUFC35_LTLOOKW</th>\n",
       "      <th>PUFC36_AVAIL</th>\n",
       "      <th>PUFC37_WILLING</th>\n",
       "      <th>PUFC38_PREVJOB</th>\n",
       "      <th>PUFC40_POCC</th>\n",
       "      <th>PUFC41_WQTR</th>\n",
       "      <th>PUFC43_QKB</th>\n",
       "      <th>PUFNEWEMPSTAT</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>124.9425</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td>6</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>52</td>\n",
       "      <td>2</td>\n",
       "      <td></td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>131.2126</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>142.0464</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>01</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>138.2958</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>100</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>195.4152</td>\n",
       "      <td>1</td>\n",
       "      <td>2018</td>\n",
       "      <td>140</td>\n",
       "      <td>32</td>\n",
       "      <td>...</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>1</td>\n",
       "      <td>41</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 50 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   PUFREG  PUFPRV  PUFPRRCD  PUFHHNUM  PUFURB2K10  PUFPWGTPRV  PUFSVYMO  \\\n",
       "0      14       1       100         1           2    124.9425         1   \n",
       "1      14       1       100         1           2    131.2126         1   \n",
       "2      14       1       100         1           2    142.0464         1   \n",
       "3      14       1       100         1           2    138.2958         1   \n",
       "4      14       1       100         2           2    195.4152         1   \n",
       "\n",
       "   PUFSVYYR  PUFPSU  PUFRPL  ...  PUFC33_WEEKS  PUFC34_WYNOT  PUFC35_LTLOOKW  \\\n",
       "0      2018     140      32  ...                           6                   \n",
       "1      2018     140      32  ...                                               \n",
       "2      2018     140      32  ...                                               \n",
       "3      2018     140      32  ...                                               \n",
       "4      2018     140      32  ...                                               \n",
       "\n",
       "   PUFC36_AVAIL  PUFC37_WILLING PUFC38_PREVJOB PUFC40_POCC PUFC41_WQTR  \\\n",
       "0                                            1          52           2   \n",
       "1                                                                    1   \n",
       "2                                                                    1   \n",
       "3                                                                        \n",
       "4                                                                    1   \n",
       "\n",
       "  PUFC43_QKB PUFNEWEMPSTAT  \n",
       "0                        3  \n",
       "1         01             1  \n",
       "2         01             1  \n",
       "3                           \n",
       "4         41             1  \n",
       "\n",
       "[5 rows x 50 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Load the survey sheet of January 2018 metadata\n",
    "jan_2018_survey = load_dataset(\"2018\", \"January\",\"survey\")\n",
    "\n",
    "# View the first few rows\n",
    "jan_2018_survey.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c7f7b8a",
   "metadata": {},
   "source": [
    "## Metadata Sheet 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "937d5752",
   "metadata": {},
   "source": [
    "<H5> Sample: January 2018 Metadata Sheet 1 (Raw) </H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "498a73c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== January 2018 Metadata Sheet 1 (Raw) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>QUEST</th>\n",
       "      <th>Questionnaire</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>_IDS0</td>\n",
       "      <td>(Id Items)</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUFREG</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUFPRV</td>\n",
       "      <td>Province</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUFPRRCD</td>\n",
       "      <td>Province Recode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>PUFHHNUM</td>\n",
       "      <td>Household Unique Sequential Number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   QUEST  Questionnaire Unnamed: 2  Unnamed: 3 Unnamed: 4  \\\n",
       "0    NaN            NaN      _IDS0  (Id Items)        NaN   \n",
       "1    NaN            NaN        NaN         NaN     PUFREG   \n",
       "2    NaN            NaN        NaN         NaN     PUFPRV   \n",
       "3    NaN            NaN        NaN         NaN   PUFPRRCD   \n",
       "4    NaN            NaN        NaN         NaN   PUFHHNUM   \n",
       "\n",
       "                           Unnamed: 5  \n",
       "0                                 NaN  \n",
       "1                              Region  \n",
       "2                            Province  \n",
       "3                     Province Recode  \n",
       "4  Household Unique Sequential Number  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the first sheet of January 2018 metadata\n",
    "january_2018_metadata_sheet1 = load_dataset(\"2018\", \"January\", \"metadata\", 0)\n",
    "\n",
    "# View the first few rows\n",
    "print(\"=== January 2018 Metadata Sheet 1 (Raw) ===\")\n",
    "january_2018_metadata_sheet1.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8b67ba5",
   "metadata": {},
   "source": [
    "#### Reshaping Metadata Sheet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "39c15d87",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "def extract_variables(df):\n",
    "    \"\"\"\n",
    "    Extract variable names and descriptions from metadata Sheet 1 (variable dictionary).\n",
    "    Automatically reads the 4th and 5th columns (E and F in Excel) where variables and descriptions reside.\n",
    "    \n",
    "    Returns a clean DataFrame with columns ['Variable', 'Description'].\n",
    "    \"\"\"\n",
    "    \n",
    "    # Select the 4th and 5th columns (index 4 and 5)\n",
    "    df_vars = df.iloc[:, 4:6].copy()\n",
    "    \n",
    "    # Rename columns\n",
    "    df_vars.columns = ['Variable', 'Description']\n",
    "    \n",
    "    # Drop rows where 'Variable' is empty or NaN\n",
    "    df_vars = df_vars[df_vars['Variable'].notna() & (df_vars['Variable'].astype(str).str.strip() != '')]\n",
    "    \n",
    "    # Strip whitespace from values\n",
    "    df_vars['Variable'] = df_vars['Variable'].astype(str).str.strip()\n",
    "    df_vars['Description'] = df_vars['Description'].astype(str).str.strip()\n",
    "    \n",
    "    # Reset index\n",
    "    df_vars = df_vars.reset_index(drop=True)\n",
    "    \n",
    "    return df_vars\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c6c97a",
   "metadata": {},
   "source": [
    "### Metadata Sheet 1 Reshaped Saving Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "92803ecc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def batch_process_sheet1_metadata(inventory, base_output_path):\n",
    "    \"\"\"\n",
    "    Loops through the entire inventory, loads Sheet 1 of the metadata,\n",
    "    reshapes it, and saves it into a structured folder hierarchy.\n",
    "    \n",
    "    Provides a text-based summary report for assurance.\n",
    "    \"\"\"\n",
    "    \n",
    "    # Counters for the summary report\n",
    "    success_count = 0\n",
    "    failure_count = 0\n",
    "    skipped_count = 0\n",
    "    errors_log = []\n",
    "\n",
    "    # 1. Define and Create the Main Parent Folder\n",
    "    main_folder_name = \"Metadata Sheet 1 CSV's\"\n",
    "    main_folder_path = os.path.join(base_output_path, main_folder_name)\n",
    "    os.makedirs(main_folder_path, exist_ok=True)\n",
    "    \n",
    "    print(\"--- STARTING BATCH PROCESS ---\")\n",
    "    print(f\"Target Directory: {main_folder_path}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 2. Iterate through Years in the Inventory\n",
    "    for year, months_data in inventory.items():\n",
    "        \n",
    "        # Create the Year Subfolder\n",
    "        year_folder_path = os.path.join(main_folder_path, year)\n",
    "        os.makedirs(year_folder_path, exist_ok=True)\n",
    "        \n",
    "        # 3. Iterate through Months in that Year\n",
    "        for month, files_list in months_data.items():\n",
    "            \n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "            \n",
    "            # Check for metadata file existence\n",
    "            has_metadata = any(f.get('filetype') == 'metadata' for f in files_list)\n",
    "            \n",
    "            if has_metadata:\n",
    "                try:\n",
    "                    # A. Load the Data (Sheet 0 = Sheet 1)\n",
    "                    raw_df = load_dataset(year, month, \"metadata\", 0)\n",
    "                    \n",
    "                    # B. Reshape the Data\n",
    "                    clean_df = extract_variables(raw_df)\n",
    "                    \n",
    "                    # C. Save to CSV\n",
    "                    filename = f\"Sheet1_{month}_{year}.csv\"\n",
    "                    full_save_path = os.path.join(year_folder_path, filename)\n",
    "                    \n",
    "                    clean_df.to_csv(full_save_path, index=False)\n",
    "                    \n",
    "                    # Print confirmation for this specific file\n",
    "                    print(f\"[OK] Saved: {year}/{filename}\")\n",
    "                    success_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Failed {month} {year}: {e}\")\n",
    "                    errors_log.append(f\"{month} {year}: {str(e)}\")\n",
    "                    failure_count += 1\n",
    "            else:\n",
    "                skipped_count += 1\n",
    "\n",
    "    # 4. Final Assurance Report\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"      PROCESSING SUMMARY REPORT\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total Successfully Saved: {success_count}\")\n",
    "    print(f\"Total Failed:             {failure_count}\")\n",
    "    print(f\"Total Skipped (No File):  {skipped_count}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if failure_count == 0:\n",
    "        print(\"STATUS: COMPLETE SUCCESS\")\n",
    "        print(f\"All files are now located in: {main_folder_path}\")\n",
    "        print(\"Google Drive is syncing these files now.\")\n",
    "    else:\n",
    "        print(\"STATUS: COMPLETED WITH ERRORS\")\n",
    "        print(\"Check the errors log above.\")\n",
    "        if errors_log:\n",
    "            print(\"\\nError Details:\")\n",
    "            for err in errors_log:\n",
    "                print(f\" - {err}\")\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6b56256e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING BATCH PROCESS ---\n",
      "Target Directory: /Users/neilkeannedelavega/Library/CloudStorage/GoogleDrive-shaniakeith23@gmail.com/My Drive/Labor Force Survey/Metadata Sheet 1 CSV's\n",
      "--------------------------------------------------\n",
      "[OK] Saved: 2018/Sheet1_January_2018.csv\n",
      "[OK] Saved: 2018/Sheet1_October_2018.csv\n",
      "[OK] Saved: 2018/Sheet1_April_2018.csv\n",
      "[OK] Saved: 2018/Sheet1_July_2018.csv\n",
      "[OK] Saved: 2019/Sheet1_April_2019.csv\n",
      "[OK] Saved: 2019/Sheet1_July_2019.csv\n",
      "[OK] Saved: 2019/Sheet1_October_2019.csv\n",
      "[OK] Saved: 2019/Sheet1_January_2019.csv\n",
      "[OK] Saved: 2022/Sheet1_December_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_February_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_August_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_March_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_September_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_October_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_January_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_May_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_November_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_July_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_June_2022.csv\n",
      "[OK] Saved: 2022/Sheet1_April_2022.csv\n",
      "[OK] Saved: 2023/Sheet1_December_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_June_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_February_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_July_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_November_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_April_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_September_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_January_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_May_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_October_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_August_2023.csv\n",
      "[OK] Saved: 2023/Sheet1_March_2023.csv\n",
      "[OK] Saved: 2024/Sheet1_February_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_June_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_April_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_July_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_May_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_January_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_March_2024.csv\n",
      "[OK] Saved: 2024/Sheet1_August_2024.csv\n",
      "\n",
      "========================================\n",
      "      PROCESSING SUMMARY REPORT\n",
      "========================================\n",
      "Total Successfully Saved: 40\n",
      "Total Failed:             0\n",
      "Total Skipped (No File):  0\n",
      "----------------------------------------\n",
      "STATUS: COMPLETE SUCCESS\n",
      "All files are now located in: /Users/neilkeannedelavega/Library/CloudStorage/GoogleDrive-shaniakeith23@gmail.com/My Drive/Labor Force Survey/Metadata Sheet 1 CSV's\n",
      "Google Drive is syncing these files now.\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Run the processor\n",
    "batch_process_sheet1_metadata(inventory, base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "715c5d72",
   "metadata": {},
   "source": [
    "#### Verifying if the variable and description counts of Reshaped Metadata Sheet 1 and Original matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ef001d48",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_verify_sheet1_variable_and_description_count_verbose(inventory, base_path):\n",
    "    \"\"\"\n",
    "    Iterates through all years and months in the inventory and compares\n",
    "    total variables and descriptions in raw vs reshaped Sheet 1 metadata.\n",
    "    Prints mismatches immediately, and returns a DataFrame with all results.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for year, months_data in inventory.items():\n",
    "        for month, files_list in months_data.items():\n",
    "            if month == \"Unmatched\":\n",
    "                continue  # Skip unmatched files\n",
    "\n",
    "            # --- Load raw Sheet 1 ---\n",
    "            try:\n",
    "                raw_df = load_dataset(year, month, \"metadata\", sheet_number=0)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {month} {year}: Could not load raw Sheet 1 ({e})\")\n",
    "                results.append({\n",
    "                    'Year': year,\n",
    "                    'Month': month,\n",
    "                    'Raw Variable Count': 'ERROR',\n",
    "                    'Reshaped Variable Count': 'ERROR',\n",
    "                    'Raw Description Count': 'ERROR',\n",
    "                    'Reshaped Description Count': 'ERROR',\n",
    "                    'Status': f'FAIL (Raw load error: {e})'\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            # --- Load reshaped CSV Sheet 1 ---\n",
    "            reshaped_file_path = os.path.join(\n",
    "                base_path, \"Metadata Sheet 1 CSV's\", year, f\"Sheet1_{month}_{year}.csv\"\n",
    "            )\n",
    "            if not os.path.exists(reshaped_file_path):\n",
    "                print(f\"[ERROR] {month} {year}: Reshaped Sheet 1 CSV missing!\")\n",
    "                results.append({\n",
    "                    'Year': year,\n",
    "                    'Month': month,\n",
    "                    'Raw Variable Count': 'ERROR',\n",
    "                    'Reshaped Variable Count': 'ERROR',\n",
    "                    'Raw Description Count': 'ERROR',\n",
    "                    'Reshaped Description Count': 'ERROR',\n",
    "                    'Status': 'FAIL (Reshaped CSV missing)'\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            reshaped_df = pd.read_csv(reshaped_file_path)\n",
    "\n",
    "            # --- Count non-empty variables & descriptions ---\n",
    "            raw_vars = raw_df.iloc[:, 4].dropna().astype(str).str.strip()\n",
    "            raw_vars = raw_vars[raw_vars != '']\n",
    "            raw_descs = raw_df.iloc[:, 5].dropna().astype(str).str.strip()\n",
    "            raw_descs = raw_descs[raw_descs != '']\n",
    "\n",
    "            reshaped_vars = reshaped_df['Variable'].astype(str).str.strip()\n",
    "            reshaped_vars = reshaped_vars[reshaped_vars != '']\n",
    "            reshaped_descs = reshaped_df['Description'].astype(str).str.strip()\n",
    "            reshaped_descs = reshaped_descs[reshaped_descs != '']\n",
    "\n",
    "            # --- PASS / FAIL ---\n",
    "            status = \"PASS\" if (len(raw_vars) == len(reshaped_vars) and len(raw_descs) == len(reshaped_descs)) else \"FAIL\"\n",
    "\n",
    "            if status == \"FAIL\":\n",
    "                print(f\"[MISMATCH] {month} {year} - Variables: {len(raw_vars)} vs {len(reshaped_vars)}, \"\n",
    "                      f\"Descriptions: {len(raw_descs)} vs {len(reshaped_descs)}\")\n",
    "\n",
    "            results.append({\n",
    "                'Year': year,\n",
    "                'Month': month,\n",
    "                'Raw Variable Count': len(raw_vars),\n",
    "                'Reshaped Variable Count': len(reshaped_vars),\n",
    "                'Raw Description Count': len(raw_descs),\n",
    "                'Reshaped Description Count': len(reshaped_descs),\n",
    "                'Status': status\n",
    "            })\n",
    "\n",
    "    df = pd.DataFrame(results).sort_values(['Year', 'Month']).reset_index(drop=True)\n",
    "\n",
    "    # ---------- NEW SUCCESS MESSAGE ----------\n",
    "    total = len(df)\n",
    "    passed = (df['Status'] == 'PASS').sum()\n",
    "    failed = total - passed\n",
    "\n",
    "    if failed == 0:\n",
    "        print(\"\\nSUCCESS: All variables and descriptions have been reshaped correctly!\\n\")\n",
    "    else:\n",
    "        print(f\"\\nCompleted with issues: {passed} PASS, {failed} FAIL.\\n\")\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "a3fe858d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "SUCCESS: All variables and descriptions have been reshaped correctly!\n",
      "\n",
      "=== Sheet 1 Metadata Variables and Descriptions (Raw vs Reshaped) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Raw Variable Count</th>\n",
       "      <th>Reshaped Variable Count</th>\n",
       "      <th>Raw Description Count</th>\n",
       "      <th>Reshaped Description Count</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>July</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>April</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>January</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>July</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>October</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022</td>\n",
       "      <td>April</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>August</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022</td>\n",
       "      <td>December</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022</td>\n",
       "      <td>February</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022</td>\n",
       "      <td>January</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022</td>\n",
       "      <td>July</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022</td>\n",
       "      <td>June</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022</td>\n",
       "      <td>March</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022</td>\n",
       "      <td>May</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022</td>\n",
       "      <td>November</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022</td>\n",
       "      <td>October</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022</td>\n",
       "      <td>September</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023</td>\n",
       "      <td>April</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023</td>\n",
       "      <td>August</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023</td>\n",
       "      <td>December</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023</td>\n",
       "      <td>February</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023</td>\n",
       "      <td>January</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023</td>\n",
       "      <td>July</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023</td>\n",
       "      <td>June</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023</td>\n",
       "      <td>March</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023</td>\n",
       "      <td>May</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023</td>\n",
       "      <td>November</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023</td>\n",
       "      <td>October</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023</td>\n",
       "      <td>September</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2024</td>\n",
       "      <td>April</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2024</td>\n",
       "      <td>August</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2024</td>\n",
       "      <td>February</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2024</td>\n",
       "      <td>January</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024</td>\n",
       "      <td>July</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2024</td>\n",
       "      <td>June</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2024</td>\n",
       "      <td>March</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year      Month  Raw Variable Count  Reshaped Variable Count  \\\n",
       "0   2018      April                  50                       50   \n",
       "1   2018    January                  50                       50   \n",
       "2   2018       July                  51                       51   \n",
       "3   2018    October                  51                       51   \n",
       "4   2019      April                  49                       49   \n",
       "5   2019    January                  49                       49   \n",
       "6   2019       July                  49                       49   \n",
       "7   2019    October                  49                       49   \n",
       "8   2022      April                  52                       52   \n",
       "9   2022     August                  42                       42   \n",
       "10  2022   December                  42                       42   \n",
       "11  2022   February                  41                       41   \n",
       "12  2022    January                  52                       52   \n",
       "13  2022       July                  52                       52   \n",
       "14  2022       June                  42                       42   \n",
       "15  2022      March                  41                       41   \n",
       "16  2022        May                  42                       42   \n",
       "17  2022   November                  42                       42   \n",
       "18  2022    October                  52                       52   \n",
       "19  2022  September                  42                       42   \n",
       "20  2023      April                  52                       52   \n",
       "21  2023     August                  41                       41   \n",
       "22  2023   December                  41                       41   \n",
       "23  2023   February                  42                       42   \n",
       "24  2023    January                  52                       52   \n",
       "25  2023       July                  52                       52   \n",
       "26  2023       June                  42                       42   \n",
       "27  2023      March                  42                       42   \n",
       "28  2023        May                  42                       42   \n",
       "29  2023   November                  41                       41   \n",
       "30  2023    October                  52                       52   \n",
       "31  2023  September                  41                       41   \n",
       "32  2024      April                  51                       51   \n",
       "33  2024     August                  40                       40   \n",
       "34  2024   February                  41                       41   \n",
       "35  2024    January                  52                       52   \n",
       "36  2024       July                  51                       51   \n",
       "37  2024       June                  40                       40   \n",
       "38  2024      March                  41                       41   \n",
       "39  2024        May                  40                       40   \n",
       "\n",
       "    Raw Description Count  Reshaped Description Count Status  \n",
       "0                      50                          50   PASS  \n",
       "1                      50                          50   PASS  \n",
       "2                      51                          51   PASS  \n",
       "3                      51                          51   PASS  \n",
       "4                      49                          49   PASS  \n",
       "5                      49                          49   PASS  \n",
       "6                      49                          49   PASS  \n",
       "7                      49                          49   PASS  \n",
       "8                      52                          52   PASS  \n",
       "9                      42                          42   PASS  \n",
       "10                     42                          42   PASS  \n",
       "11                     41                          41   PASS  \n",
       "12                     52                          52   PASS  \n",
       "13                     52                          52   PASS  \n",
       "14                     42                          42   PASS  \n",
       "15                     41                          41   PASS  \n",
       "16                     42                          42   PASS  \n",
       "17                     42                          42   PASS  \n",
       "18                     52                          52   PASS  \n",
       "19                     42                          42   PASS  \n",
       "20                     52                          52   PASS  \n",
       "21                     41                          41   PASS  \n",
       "22                     41                          41   PASS  \n",
       "23                     42                          42   PASS  \n",
       "24                     52                          52   PASS  \n",
       "25                     52                          52   PASS  \n",
       "26                     42                          42   PASS  \n",
       "27                     42                          42   PASS  \n",
       "28                     42                          42   PASS  \n",
       "29                     41                          41   PASS  \n",
       "30                     52                          52   PASS  \n",
       "31                     41                          41   PASS  \n",
       "32                     51                          51   PASS  \n",
       "33                     40                          40   PASS  \n",
       "34                     41                          41   PASS  \n",
       "35                     52                          52   PASS  \n",
       "36                     51                          51   PASS  \n",
       "37                     40                          40   PASS  \n",
       "38                     41                          41   PASS  \n",
       "39                     40                          40   PASS  "
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "verification_df = batch_verify_sheet1_variable_and_description_count_verbose(inventory, base_path)\n",
    "\n",
    "print(\"=== Sheet 1 Metadata Variables and Descriptions (Raw vs Reshaped) ===\")\n",
    "verification_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58ce0b5c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def batch_verify_sheet1_variable_and_description_count_verbose(inventory, base_path):\n",
    "    \"\"\"\n",
    "    Iterates through all years and months in the inventory and compares\n",
    "    total variables and descriptions in raw vs reshaped Sheet 1 metadata.\n",
    "    Prints mismatches immediately, and returns a DataFrame with all results.\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for year, months_data in inventory.items():\n",
    "        for month, files_list in months_data.items():\n",
    "            if month == \"Unmatched\":\n",
    "                continue  # Skip unmatched files\n",
    "\n",
    "            # --- Load raw Sheet 1 ---\n",
    "            try:\n",
    "                raw_df = load_dataset(year, month, \"metadata\", sheet_number=0)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {month} {year}: Could not load raw Sheet 1 ({e})\")\n",
    "                results.append({\n",
    "                    'Year': year,\n",
    "                    'Month': month,\n",
    "                    'Raw Variable Count': 'ERROR',\n",
    "                    'Reshaped Variable Count': 'ERROR',\n",
    "                    'Raw Description Count': 'ERROR',\n",
    "                    'Reshaped Description Count': 'ERROR',\n",
    "                    'Status': f'FAIL (Raw load error: {e})'\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            # --- Load reshaped CSV Sheet 1 ---\n",
    "            reshaped_file_path = os.path.join(\n",
    "                base_path, \"Metadata Sheet 1 CSV's\", year, f\"Sheet1_{month}_{year}.csv\"\n",
    "            )\n",
    "            if not os.path.exists(reshaped_file_path):\n",
    "                print(f\"[ERROR] {month} {year}: Reshaped Sheet 1 CSV missing!\")\n",
    "                results.append({\n",
    "                    'Year': year,\n",
    "                    'Month': month,\n",
    "                    'Raw Variable Count': 'ERROR',\n",
    "                    'Reshaped Variable Count': 'ERROR',\n",
    "                    'Raw Description Count': 'ERROR',\n",
    "                    'Reshaped Description Count': 'ERROR',\n",
    "                    'Status': 'FAIL (Reshaped CSV missing)'\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            reshaped_df = pd.read_csv(reshaped_file_path)\n",
    "\n",
    "            # --- Count non-empty variables and descriptions ---\n",
    "            raw_vars = raw_df.iloc[:, 4].dropna().astype(str).str.strip()\n",
    "            raw_vars = raw_vars[raw_vars != '']\n",
    "            raw_descs = raw_df.iloc[:, 5].dropna().astype(str).str.strip()\n",
    "            raw_descs = raw_descs[raw_descs != '']\n",
    "\n",
    "            reshaped_vars = reshaped_df['Variable'].astype(str).str.strip()\n",
    "            reshaped_vars = reshaped_vars[reshaped_vars != '']\n",
    "            reshaped_descs = reshaped_df['Description'].astype(str).str.strip()\n",
    "            reshaped_descs = reshaped_descs[reshaped_descs != '']\n",
    "\n",
    "            # --- Check if both counts match ---\n",
    "            status = \"PASS\" if (len(raw_vars) == len(reshaped_vars) and len(raw_descs) == len(reshaped_descs)) else \"FAIL\"\n",
    "\n",
    "            if status == \"FAIL\":\n",
    "                # Immediate print for any mismatch\n",
    "                print(f\"[MISMATCH] {month} {year} - Variables: {len(raw_vars)} vs {len(reshaped_vars)}, \"\n",
    "                      f\"Descriptions: {len(raw_descs)} vs {len(reshaped_descs)}\")\n",
    "\n",
    "            results.append({\n",
    "                'Year': year,\n",
    "                'Month': month,\n",
    "                'Raw Variable Count': len(raw_vars),\n",
    "                'Reshaped Variable Count': len(reshaped_vars),\n",
    "                'Raw Description Count': len(raw_descs),\n",
    "                'Reshaped Description Count': len(reshaped_descs),\n",
    "                'Status': status\n",
    "            })\n",
    "\n",
    "    return pd.DataFrame(results).sort_values(['Year', 'Month']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "705162ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Sheet 1 Metadata Variables and Descriptions (Raw vs Reshaped) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Raw Variable Count</th>\n",
       "      <th>Reshaped Variable Count</th>\n",
       "      <th>Raw Description Count</th>\n",
       "      <th>Reshaped Description Count</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>July</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>April</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Year    Month  Raw Variable Count  Reshaped Variable Count  \\\n",
       "0  2018    April                  50                       50   \n",
       "1  2018  January                  50                       50   \n",
       "2  2018     July                  51                       51   \n",
       "3  2018  October                  51                       51   \n",
       "4  2019    April                  49                       49   \n",
       "\n",
       "   Raw Description Count  Reshaped Description Count Status  \n",
       "0                     50                          50   PASS  \n",
       "1                     50                          50   PASS  \n",
       "2                     51                          51   PASS  \n",
       "3                     51                          51   PASS  \n",
       "4                     49                          49   PASS  "
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Run the Sheet 1 verifier\n",
    "verification_df = batch_verify_sheet1_variable_and_description_count_verbose(inventory, base_path)\n",
    "\n",
    "# Print a header and show the first few rows\n",
    "print(\"=== Sheet 1 Metadata Variables and Descriptions (Raw vs Reshaped) ===\")\n",
    "verification_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90639dd6",
   "metadata": {},
   "source": [
    "Checking January 2018 Metadata Reshaped Sheet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1855dd5e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PUFREG</td>\n",
       "      <td>Region</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUFPRV</td>\n",
       "      <td>Province</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUFPRRCD</td>\n",
       "      <td>Province Recode</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUFHHNUM</td>\n",
       "      <td>Household Unique Sequential Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUFURB2K10</td>\n",
       "      <td>2010Urban-RuralFIES</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Variable                         Description\n",
       "0      PUFREG                              Region\n",
       "1      PUFPRV                            Province\n",
       "2    PUFPRRCD                     Province Recode\n",
       "3    PUFHHNUM  Household Unique Sequential Number\n",
       "4  PUFURB2K10                 2010Urban-RuralFIES"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata Sheet 1\n",
    "January_metadata = load_dataset(\"2018\", \"January\", \"metadata\", 0)\n",
    "\n",
    "# Call your function\n",
    "variables_df = extract_variables(January_metadata)\n",
    "\n",
    "# View results\n",
    "variables_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fba725a1",
   "metadata": {},
   "source": [
    "Checking August 2024 Metadata Reshaped Sheet 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "dcaca8e9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>Description</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>PUFHHNUM</td>\n",
       "      <td>Household Unique Sequential Number</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>PUFPWGTPRV</td>\n",
       "      <td>Final Weight Based on Projection</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>PUFSVYMO</td>\n",
       "      <td>Survey Month</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>PUFSVYYR</td>\n",
       "      <td>Survey Year</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>PUFPSU</td>\n",
       "      <td>Psu Number</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Variable                         Description\n",
       "0    PUFHHNUM  Household Unique Sequential Number\n",
       "1  PUFPWGTPRV    Final Weight Based on Projection\n",
       "2    PUFSVYMO                        Survey Month\n",
       "3    PUFSVYYR                         Survey Year\n",
       "4      PUFPSU                          Psu Number"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load metadata Sheet 1\n",
    "August_2024_metadata = load_dataset(\"2024\", \"August\", \"metadata\", 0)\n",
    "\n",
    "# Call your function\n",
    "variables_df = extract_variables(August_2024_metadata)\n",
    "\n",
    "# View results\n",
    "variables_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2765e519",
   "metadata": {},
   "source": [
    "## Metadata Sheet 2 Function"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5cf97232",
   "metadata": {},
   "source": [
    "<H5> Sample: January 2018 Metadata Sheet 2 (Raw)</H5>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "c0585a33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== January 2018 Metadata Sheet 2 (Raw) ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PUFREG_VS1</th>\n",
       "      <th>Region</th>\n",
       "      <th>Unnamed: 2</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>National Capital Region</td>\n",
       "      <td>13</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Cordillera Administrative Region</td>\n",
       "      <td>14</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Region I - Ilocos Region</td>\n",
       "      <td>1</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Region II - Cagayan Valley</td>\n",
       "      <td>2</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>Region III - Central Luzon</td>\n",
       "      <td>3</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  PUFREG_VS1 Region                        Unnamed: 2 Unnamed: 3  Unnamed: 4  \\\n",
       "0        NaN    NaN           National Capital Region         13         NaN   \n",
       "1        NaN    NaN  Cordillera Administrative Region         14         NaN   \n",
       "2        NaN    NaN          Region I - Ilocos Region          1         NaN   \n",
       "3        NaN    NaN        Region II - Cagayan Valley          2         NaN   \n",
       "4        NaN    NaN        Region III - Central Luzon          3         NaN   \n",
       "\n",
       "  Unnamed: 5  \n",
       "0        NaN  \n",
       "1        NaN  \n",
       "2        NaN  \n",
       "3        NaN  \n",
       "4        NaN  "
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load the second sheet of January 2018 metadata\n",
    "january_2018_metadata_sheet2 = load_dataset(\"2018\", \"January\", \"metadata\", 1)\n",
    "\n",
    "# View the first few rows\n",
    "print(\"=== January 2018 Metadata Sheet 2 (Raw) ===\")\n",
    "january_2018_metadata_sheet2.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b000e17a",
   "metadata": {},
   "source": [
    "### Reshaping Metadata Sheet 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "acb63dd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "def reshape_sheet2_robust(df):\n",
    "    \"\"\"\n",
    "    Convert metadata Sheet 2 (the values dictionary) into a clean, long-format table.\n",
    "\n",
    "    This function reads the sheet exactly as it appears in Excel, without:\n",
    "    - Assuming any header row\n",
    "    - Auto-filling missing values\n",
    "    - Inferencing min/max values\n",
    "    - Guessing variable names\n",
    "\n",
    "    Sheet 2 typically has this layout:\n",
    "        Column A = Variable name (only appears once per block)\n",
    "        Column B = Variable description (blank except at the start of a block)\n",
    "        Column C = Label for each value (required)\n",
    "        Column D = Minimum value (optional)\n",
    "        Column E = Maximum value (optional)\n",
    "        Column F+ = Additional text or category notes (optional)\n",
    "\n",
    "    The function processes rows in order and:\n",
    "        - Carries forward the most recent non-empty variable name (Column A)\n",
    "        - Carries forward the most recent non-empty description (Column B)\n",
    "        - Creates one output row per value label (Column C)\n",
    "        - Leaves missing min/max/additional values as 0\n",
    "        - Reads extra info (Column F onward) if present\n",
    "\n",
    "    Returns:\n",
    "        A clean pandas DataFrame with columns:\n",
    "            Variable\n",
    "            Description\n",
    "            Label\n",
    "            min_value\n",
    "            max_value\n",
    "            additional_value\n",
    "    \"\"\"\n",
    "\n",
    "    reshaped = []\n",
    "\n",
    "    # Ensure all blanks are handled consistently\n",
    "    df = df.fillna('').astype(str)\n",
    "\n",
    "    # Initialize with the first variable and description\n",
    "    current_var = df.iloc[0, 0].strip() or 'UNKNOWN_VAR'\n",
    "    current_desc = df.iloc[0, 1].strip() or ''\n",
    "\n",
    "    # Iterate row-by-row\n",
    "    for idx, row in df.iterrows():\n",
    "        # ---- Column A: Variable name ----\n",
    "        var_candidate = row.iloc[0].strip()\n",
    "        if var_candidate:\n",
    "            current_var = var_candidate\n",
    "\n",
    "        # ---- Column B: Description ----\n",
    "        desc_candidate = row.iloc[1].strip()\n",
    "        if desc_candidate:\n",
    "            current_desc = desc_candidate\n",
    "\n",
    "        # ---- PRE-READ Columns D, E, F (Values) ----\n",
    "        raw_min = row.iloc[3].strip()\n",
    "        raw_max = row.iloc[4].strip()\n",
    "        \n",
    "        # Look for extra values (Column F+)\n",
    "        extra = '0'\n",
    "        if len(row) > 5:\n",
    "            for j in range(5, len(row)):\n",
    "                extra_candidate = row.iloc[j].strip()\n",
    "                if extra_candidate:\n",
    "                    extra = extra_candidate\n",
    "                    break\n",
    "\n",
    "        # ---- Column C: Label ----\n",
    "        label = row.iloc[2].strip()\n",
    "\n",
    "        # FIX: Don't just continue. Check if values exist.\n",
    "        if not label:\n",
    "            # If label is missing BUT we have min, max, or extra -> It's a valid row\n",
    "            if raw_min or raw_max or extra != '0':\n",
    "                label = '0'  # Assign default label\n",
    "            else:\n",
    "                continue     # Skip only if truly empty\n",
    "\n",
    "        # ---- Finalize Min/Max ----\n",
    "        min_value = raw_min if raw_min else '0'\n",
    "        max_value = raw_max if raw_max else '0'\n",
    "\n",
    "        # ---- Append clean record ----\n",
    "        reshaped.append({\n",
    "            \"Variable\": current_var,\n",
    "            \"Description\": current_desc,\n",
    "            \"Label\": label,\n",
    "            \"min_value\": min_value,\n",
    "            \"max_value\": max_value,\n",
    "            \"additional_value\": extra\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(reshaped)\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "#   load_dataset()\n",
    "# ============================================================\n",
    "def load_dataset(year, month, filetype=\"survey\", sheet_number=None):\n",
    "    \"\"\"\n",
    "    Load any dataset (survey or metadata) from the file inventory.\n",
    "\n",
    "    â€¢ For SURVEY CSV: normal pandas.read_csv()\n",
    "    â€¢ For METADATA Excel: read with no header, reshape Sheet 2 automatically\n",
    "    \"\"\"\n",
    "    # Retrieve file information from inventory\n",
    "    file_info = next(\n",
    "        (f for f in inventory[year][month] if f[\"filetype\"] == filetype),\n",
    "        None\n",
    "    )\n",
    "\n",
    "    if not file_info:\n",
    "        raise ValueError(f\"No {filetype} file found for {month} {year}\")\n",
    "\n",
    "    file_path = os.path.join(base_path, year, file_info[\"filename\"])\n",
    "\n",
    "    if filetype == \"survey\":\n",
    "        return pd.read_csv(file_path, low_memory=False)\n",
    "\n",
    "    # Metadata Excel â€” always read with no header\n",
    "    df = pd.read_excel(file_path, sheet_name=sheet_number, header=None)\n",
    "\n",
    "    # Automatic reshaping ONLY for metadata Sheet 2\n",
    "    if sheet_number == 1:\n",
    "        df = reshape_sheet2_robust(df)\n",
    "\n",
    "    return df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "68122521",
   "metadata": {},
   "source": [
    "### Metadata Sheet 2 Reshaped Saving Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "72447c37",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def batch_process_sheet2_metadata(inventory, base_output_path):\n",
    "    \"\"\"\n",
    "    Loops through the inventory to process 'Sheet 2' (Value Codes).\n",
    "    \"\"\"\n",
    "    \n",
    "    # Counters for the summary report\n",
    "    success_count = 0\n",
    "    failure_count = 0\n",
    "    skipped_count = 0\n",
    "    errors_log = []\n",
    "\n",
    "    # 1. Define Main Folder Name\n",
    "    main_folder_name = \"Metadata Sheet 2 CSV's\"\n",
    "    main_folder_path = os.path.join(base_output_path, main_folder_name)\n",
    "    os.makedirs(main_folder_path, exist_ok=True)\n",
    "    \n",
    "    print(\"--- STARTING BATCH PROCESS (SHEET 2) ---\")\n",
    "    print(f\"Target Directory: {main_folder_path}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # 2. Iterate through Inventory\n",
    "    for year, months_data in inventory.items():\n",
    "        \n",
    "        # Create Year Subfolder\n",
    "        year_folder_path = os.path.join(main_folder_path, year)\n",
    "        os.makedirs(year_folder_path, exist_ok=True)\n",
    "        \n",
    "        for month, files_list in months_data.items():\n",
    "            # Skip unmatched files\n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "            \n",
    "            # Check if metadata exists for this month\n",
    "            has_metadata = any(f.get('filetype') == 'metadata' for f in files_list)\n",
    "            \n",
    "            if has_metadata:\n",
    "                try:\n",
    "                    # A. Load & Reshape\n",
    "                    # Your load_dataset function handles the cleaning internally\n",
    "                    clean_df = load_dataset(year, month, \"metadata\", 1)\n",
    "                    \n",
    "                    # B. Generate Filename\n",
    "                    filename = f\"Sheet2_{month}_{year}.csv\"\n",
    "                    full_save_path = os.path.join(year_folder_path, filename)\n",
    "                    \n",
    "                    # C. Save\n",
    "                    clean_df.to_csv(full_save_path, index=False)\n",
    "                    \n",
    "                    print(f\"[OK] Saved: {year}/{filename}\")\n",
    "                    success_count += 1\n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Failed {month} {year}: {e}\")\n",
    "                    errors_log.append(f\"{month} {year}: {str(e)}\")\n",
    "                    failure_count += 1\n",
    "            else:\n",
    "                skipped_count += 1\n",
    "\n",
    "    # 3. Final Report\n",
    "    print(\"\\n\" + \"=\"*40)\n",
    "    print(\"      SHEET 2 PROCESSING SUMMARY\")\n",
    "    print(\"=\"*40)\n",
    "    print(f\"Total Saved:    {success_count}\")\n",
    "    print(f\"Total Failed:   {failure_count}\")\n",
    "    print(f\"Total Skipped:  {skipped_count}\")\n",
    "    print(\"-\" * 40)\n",
    "    \n",
    "    if failure_count == 0:\n",
    "        print(\"STATUS: COMPLETE SUCCESS\")\n",
    "        print(f\"Files are syncing to: {main_folder_path}\")\n",
    "    else:\n",
    "        print(\"STATUS: COMPLETED WITH ERRORS\")\n",
    "        for err in errors_log:\n",
    "            print(f\" - {err}\")\n",
    "    print(\"=\"*40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "aea6147e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING BATCH PROCESS (SHEET 2) ---\n",
      "Target Directory: /Users/neilkeannedelavega/Library/CloudStorage/GoogleDrive-shaniakeith23@gmail.com/My Drive/Labor Force Survey/Metadata Sheet 2 CSV's\n",
      "--------------------------------------------------\n",
      "[OK] Saved: 2018/Sheet2_January_2018.csv\n",
      "[OK] Saved: 2018/Sheet2_October_2018.csv\n",
      "[OK] Saved: 2018/Sheet2_April_2018.csv\n",
      "[OK] Saved: 2018/Sheet2_July_2018.csv\n",
      "[OK] Saved: 2019/Sheet2_April_2019.csv\n",
      "[OK] Saved: 2019/Sheet2_July_2019.csv\n",
      "[OK] Saved: 2019/Sheet2_October_2019.csv\n",
      "[OK] Saved: 2019/Sheet2_January_2019.csv\n",
      "[OK] Saved: 2022/Sheet2_December_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_February_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_August_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_March_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_September_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_October_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_January_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_May_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_November_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_July_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_June_2022.csv\n",
      "[OK] Saved: 2022/Sheet2_April_2022.csv\n",
      "[OK] Saved: 2023/Sheet2_December_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_June_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_February_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_July_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_November_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_April_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_September_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_January_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_May_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_October_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_August_2023.csv\n",
      "[OK] Saved: 2023/Sheet2_March_2023.csv\n",
      "[OK] Saved: 2024/Sheet2_February_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_June_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_April_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_July_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_May_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_January_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_March_2024.csv\n",
      "[OK] Saved: 2024/Sheet2_August_2024.csv\n",
      "\n",
      "========================================\n",
      "      SHEET 2 PROCESSING SUMMARY\n",
      "========================================\n",
      "Total Saved:    40\n",
      "Total Failed:   0\n",
      "Total Skipped:  0\n",
      "----------------------------------------\n",
      "STATUS: COMPLETE SUCCESS\n",
      "Files are syncing to: /Users/neilkeannedelavega/Library/CloudStorage/GoogleDrive-shaniakeith23@gmail.com/My Drive/Labor Force Survey/Metadata Sheet 2 CSV's\n",
      "========================================\n"
     ]
    }
   ],
   "source": [
    "# Run the processor\n",
    "# (Requires 'inventory' and 'load_dataset' to be defined in your environment)\n",
    "batch_process_sheet2_metadata(inventory, base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1009e2b",
   "metadata": {},
   "source": [
    "#### Verifying if the variable counts of Reshaped Metadata Sheet 2 and Original matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "050a0a45",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def batch_verify_sheet2_variable_and_label_count(inventory, base_path):\n",
    "    \"\"\"\n",
    "    Batch verify Sheet 2 metadata (values dictionary) across years/months.\n",
    "    Compares:\n",
    "      â€¢ Unique variable count (raw vs reshaped)\n",
    "      â€¢ Label count per variable (raw vs reshaped)\n",
    "    Prints mismatches immediately and returns a summary DataFrame.\n",
    "    \"\"\"\n",
    "    all_results = []\n",
    "\n",
    "    for year, months_data in inventory.items():\n",
    "        for month, files_list in months_data.items():\n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "\n",
    "            # --- Load raw Sheet 2 ---\n",
    "            # NOTE: Ensure 'load_dataset' is defined in your previous cells\n",
    "            try:\n",
    "                raw_df = load_dataset(year, month, \"metadata\", sheet_number=1)\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {month} {year}: Could not load raw Sheet 2 ({e})\")\n",
    "                continue\n",
    "\n",
    "            # --- Load reshaped Sheet 2 CSV ---\n",
    "            reshaped_path = os.path.join(\n",
    "                base_path, \n",
    "                \"Metadata Sheet 2 CSV's\", \n",
    "                year, \n",
    "                f\"Sheet2_{month}_{year}.csv\"\n",
    "            )\n",
    "            \n",
    "            if not os.path.exists(reshaped_path):\n",
    "                print(f\"[ERROR] {month} {year}: Reshaped Sheet 2 CSV missing!\")\n",
    "                continue\n",
    "\n",
    "            reshaped_df = pd.read_csv(reshaped_path, dtype=str).fillna(\"\")\n",
    "\n",
    "            # --- Count unique variables ---\n",
    "            raw_vars = raw_df.iloc[:, 0].astype(str).str.strip()\n",
    "            raw_vars = raw_vars[raw_vars != '']  # ignore empty\n",
    "            raw_unique_vars = pd.Index(raw_vars).unique()\n",
    "\n",
    "            resh_vars = reshaped_df['Variable'].astype(str).str.strip()\n",
    "            resh_unique_vars = pd.Index(resh_vars).unique()\n",
    "\n",
    "            # Check variable count mismatch\n",
    "            variable_mismatch = len(raw_unique_vars) != len(resh_unique_vars)\n",
    "            if variable_mismatch:\n",
    "                print(f\"[VARIABLE COUNT MISMATCH] {month} {year}: Raw={len(raw_unique_vars)}, Reshaped={len(resh_unique_vars)}\")\n",
    "\n",
    "            # --- Count labels per variable ---\n",
    "            label_mismatches = []\n",
    "\n",
    "            for var in raw_unique_vars:\n",
    "                # Raw: select rows matching variable\n",
    "                raw_rows = raw_df[raw_df.iloc[:, 0].astype(str).str.strip() == var]\n",
    "\n",
    "                # Count non-empty label cells safely (cols 2 to 6 usually contain labels/values)\n",
    "                raw_label_count = raw_rows.iloc[:, 2:6].astype(str).apply(\n",
    "                    lambda x: x.str.strip().ne('').any(), axis=1\n",
    "                ).sum()\n",
    "\n",
    "                # Reshaped: count rows per variable\n",
    "                resh_label_count = reshaped_df[reshaped_df['Variable'].astype(str).str.strip() == var].shape[0]\n",
    "\n",
    "                if raw_label_count != resh_label_count:\n",
    "                    label_mismatches.append({\n",
    "                        \"Variable\": var,\n",
    "                        \"Raw_Label_Count\": raw_label_count,\n",
    "                        \"Reshaped_Label_Count\": resh_label_count\n",
    "                    })\n",
    "\n",
    "            # --- Print immediate label mismatches ---\n",
    "            for m in label_mismatches:\n",
    "                print(f\"[LABEL COUNT MISMATCH] {month} {year} - Variable: {m['Variable']} | Raw={m['Raw_Label_Count']} vs Reshaped={m['Reshaped_Label_Count']}\")\n",
    "\n",
    "            # --- Record summary ---\n",
    "            all_results.append({\n",
    "                \"Year\": year,\n",
    "                \"Month\": month,\n",
    "                \"Raw_Variable_Count\": len(raw_unique_vars),\n",
    "                \"Reshaped_Variable_Count\": len(resh_unique_vars),\n",
    "                \"Variable_Count_Status\": \"PASS\" if not variable_mismatch else \"FAIL\",\n",
    "                \"Label_Count_Mismatches\": len(label_mismatches)\n",
    "            })\n",
    "\n",
    "    # --- Final Summary Report ---\n",
    "    df_summary = pd.DataFrame(all_results).sort_values(['Year', 'Month']).reset_index(drop=True)\n",
    "    \n",
    "    var_fails = (df_summary[\"Variable_Count_Status\"] == \"FAIL\").sum()\n",
    "    label_fails = df_summary[\"Label_Count_Mismatches\"].sum()\n",
    "\n",
    "    if var_fails == 0 and label_fails == 0:\n",
    "        print(\"\\nSUCCESS: All Sheet 2 variables and labels have been reshaped correctly across the batch!\\n\")\n",
    "    else:\n",
    "        print(f\"\\nCompleted with issues: {var_fails} variable count mismatches, {label_fails} label mismatches.\\n\")\n",
    "\n",
    "    return df_summary\n",
    "\n",
    "def verify_sheet2_content(original_df, reshaped_df):\n",
    "    \"\"\"\n",
    "    Compare original Sheet 2 with reshaped version.\n",
    "    Checks: Variables, Descriptions, Labels, Min/Max/Additional values.\n",
    "    Ignores row order.\n",
    "    \"\"\"\n",
    "    # Normalize to string\n",
    "    original = original_df.fillna(\"\").astype(str)\n",
    "    reshaped = reshaped_df.fillna(\"\").astype(str)\n",
    "\n",
    "    # --- Extract original as dict ---\n",
    "    def build_original_dict(df):\n",
    "        data = {}\n",
    "        current_var = \"\"\n",
    "        current_desc = \"\"\n",
    "        for _, row in df.iterrows():\n",
    "            colA = row.iloc[0].strip()\n",
    "            colB = row.iloc[1].strip()\n",
    "            colC = row.iloc[2].strip()\n",
    "            \n",
    "            if colA: current_var = colA\n",
    "            if colB: current_desc = colB\n",
    "            \n",
    "            if not colC: continue # Skip if label is empty\n",
    "            \n",
    "            minv = row.iloc[3].strip() if len(row) > 3 else \"\"\n",
    "            maxv = row.iloc[4].strip() if len(row) > 4 else \"\"\n",
    "            extra = \"\"\n",
    "            \n",
    "            # Find extra value if it exists beyond standard columns\n",
    "            if len(row) > 5:\n",
    "                for j in range(5, len(row)):\n",
    "                    if row.iloc[j].strip():\n",
    "                        extra = row.iloc[j].strip()\n",
    "                        break\n",
    "                        \n",
    "            if current_var not in data:\n",
    "                data[current_var] = []\n",
    "            \n",
    "            data[current_var].append({\n",
    "                \"Description\": current_desc,\n",
    "                \"Label\": colC,\n",
    "                \"min_value\": minv,\n",
    "                \"max_value\": maxv,\n",
    "                \"additional_value\": extra\n",
    "            })\n",
    "        return data\n",
    "\n",
    "    orig_dict = build_original_dict(original)\n",
    "\n",
    "    # --- Extract reshaped as dict ---\n",
    "    resh_dict = {\n",
    "        var: group.drop(columns=\"Variable\").to_dict(\"records\")\n",
    "        for var, group in reshaped.groupby(\"Variable\")\n",
    "    }\n",
    "\n",
    "    # --- Verification ---\n",
    "    errors = []\n",
    "    orig_vars = set(orig_dict.keys())\n",
    "    resh_vars = set(resh_dict.keys())\n",
    "\n",
    "    missing_vars = orig_vars - resh_vars\n",
    "    extra_vars = resh_vars - orig_vars\n",
    "    \n",
    "    if missing_vars: errors.append(f\"Missing variables in reshaped: {missing_vars}\")\n",
    "    if extra_vars: errors.append(f\"Extra variables in reshaped: {extra_vars}\")\n",
    "\n",
    "    # Detailed label/content comparison\n",
    "    for var in orig_vars & resh_vars:\n",
    "        orig_records = orig_dict[var]\n",
    "        resh_records = resh_dict[var]\n",
    "        \n",
    "        orig_set = {(d[\"Label\"], d[\"min_value\"], d[\"max_value\"], d[\"additional_value\"]) for d in orig_records}\n",
    "        resh_set = {(d[\"Label\"], d[\"min_value\"], d[\"max_value\"], d[\"additional_value\"]) for d in resh_records}\n",
    "        \n",
    "        missing_rec = orig_set - resh_set\n",
    "        extra_rec = resh_set - orig_set\n",
    "        \n",
    "        if missing_rec: errors.append(f\"[{var}] Missing records: {missing_rec}\")\n",
    "        if extra_rec: errors.append(f\"[{var}] Extra records: {extra_rec}\")\n",
    "\n",
    "    if not errors:\n",
    "        return \"SUCCESS\"\n",
    "    else:\n",
    "        return \"MISMATCH FOUND:\\n\" + \"\\n\".join(errors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "e2de0afe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- Starting Batch Structure Verification ---\n",
      "\n",
      "SUCCESS: All Sheet 2 variables and labels have been reshaped correctly across the batch!\n",
      "\n",
      "\n",
      "[PASS] Structural batch check passed for all files.\n",
      "\n",
      "--- Starting Deep Content Verification (All Files) ---\n",
      "Verifying: January 2018... OK\n",
      "Verifying: October 2018... OK\n",
      "Verifying: April 2018... OK\n",
      "Verifying: July 2018... OK\n",
      "Verifying: April 2019... OK\n",
      "Verifying: July 2019... OK\n",
      "Verifying: October 2019... OK\n",
      "Verifying: January 2019... OK\n",
      "Verifying: December 2022... OK\n",
      "Verifying: February 2022... OK\n",
      "Verifying: August 2022... OK\n",
      "Verifying: March 2022... OK\n",
      "Verifying: September 2022... OK\n",
      "Verifying: October 2022... OK\n",
      "Verifying: January 2022... OK\n",
      "Verifying: May 2022... OK\n",
      "Verifying: November 2022... OK\n",
      "Verifying: July 2022... OK\n",
      "Verifying: June 2022... OK\n",
      "Verifying: April 2022... OK\n",
      "Verifying: December 2023... OK\n",
      "Verifying: June 2023... OK\n",
      "Verifying: February 2023... OK\n",
      "Verifying: July 2023... OK\n",
      "Verifying: November 2023... OK\n",
      "Verifying: April 2023... OK\n",
      "Verifying: September 2023... OK\n",
      "Verifying: January 2023... OK\n",
      "Verifying: May 2023... OK\n",
      "Verifying: October 2023... OK\n",
      "Verifying: August 2023... OK\n",
      "Verifying: March 2023... OK\n",
      "Verifying: February 2024... OK\n",
      "Verifying: June 2024... OK\n",
      "Verifying: April 2024... OK\n",
      "Verifying: July 2024... OK\n",
      "Verifying: May 2024... OK\n",
      "Verifying: January 2024... OK\n",
      "Verifying: March 2024... OK\n",
      "Verifying: August 2024... OK\n",
      "\n",
      "========================================\n",
      "FINAL VERIFICATION REPORT\n",
      "========================================\n",
      "Total Files Checked: 40\n",
      "Passed: 40\n",
      "Issues: 0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# AUTOMATION START\n",
    "# ==========================================\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "# 1. Run the Batch Verifier (Counts & Structure)\n",
    "# This quickly checks if the number of variables and labels match.\n",
    "print(\"--- Starting Batch Structure Verification ---\")\n",
    "batch_summary_df = batch_verify_sheet2_variable_and_label_count(inventory, base_path)\n",
    "\n",
    "# Print a quick summary of the batch check\n",
    "if not batch_summary_df.empty:\n",
    "    fails = batch_summary_df[batch_summary_df['Variable_Count_Status'] == 'FAIL']\n",
    "    if not fails.empty:\n",
    "        print(f\"\\n[WARNING] Found {len(fails)} structural failures in the following months:\")\n",
    "        print(fails[['Year', 'Month', 'Variable_Count_Status']])\n",
    "    else:\n",
    "        print(\"\\n[PASS] Structural batch check passed for all files.\")\n",
    "\n",
    "# 2. Run Deep Content Verification (Every Month/Year)\n",
    "# This checks the actual text (labels, descriptions, values) for every file.\n",
    "print(\"\\n--- Starting Deep Content Verification (All Files) ---\")\n",
    "\n",
    "deep_verification_results = []\n",
    "\n",
    "for year, months_data in inventory.items():\n",
    "    for month, files_list in months_data.items():\n",
    "        if month == \"Unmatched\":\n",
    "            continue\n",
    "\n",
    "        print(f\"Verifying: {month} {year}...\", end=\" \")\n",
    "\n",
    "        try:\n",
    "            # --- Load Raw Original ---\n",
    "            # Ensure load_dataset is defined in your environment\n",
    "            original_df = load_dataset(year, month, \"metadata\", sheet_number=1)\n",
    "            \n",
    "            # --- Load Reshaped CSV ---\n",
    "            reshaped_path = os.path.join(\n",
    "                base_path, \n",
    "                \"Metadata Sheet 2 CSV's\", \n",
    "                year, \n",
    "                f\"Sheet2_{month}_{year}.csv\"\n",
    "            )\n",
    "            \n",
    "            if not os.path.exists(reshaped_path):\n",
    "                print(\"SKIPPED (Reshaped file missing)\")\n",
    "                deep_verification_results.append({\"Year\": year, \"Month\": month, \"Status\": \"Missing File\"})\n",
    "                continue\n",
    "\n",
    "            reshaped_df = pd.read_csv(reshaped_path, dtype=str).fillna(\"\")\n",
    "            \n",
    "            # --- Run Verification ---\n",
    "            # Using the verify_sheet2_content function from the first code block\n",
    "            result_message = verify_sheet2_content(original_df, reshaped_df)\n",
    "            \n",
    "            if result_message == \"SUCCESS\":\n",
    "                print(\"OK\")\n",
    "                deep_verification_results.append({\"Year\": year, \"Month\": month, \"Status\": \"PASS\"})\n",
    "            else:\n",
    "                print(\"MISMATCH FOUND\")\n",
    "                print(f\"   -> {result_message}\")\n",
    "                deep_verification_results.append({\"Year\": year, \"Month\": month, \"Status\": \"FAIL\", \"Error\": result_message})\n",
    "                \n",
    "        except Exception as e:\n",
    "            print(f\"ERROR ({e})\")\n",
    "            deep_verification_results.append({\"Year\": year, \"Month\": month, \"Status\": \"ERROR\", \"Error\": str(e)})\n",
    "\n",
    "# --- Final Report ---\n",
    "print(\"\\n\" + \"=\"*40)\n",
    "print(\"FINAL VERIFICATION REPORT\")\n",
    "print(\"=\"*40)\n",
    "results_df = pd.DataFrame(deep_verification_results)\n",
    "\n",
    "if not results_df.empty:\n",
    "    pass_count = len(results_df[results_df['Status'] == 'PASS'])\n",
    "    fail_count = len(results_df[results_df['Status'] != 'PASS'])\n",
    "    print(f\"Total Files Checked: {len(results_df)}\")\n",
    "    print(f\"Passed: {pass_count}\")\n",
    "    print(f\"Issues: {fail_count}\")\n",
    "\n",
    "    if fail_count > 0:\n",
    "        print(\"\\nFiles with Issues:\")\n",
    "        print(results_df[results_df['Status'] != 'PASS'][['Year', 'Month', 'Status']])\n",
    "else:\n",
    "    print(\"No files were processed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39499d9a",
   "metadata": {},
   "source": [
    "--------"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28e67a98",
   "metadata": {},
   "source": [
    "## Sheet 1 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96788a2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_dataset(year, month, filetype=\"survey\"):\n",
    "    \"\"\"\n",
    "    Locates and loads a dataset file (CSV or Excel) from the global inventory\n",
    "    based on the year, month, and requested type.\n",
    "    \"\"\"\n",
    "    # Relies on the global 'inventory' dictionary existing in your notebook\n",
    "    if year not in inventory or month not in inventory[year]:\n",
    "        raise ValueError(f\"Error: No records found in inventory for {month} {year}.\")\n",
    "\n",
    "\n",
    "    files = inventory[year][month]\n",
    "\n",
    "\n",
    "    # Locate the specific file type\n",
    "    found_file = next((f for f in files if f['filetype'] == filetype), None)\n",
    "\n",
    "\n",
    "    if not found_file:\n",
    "        raise FileNotFoundError(f\"Error: No {filetype} file found for {month} {year}.\")\n",
    "\n",
    "\n",
    "    # Construct the full file path using the global base_path\n",
    "    file_path = os.path.join(base_path, year, found_file['filename'])\n",
    "\n",
    "\n",
    "    # Load appropriate file format based on type\n",
    "    if filetype == \"survey\":\n",
    "        return pd.read_csv(file_path, low_memory=False)\n",
    "    else:\n",
    "        return pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def load_clean_sheet1(year, month):\n",
    "    \"\"\"\n",
    "    Loads the processed variable definitions (Sheet 1) from the\n",
    "    'Metadata Sheet 1 CSV's' folder in Google Drive.\n",
    "    \"\"\"\n",
    "    folder_name = \"Metadata Sheet 1 CSV's\"\n",
    "    filename = f\"Sheet1_{month}_{year}.csv\"\n",
    "    file_path = os.path.join(base_path, folder_name, year, filename)\n",
    "\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Error: Processed metadata file not found at {file_path}\")\n",
    "\n",
    "\n",
    "    return pd.read_csv(file_path)\n",
    "\n",
    "\n",
    "def apply_metadata_headers(survey_df, metadata_sheet1_df, year=\"Unknown\", month=\"Survey\"):\n",
    "    \"\"\"\n",
    "    Renames the columns of the raw survey dataset to human-readable labels\n",
    "    using the provided metadata definitions. Prints a formal status report.\n",
    "    \"\"\"\n",
    "    # 1. Standardization\n",
    "    metadata_sheet1_df['Variable'] = metadata_sheet1_df['Variable'].astype(str).str.strip()\n",
    "    metadata_sheet1_df['Description'] = metadata_sheet1_df['Description'].astype(str).str.strip()\n",
    "\n",
    "\n",
    "    # 2. Map Generation\n",
    "    header_map = dict(zip(metadata_sheet1_df['Variable'], metadata_sheet1_df['Description']))\n",
    "\n",
    "\n",
    "    # 3. Analysis\n",
    "    original_cols = set(survey_df.columns)\n",
    "    mapped_cols = set(header_map.keys())\n",
    "\n",
    "\n",
    "    translated_cols = original_cols.intersection(mapped_cols)\n",
    "    untranslated_cols = original_cols - mapped_cols\n",
    "\n",
    "\n",
    "    total_columns = len(original_cols)\n",
    "    translated_count = len(translated_cols)\n",
    "    untranslated_count = len(untranslated_cols)\n",
    "\n",
    "\n",
    "    # 4. Execution\n",
    "    renamed_df = survey_df.rename(columns=header_map)\n",
    "\n",
    "\n",
    "    # 5. Reporting\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"METADATA TRANSLATION REPORT: {month.upper()} {year}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total Columns Detected:       {total_columns}\")\n",
    "    print(f\"Successfully Decoded:         {translated_count}\")\n",
    "    print(f\"Remaining as Raw Codes:       {untranslated_count}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "\n",
    "    if untranslated_count == 0:\n",
    "        print(\"Status: SUCCESS (100% Metadata Coverage)\")\n",
    "        print(\"All column headers have been successfully translated to descriptions.\")\n",
    "    else:\n",
    "        print(\"Status: PARTIAL SUCCESS\")\n",
    "        print(\"The following columns retained their original codes because\")\n",
    "        print(\"no matching definition was found in the metadata library:\")\n",
    "        # Sort the list for easier reading\n",
    "        print(f\"\\nList of Untranslated Codes: {sorted(list(untranslated_cols))}\")\n",
    "\n",
    "\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "\n",
    "\n",
    "    return renamed_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67fb9efd",
   "metadata": {},
   "source": [
    "## Automation for Sheet 1 Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "47d6fa22",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch_header_translation(inventory, base_path):\n",
    "    \"\"\"\n",
    "    Iterates through the inventory, applies header translation to all survey CSVs,\n",
    "    and saves the results to a temporary output folder.\n",
    "    \"\"\"\n",
    "    output_folder_name = \"Header Encoded Surveys\"\n",
    "    output_base_path = os.path.join(base_path, output_folder_name)\n",
    "    os.makedirs(output_base_path, exist_ok=True)\n",
    "\n",
    "\n",
    "    print(\"================================================\")\n",
    "    print(\"STARTING BATCH HEADER TRANSLATION\")\n",
    "    print(f\"Output Directory: {output_base_path}\")\n",
    "    print(\"================================================\\n\")\n",
    "\n",
    "\n",
    "    success_count = 0\n",
    "    skip_count = 0\n",
    "    error_count = 0\n",
    "\n",
    "\n",
    "    # Loop through the existing 'inventory' dictionary\n",
    "    for year in sorted(inventory.keys()):\n",
    "       \n",
    "        # Create Year subfolder in output directory\n",
    "        year_output_path = os.path.join(output_base_path, year)\n",
    "        os.makedirs(year_output_path, exist_ok=True)\n",
    "       \n",
    "        for month in inventory[year].keys():\n",
    "            if month == \"Unmatched\": continue\n",
    "           \n",
    "            print(f\"Processing: {month.upper()} {year}...\")\n",
    "           \n",
    "            try:\n",
    "                # 1. Check if a raw survey CSV exists for this month\n",
    "                files_list = inventory[year][month]\n",
    "                survey_file_data = next((f for f in files_list if f['filetype'] == 'survey'), None)\n",
    "               \n",
    "                if not survey_file_data:\n",
    "                    print(\"   [SKIP] No raw survey CSV found.\")\n",
    "                    skip_count += 1\n",
    "                    continue\n",
    "\n",
    "\n",
    "                # 2. Load Data\n",
    "                # We use the load functions defined above\n",
    "                raw_survey = load_dataset(year, month, \"survey\")\n",
    "               \n",
    "                # This will raise FileNotFoundError if the clean sheet 1 doesn't exist\n",
    "                clean_metadata = load_clean_sheet1(year, month)\n",
    "               \n",
    "                # 3. Translate\n",
    "                # We pass year/month explicitly so the report title is correct\n",
    "                decoded_df = apply_metadata_headers(raw_survey, clean_metadata, year, month)\n",
    "               \n",
    "                # 4. Save to \"Temporary\" Folder using ORIGINAL FILENAME\n",
    "                # We extract the actual filename (e.g. \"JANUARY_2018.CSV\") from the inventory data\n",
    "                original_filename = survey_file_data['filename']\n",
    "                save_path = os.path.join(year_output_path, original_filename)\n",
    "               \n",
    "                decoded_df.to_csv(save_path, index=False)\n",
    "                print(f\"   [OK] Saved File: {original_filename}\")\n",
    "                success_count += 1\n",
    "               \n",
    "            except FileNotFoundError:\n",
    "                print(f\"   [SKIP] Missing Metadata Sheet 1 CSV for {month} {year}.\")\n",
    "                skip_count += 1\n",
    "            except Exception as e:\n",
    "                print(f\"   [ERROR] Failed to process: {e}\")\n",
    "                error_count += 1\n",
    "           \n",
    "            print(\"-\" * 40)\n",
    "\n",
    "\n",
    "    print(\"\\n================================================\")\n",
    "    print(\"BATCH PROCESS COMPLETE\")\n",
    "    print(f\"   Successful: {success_count}\")\n",
    "    print(f\"   Skipped:    {skip_count}\")\n",
    "    print(f\"   Errors:     {error_count}\")\n",
    "    print(\"================================================\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "ea1bef4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "STARTING BATCH HEADER TRANSLATION\n",
      "Output Directory: /Users/neilkeannedelavega/Library/CloudStorage/GoogleDrive-shaniakeith23@gmail.com/My Drive/Labor Force Survey/Header Encoded Surveys\n",
      "================================================\n",
      "\n",
      "Processing: JANUARY 2018...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JANUARY 2018\n",
      "============================================================\n",
      "Total Columns Detected:       50\n",
      "Successfully Decoded:         50\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JANUARY_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2018...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: OCTOBER 2018\n",
      "============================================================\n",
      "Total Columns Detected:       51\n",
      "Successfully Decoded:         51\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: OCTOBER_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2018...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: APRIL 2018\n",
      "============================================================\n",
      "Total Columns Detected:       50\n",
      "Successfully Decoded:         50\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: APRIL_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2018...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JULY 2018\n",
      "============================================================\n",
      "Total Columns Detected:       51\n",
      "Successfully Decoded:         51\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JULY_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2019...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: APRIL 2019\n",
      "============================================================\n",
      "Total Columns Detected:       49\n",
      "Successfully Decoded:         49\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: APRIL_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2019...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JULY 2019\n",
      "============================================================\n",
      "Total Columns Detected:       49\n",
      "Successfully Decoded:         49\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JULY_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2019...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: OCTOBER 2019\n",
      "============================================================\n",
      "Total Columns Detected:       49\n",
      "Successfully Decoded:         49\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: OCTOBER_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2019...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JANUARY 2019\n",
      "============================================================\n",
      "Total Columns Detected:       49\n",
      "Successfully Decoded:         49\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JANUARY_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: DECEMBER 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: DECEMBER 2022\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: DECEMBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: FEBRUARY 2022\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: FEBRUARY_2022.csv\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: AUGUST 2022\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: AUGUST_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: MARCH 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: MARCH 2022\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: MARCH_2022.csv\n",
      "----------------------------------------\n",
      "Processing: SEPTEMBER 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: SEPTEMBER 2022\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: SEPTEMBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: OCTOBER 2022\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: OCTOBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JANUARY 2022\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JANUARY_2022.csv\n",
      "----------------------------------------\n",
      "Processing: MAY 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: MAY 2022\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: MAY_2022.csv\n",
      "----------------------------------------\n",
      "Processing: NOVEMBER 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: NOVEMBER 2022\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: NOVEMBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JULY 2022\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JULY_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: JUNE 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JUNE 2022\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JUNE_2022.csv\n",
      "----------------------------------------\n",
      "Processing: APRIL 2022...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: APRIL 2022\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: APRIL_2022.csv\n",
      "----------------------------------------\n",
      "Processing: DECEMBER 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: DECEMBER 2023\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: DECEMBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: JUNE 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JUNE 2023\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JUNE_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: FEBRUARY 2023\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: FEBRUARY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JULY 2023\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JULY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: NOVEMBER 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: NOVEMBER 2023\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: NOVEMBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: APRIL 2023\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: APRIL_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: SEPTEMBER 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: SEPTEMBER 2023\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: SEPTEMBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JANUARY 2023\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JANUARY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: MAY 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: MAY 2023\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: MAY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: OCTOBER 2023\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: OCTOBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: AUGUST 2023\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: AUGUST_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: MARCH 2023...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: MARCH 2023\n",
      "============================================================\n",
      "Total Columns Detected:       42\n",
      "Successfully Decoded:         42\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: MARCH_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: FEBRUARY 2024\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: FEBRUARY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: JUNE 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JUNE 2024\n",
      "============================================================\n",
      "Total Columns Detected:       40\n",
      "Successfully Decoded:         40\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JUNE_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: APRIL 2024\n",
      "============================================================\n",
      "Total Columns Detected:       51\n",
      "Successfully Decoded:         51\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: APRIL_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JULY 2024\n",
      "============================================================\n",
      "Total Columns Detected:       51\n",
      "Successfully Decoded:         51\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JULY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: MAY 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: MAY 2024\n",
      "============================================================\n",
      "Total Columns Detected:       40\n",
      "Successfully Decoded:         40\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: MAY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: JANUARY 2024\n",
      "============================================================\n",
      "Total Columns Detected:       52\n",
      "Successfully Decoded:         52\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: JANUARY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: MARCH 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: MARCH 2024\n",
      "============================================================\n",
      "Total Columns Detected:       41\n",
      "Successfully Decoded:         41\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: MARCH_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2024...\n",
      "\n",
      "============================================================\n",
      "METADATA TRANSLATION REPORT: AUGUST 2024\n",
      "============================================================\n",
      "Total Columns Detected:       40\n",
      "Successfully Decoded:         40\n",
      "Remaining as Raw Codes:       0\n",
      "------------------------------------------------------------\n",
      "Status: SUCCESS (100% Metadata Coverage)\n",
      "All column headers have been successfully translated to descriptions.\n",
      "============================================================\n",
      "\n",
      "   [OK] Saved File: AUGUST_2024.CSV\n",
      "----------------------------------------\n",
      "\n",
      "================================================\n",
      "BATCH PROCESS COMPLETE\n",
      "   Successful: 40\n",
      "   Skipped:    0\n",
      "   Errors:     0\n",
      "================================================\n"
     ]
    }
   ],
   "source": [
    "if __name__ == \"__main__\":\n",
    "    if 'inventory' in locals() and 'base_path' in locals():\n",
    "        run_batch_header_translation(inventory, base_path)\n",
    "    else:\n",
    "        print(\"Skipping execution: 'inventory' or 'base_path' not found in scope.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "8396c71f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def verify_header_decoding_integrity(inventory, base_path):\n",
    "    \"\"\"\n",
    "    Checks if all raw survey columns have been successfully decoded\n",
    "    using metadata Sheet 1.\n",
    "    \n",
    "    Returns a DataFrame with:\n",
    "    Year | Month | Raw Headers Count | Decoded Headers Count | Integrity Status\n",
    "    \"\"\"\n",
    "\n",
    "    results = []\n",
    "\n",
    "    for year, months_data in inventory.items():\n",
    "        for month, files_list in months_data.items():\n",
    "\n",
    "            if month == \"Unmatched\":\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                # ---- Load raw survey ----\n",
    "                raw_df = load_dataset(year, month, \"survey\")\n",
    "                raw_headers = list(raw_df.columns)\n",
    "                raw_count = len(raw_headers)\n",
    "\n",
    "                # ---- Load decoded metadata Sheet 1 ----\n",
    "                meta_df = load_clean_sheet1(year, month)\n",
    "                meta_df['Variable'] = meta_df['Variable'].astype(str).str.strip()\n",
    "                meta_df['Description'] = meta_df['Description'].astype(str).str.strip()\n",
    "\n",
    "                # Build mapping dict\n",
    "                header_map = dict(zip(meta_df['Variable'], meta_df['Description']))\n",
    "\n",
    "                # ---- Count decoded columns ----\n",
    "                decoded_count = sum(col in header_map for col in raw_headers)\n",
    "\n",
    "                # ---- Determine integrity ----\n",
    "                status = \"PASS\" if raw_count == decoded_count else \"FAIL\"\n",
    "\n",
    "                results.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Raw Headers Count\": raw_count,\n",
    "                    \"Decoded Headers Count\": decoded_count,\n",
    "                    \"Integrity Status\": status\n",
    "                })\n",
    "\n",
    "            except Exception as e:\n",
    "                # Any error â†’ FAIL\n",
    "                results.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Raw Headers Count\": \"ERROR\",\n",
    "                    \"Decoded Headers Count\": \"ERROR\",\n",
    "                    \"Integrity Status\": f\"FAIL ({e})\"\n",
    "                })\n",
    "                continue\n",
    "\n",
    "    result_df = pd.DataFrame(results)\n",
    "\n",
    "    print(\"\\n===== HEADER DECODING INTEGRITY CHECK COMPLETE =====\")\n",
    "    \n",
    "    total_failures = (result_df[\"Integrity Status\"] != \"PASS\").sum()\n",
    "\n",
    "    if total_failures == 0:\n",
    "        print(\"SUCCESS: All survey column headers have been fully decoded.\")\n",
    "    else:\n",
    "        print(f\"Completed with {total_failures} months failing integrity checks.\")\n",
    "\n",
    "    print(\"====================================================\\n\")\n",
    "\n",
    "    return result_df.sort_values([\"Year\", \"Month\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4982484",
   "metadata": {},
   "source": [
    "#### Checking if all column headers were decoded successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "df006e0a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== HEADER DECODING INTEGRITY CHECK COMPLETE =====\n",
      "SUCCESS: All survey column headers have been fully decoded.\n",
      "====================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Raw Headers Count</th>\n",
       "      <th>Decoded Headers Count</th>\n",
       "      <th>Integrity Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>50</td>\n",
       "      <td>50</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>July</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>April</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>January</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>July</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>October</td>\n",
       "      <td>49</td>\n",
       "      <td>49</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022</td>\n",
       "      <td>April</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>August</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022</td>\n",
       "      <td>December</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022</td>\n",
       "      <td>February</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022</td>\n",
       "      <td>January</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022</td>\n",
       "      <td>July</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022</td>\n",
       "      <td>June</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022</td>\n",
       "      <td>March</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022</td>\n",
       "      <td>May</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022</td>\n",
       "      <td>November</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022</td>\n",
       "      <td>October</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022</td>\n",
       "      <td>September</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023</td>\n",
       "      <td>April</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023</td>\n",
       "      <td>August</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023</td>\n",
       "      <td>December</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023</td>\n",
       "      <td>February</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023</td>\n",
       "      <td>January</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023</td>\n",
       "      <td>July</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023</td>\n",
       "      <td>June</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023</td>\n",
       "      <td>March</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023</td>\n",
       "      <td>May</td>\n",
       "      <td>42</td>\n",
       "      <td>42</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023</td>\n",
       "      <td>November</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023</td>\n",
       "      <td>October</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023</td>\n",
       "      <td>September</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2024</td>\n",
       "      <td>April</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2024</td>\n",
       "      <td>August</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2024</td>\n",
       "      <td>February</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2024</td>\n",
       "      <td>January</td>\n",
       "      <td>52</td>\n",
       "      <td>52</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024</td>\n",
       "      <td>July</td>\n",
       "      <td>51</td>\n",
       "      <td>51</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2024</td>\n",
       "      <td>June</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2024</td>\n",
       "      <td>March</td>\n",
       "      <td>41</td>\n",
       "      <td>41</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>40</td>\n",
       "      <td>40</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year      Month  Raw Headers Count  Decoded Headers Count Integrity Status\n",
       "0   2018      April                 50                     50             PASS\n",
       "1   2018    January                 50                     50             PASS\n",
       "2   2018       July                 51                     51             PASS\n",
       "3   2018    October                 51                     51             PASS\n",
       "4   2019      April                 49                     49             PASS\n",
       "5   2019    January                 49                     49             PASS\n",
       "6   2019       July                 49                     49             PASS\n",
       "7   2019    October                 49                     49             PASS\n",
       "8   2022      April                 52                     52             PASS\n",
       "9   2022     August                 42                     42             PASS\n",
       "10  2022   December                 42                     42             PASS\n",
       "11  2022   February                 41                     41             PASS\n",
       "12  2022    January                 52                     52             PASS\n",
       "13  2022       July                 52                     52             PASS\n",
       "14  2022       June                 42                     42             PASS\n",
       "15  2022      March                 41                     41             PASS\n",
       "16  2022        May                 42                     42             PASS\n",
       "17  2022   November                 42                     42             PASS\n",
       "18  2022    October                 52                     52             PASS\n",
       "19  2022  September                 42                     42             PASS\n",
       "20  2023      April                 52                     52             PASS\n",
       "21  2023     August                 41                     41             PASS\n",
       "22  2023   December                 41                     41             PASS\n",
       "23  2023   February                 42                     42             PASS\n",
       "24  2023    January                 52                     52             PASS\n",
       "25  2023       July                 52                     52             PASS\n",
       "26  2023       June                 42                     42             PASS\n",
       "27  2023      March                 42                     42             PASS\n",
       "28  2023        May                 42                     42             PASS\n",
       "29  2023   November                 41                     41             PASS\n",
       "30  2023    October                 52                     52             PASS\n",
       "31  2023  September                 41                     41             PASS\n",
       "32  2024      April                 51                     51             PASS\n",
       "33  2024     August                 40                     40             PASS\n",
       "34  2024   February                 41                     41             PASS\n",
       "35  2024    January                 52                     52             PASS\n",
       "36  2024       July                 51                     51             PASS\n",
       "37  2024       June                 40                     40             PASS\n",
       "38  2024      March                 41                     41             PASS\n",
       "39  2024        May                 40                     40             PASS"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "integrity_df = verify_header_decoding_integrity(inventory, base_path)\n",
    "integrity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684b1331",
   "metadata": {},
   "source": [
    "## Sheet 2 Decoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c16b079f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_clean_sheet2(base_path, year, month):\n",
    "    \"\"\"Loads the Clean Sheet 2 Metadata.\"\"\"\n",
    "    path = os.path.join(base_path, \"Metadata Sheet 2 CSV's\", year, f\"Sheet2_{month}_{year}.csv\")\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Metadata not found at: {path}\")\n",
    "    return pd.read_csv(path, dtype=str)\n",
    "\n",
    "\n",
    "def find_target_column(survey_columns, meta_desc):\n",
    "    \"\"\"\n",
    "    Smart Matcher: Handles 'Highest Grade' vs 'C07-Highest Grade Completed'.\n",
    "    \"\"\"\n",
    "    if pd.isna(meta_desc): return None\n",
    "    meta_desc = str(meta_desc).strip()\n",
    "   \n",
    "    # 1. Exact Match\n",
    "    if meta_desc in survey_columns: return meta_desc\n",
    "   \n",
    "    # 2. Metadata has prefix (Meta=\"C06-Status\" -> Survey=\"Status\")\n",
    "    clean_meta = re.sub(r'^C\\d+[\\s\\-_]+', '', meta_desc, flags=re.IGNORECASE).strip()\n",
    "    if clean_meta in survey_columns: return clean_meta\n",
    "       \n",
    "    # 3. Survey has prefix (Meta=\"Status\" -> Survey=\"C06-Status\")\n",
    "    for col in survey_columns:\n",
    "        if col.endswith(meta_desc):\n",
    "            prefix = col[:-len(meta_desc)].strip()\n",
    "            if re.search(r'^C\\d+[\\s\\-_]*$', prefix, re.IGNORECASE) or prefix == \"\":\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "\n",
    "def decode_survey_safe(survey_df, meta_df):\n",
    "    \"\"\"\n",
    "    Decodes the entire survey using the Smart Matcher and Safe Logic.\n",
    "    \"\"\"\n",
    "    unique_vars = meta_df['Variable'].unique()\n",
    "    decoded_count = 0\n",
    "    survey_cols = list(survey_df.columns)\n",
    "   \n",
    "    for var_code in unique_vars:\n",
    "        subset = meta_df[meta_df['Variable'] == var_code].copy()\n",
    "       \n",
    "        if subset['Description'].isnull().all(): continue\n",
    "        raw_desc = subset['Description'].dropna().iloc[0].strip()\n",
    "       \n",
    "        target_col = find_target_column(survey_cols, raw_desc)\n",
    "        if not target_col: continue\n",
    "           \n",
    "        mask_zeros = subset['Label'].astype(str).isin(['0', '0.0', '0.00', 'nan', 'NaN'])\n",
    "        if mask_zeros.all(): continue\n",
    "           \n",
    "        lookup = {}\n",
    "        for _, row in subset.iterrows():\n",
    "            try:\n",
    "                label = row['Label']\n",
    "                if str(label) in ['0', '0.0', 'nan']: continue\n",
    "               \n",
    "                min_v = float(row['min_value'])\n",
    "                max_v = float(row['max_value'])\n",
    "               \n",
    "                if max_v > min_v and max_v != 0:\n",
    "                    for c in range(int(min_v), int(max_v) + 1): lookup[c] = label\n",
    "                else:\n",
    "                    lookup[int(min_v)] = label\n",
    "            except: continue\n",
    "           \n",
    "        if not lookup: continue\n",
    "\n",
    "\n",
    "        def safe_map(val):\n",
    "            try: return lookup.get(int(float(val)), val)\n",
    "            except: return val\n",
    "           \n",
    "        survey_df[target_col] = survey_df[target_col].apply(safe_map)\n",
    "        decoded_count += 1\n",
    "\n",
    "\n",
    "    return survey_df, decoded_count\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc846431",
   "metadata": {},
   "source": [
    "## Automation for Sheet 2 Decoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "36b06bd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_batch_decoding(base_path):\n",
    "    \"\"\"\n",
    "    Scans the folder, decodes all files, and saves to Fully Decoded.\n",
    "    \"\"\"\n",
    "    # --- FOLDER CONFIGURATION ---\n",
    "    input_folder_name = \"Header Encoded Surveys\"\n",
    "    output_folder_name = \"Fully Decoded Surveys\"\n",
    "   \n",
    "    input_root = os.path.join(base_path, input_folder_name)\n",
    "    output_root = os.path.join(base_path, output_folder_name)\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "   \n",
    "    print(\"================================================\")\n",
    "    print(\"STARTING BATCH VALUE DECODING\")\n",
    "    print(f\"Source: {input_root}\")\n",
    "    print(f\"Dest:   {output_root}\")\n",
    "    print(\"================================================\\n\")\n",
    "   \n",
    "    month_pattern = re.compile(r\"(JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)\", re.IGNORECASE)\n",
    "   \n",
    "    if not os.path.exists(input_root):\n",
    "        print(f\"Error: Input folder not found: {input_root}\")\n",
    "        return\n",
    "\n",
    "\n",
    "    year_folders = [f for f in os.listdir(input_root) if f.isdigit() and os.path.isdir(os.path.join(input_root, f))]\n",
    "   \n",
    "    success = 0\n",
    "    errors = 0\n",
    "   \n",
    "    for year in sorted(year_folders):\n",
    "        year_in = os.path.join(input_root, year)\n",
    "        year_out = os.path.join(output_root, year)\n",
    "        os.makedirs(year_out, exist_ok=True)\n",
    "       \n",
    "        files = [f for f in os.listdir(year_in) if f.lower().endswith(\".csv\")]\n",
    "       \n",
    "        for filename in files:\n",
    "            match = month_pattern.search(filename)\n",
    "            if not match: continue\n",
    "            month = match.group(1).capitalize()\n",
    "           \n",
    "            print(f\"Processing: {month.upper()} {year}...\")\n",
    "           \n",
    "            try:\n",
    "                # 1. Load Survey\n",
    "                survey_path = os.path.join(year_in, filename)\n",
    "                df_survey = pd.read_csv(survey_path, low_memory=False)\n",
    "               \n",
    "                # 2. Load Metadata\n",
    "                df_meta = load_clean_sheet2(base_path, year, month)\n",
    "               \n",
    "                # 3. Decode (CALLS THE FUNCTION ABOVE)\n",
    "                df_final, count = decode_survey_safe(df_survey, df_meta)\n",
    "               \n",
    "                # 4. Save\n",
    "                save_path = os.path.join(year_out, filename)\n",
    "                df_final.to_csv(save_path, index=False)\n",
    "               \n",
    "                print(f\"   [OK] Decoded {count} columns.\")\n",
    "                print(f\"   [SAVED] {filename}\")\n",
    "                success += 1\n",
    "               \n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"   [SKIP] Metadata missing: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   [ERROR] {e}\")\n",
    "                errors += 1\n",
    "           \n",
    "            print(\"-\" * 40)\n",
    "\n",
    "\n",
    "    print(f\"\\nCOMPLETED. Success: {success} | Errors: {errors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "bc76e3be",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "STARTING BATCH VALUE DECODING\n",
      "Source: /Users/neilkeannedelavega/Library/CloudStorage/GoogleDrive-shaniakeith23@gmail.com/My Drive/Labor Force Survey/Header Encoded Surveys\n",
      "Dest:   /Users/neilkeannedelavega/Library/CloudStorage/GoogleDrive-shaniakeith23@gmail.com/My Drive/Labor Force Survey/Fully Decoded Surveys\n",
      "================================================\n",
      "\n",
      "Processing: JULY 2018...\n",
      "   [OK] Decoded 37 columns.\n",
      "   [SAVED] JULY_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2018...\n",
      "   [OK] Decoded 39 columns.\n",
      "   [SAVED] OCTOBER_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2018...\n",
      "   [OK] Decoded 37 columns.\n",
      "   [SAVED] APRIL_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2018...\n",
      "   [OK] Decoded 39 columns.\n",
      "   [SAVED] JANUARY_2018.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2019...\n",
      "   [OK] Decoded 41 columns.\n",
      "   [SAVED] JULY_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2019...\n",
      "   [OK] Decoded 38 columns.\n",
      "   [SAVED] JANUARY_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2019...\n",
      "   [OK] Decoded 39 columns.\n",
      "   [SAVED] APRIL_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2019...\n",
      "   [OK] Decoded 41 columns.\n",
      "   [SAVED] OCTOBER_2019.CSV\n",
      "----------------------------------------\n",
      "Processing: DECEMBER 2022...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] DECEMBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2022...\n",
      "   [OK] Decoded 31 columns.\n",
      "   [SAVED] FEBRUARY_2022.csv\n",
      "----------------------------------------\n",
      "Processing: SEPTEMBER 2022...\n",
      "   [OK] Decoded 33 columns.\n",
      "   [SAVED] SEPTEMBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: NOVEMBER 2022...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] NOVEMBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2022...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] JULY_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: JUNE 2022...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] JUNE_2022.csv\n",
      "----------------------------------------\n",
      "Processing: MAY 2022...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] MAY_2022.csv\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2022...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] AUGUST_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2022...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] OCTOBER_2022.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2022...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] APRIL_2022.csv\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2022...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] JANUARY_2022.csv\n",
      "----------------------------------------\n",
      "Processing: MARCH 2022...\n",
      "   [OK] Decoded 31 columns.\n",
      "   [SAVED] MARCH_2022.csv\n",
      "----------------------------------------\n",
      "Processing: DECEMBER 2023...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] DECEMBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2023...\n",
      "   [OK] Decoded 33 columns.\n",
      "   [SAVED] FEBRUARY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: SEPTEMBER 2023...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] SEPTEMBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: NOVEMBER 2023...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] NOVEMBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: JUNE 2023...\n",
      "   [OK] Decoded 33 columns.\n",
      "   [SAVED] JUNE_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2023...\n",
      "   [OK] Decoded 45 columns.\n",
      "   [SAVED] JULY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: MAY 2023...\n",
      "   [OK] Decoded 33 columns.\n",
      "   [SAVED] MAY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2023...\n",
      "   [OK] Decoded 33 columns.\n",
      "   [SAVED] AUGUST_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2023...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] JANUARY_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2023...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] APRIL_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2023...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] OCTOBER_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: MARCH 2023...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] MARCH_2023.CSV\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2024...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] FEBRUARY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: JULY 2024...\n",
      "   [OK] Decoded 43 columns.\n",
      "   [SAVED] JULY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: JUNE 2024...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] JUNE_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: APRIL 2024...\n",
      "   [OK] Decoded 43 columns.\n",
      "   [SAVED] APRIL_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2024...\n",
      "   [OK] Decoded 44 columns.\n",
      "   [SAVED] JANUARY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: MARCH 2024...\n",
      "   [OK] Decoded 32 columns.\n",
      "   [SAVED] MARCH_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: MAY 2024...\n",
      "   [OK] Decoded 33 columns.\n",
      "   [SAVED] MAY_2024.CSV\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2024...\n",
      "   [OK] Decoded 31 columns.\n",
      "   [SAVED] AUGUST_2024.CSV\n",
      "----------------------------------------\n",
      "\n",
      "COMPLETED. Success: 40 | Errors: 0\n"
     ]
    }
   ],
   "source": [
    "# ==========================================\n",
    "# EXECUTION\n",
    "# ==========================================\n",
    "if __name__ == \"__main__\":\n",
    "    run_batch_decoding(base_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "145e4e11",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "def verify_decoded_record_integrity(base_path):\n",
    "    \"\"\"\n",
    "    Checks if all raw survey records (rows) match the fully decoded records.\n",
    "    \n",
    "    Compares:\n",
    "    - Raw Total Records (Header Encoded Surveys)\n",
    "    - Decoded Total Records (Fully Decoded Surveys)\n",
    "    \n",
    "    Returns: DataFrame summary\n",
    "    \"\"\"\n",
    "\n",
    "    raw_root = os.path.join(base_path, \"Header Encoded Surveys\")\n",
    "    decoded_root = os.path.join(base_path, \"Fully Decoded Surveys\")\n",
    "\n",
    "    if not os.path.exists(raw_root):\n",
    "        raise FileNotFoundError(f\"Header Encoded Surveys folder missing: {raw_root}\")\n",
    "    if not os.path.exists(decoded_root):\n",
    "        raise FileNotFoundError(f\"Fully Decoded Surveys folder missing: {decoded_root}\")\n",
    "\n",
    "    # Detect months inside filenames\n",
    "    month_pattern = re.compile(\n",
    "        r\"(JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    results = []\n",
    "\n",
    "    # Loop through year folders\n",
    "    year_folders = [y for y in os.listdir(raw_root) if y.isdigit()]\n",
    "\n",
    "    for year in sorted(year_folders):\n",
    "        year_raw_folder = os.path.join(raw_root, year)\n",
    "        year_dec_folder = os.path.join(decoded_root, year)\n",
    "\n",
    "        if not os.path.exists(year_dec_folder):\n",
    "            # If missing decoded folder, mark all as FAIL\n",
    "            files = [f for f in os.listdir(year_raw_folder) if f.lower().endswith(\".csv\")]\n",
    "            for f in files:\n",
    "                match = month_pattern.search(f)\n",
    "                if not match: continue\n",
    "                month = match.group(1).capitalize()\n",
    "\n",
    "                results.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Raw Total Records\": \"N/A\",\n",
    "                    \"Decoded Total Records\": \"Missing\",\n",
    "                    \"Integrity Status\": \"FAIL\"\n",
    "                })\n",
    "            continue\n",
    "\n",
    "        raw_files = [f for f in os.listdir(year_raw_folder) if f.lower().endswith(\".csv\")]\n",
    "\n",
    "        for filename in raw_files:\n",
    "\n",
    "            match = month_pattern.search(filename)\n",
    "            if not match:\n",
    "                continue\n",
    "\n",
    "            month = match.group(1).capitalize()\n",
    "\n",
    "            raw_path = os.path.join(year_raw_folder, filename)\n",
    "            decoded_path = os.path.join(year_dec_folder, filename)\n",
    "\n",
    "            try:\n",
    "                # Load raw records\n",
    "                raw_df = pd.read_csv(raw_path, low_memory=False)\n",
    "                raw_count = len(raw_df)\n",
    "\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Raw Total Records\": f\"ERROR: {e}\",\n",
    "                    \"Decoded Total Records\": \"N/A\",\n",
    "                    \"Integrity Status\": \"FAIL\"\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            # Load decoded records\n",
    "            if not os.path.exists(decoded_path):\n",
    "                results.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Raw Total Records\": raw_count,\n",
    "                    \"Decoded Total Records\": \"Missing\",\n",
    "                    \"Integrity Status\": \"FAIL\"\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            try:\n",
    "                decoded_df = pd.read_csv(decoded_path, low_memory=False)\n",
    "                dec_count = len(decoded_df)\n",
    "            except Exception as e:\n",
    "                results.append({\n",
    "                    \"Year\": year,\n",
    "                    \"Month\": month,\n",
    "                    \"Raw Total Records\": raw_count,\n",
    "                    \"Decoded Total Records\": f\"ERROR: {e}\",\n",
    "                    \"Integrity Status\": \"FAIL\"\n",
    "                })\n",
    "                continue\n",
    "\n",
    "            # Determine PASS/FAIL\n",
    "            status = \"PASS\" if raw_count == dec_count else \"FAIL\"\n",
    "\n",
    "            results.append({\n",
    "                \"Year\": year,\n",
    "                \"Month\": month,\n",
    "                \"Raw Total Records\": raw_count,\n",
    "                \"Decoded Total Records\": dec_count,\n",
    "                \"Integrity Status\": status\n",
    "            })\n",
    "\n",
    "    summary_df = pd.DataFrame(results)\n",
    "\n",
    "    print(\"\\n===== RECORD DECODING INTEGRITY CHECK COMPLETE =====\")\n",
    "    fails = (summary_df[\"Integrity Status\"] != \"PASS\").sum()\n",
    "\n",
    "    if fails == 0:\n",
    "        print(\"SUCCESS: All decoded surveys match the raw row counts.\")\n",
    "    else:\n",
    "        print(f\"WARNING: {fails} months failed record integrity checks.\")\n",
    "\n",
    "    print(\"====================================================\\n\")\n",
    "\n",
    "    return summary_df.sort_values([\"Year\", \"Month\"]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f3e5e73c",
   "metadata": {},
   "source": [
    "#### Checking if all records were decoded successfully"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "0e137378",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "===== RECORD DECODING INTEGRITY CHECK COMPLETE =====\n",
      "SUCCESS: All decoded surveys match the raw row counts.\n",
      "====================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Raw Total Records</th>\n",
       "      <th>Decoded Total Records</th>\n",
       "      <th>Integrity Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>179815</td>\n",
       "      <td>179815</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>180262</td>\n",
       "      <td>180262</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>July</td>\n",
       "      <td>182956</td>\n",
       "      <td>182956</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>October</td>\n",
       "      <td>179204</td>\n",
       "      <td>179204</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2019</td>\n",
       "      <td>April</td>\n",
       "      <td>172284</td>\n",
       "      <td>172284</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2019</td>\n",
       "      <td>January</td>\n",
       "      <td>181233</td>\n",
       "      <td>181233</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2019</td>\n",
       "      <td>July</td>\n",
       "      <td>175438</td>\n",
       "      <td>175438</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2019</td>\n",
       "      <td>October</td>\n",
       "      <td>178067</td>\n",
       "      <td>178067</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2022</td>\n",
       "      <td>April</td>\n",
       "      <td>184237</td>\n",
       "      <td>184237</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2022</td>\n",
       "      <td>August</td>\n",
       "      <td>45054</td>\n",
       "      <td>45054</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2022</td>\n",
       "      <td>December</td>\n",
       "      <td>45687</td>\n",
       "      <td>45687</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2022</td>\n",
       "      <td>February</td>\n",
       "      <td>45889</td>\n",
       "      <td>45889</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2022</td>\n",
       "      <td>January</td>\n",
       "      <td>736746</td>\n",
       "      <td>736746</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2022</td>\n",
       "      <td>July</td>\n",
       "      <td>183856</td>\n",
       "      <td>183856</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2022</td>\n",
       "      <td>June</td>\n",
       "      <td>45894</td>\n",
       "      <td>45894</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2022</td>\n",
       "      <td>March</td>\n",
       "      <td>46154</td>\n",
       "      <td>46154</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2022</td>\n",
       "      <td>May</td>\n",
       "      <td>46264</td>\n",
       "      <td>46264</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2022</td>\n",
       "      <td>November</td>\n",
       "      <td>45561</td>\n",
       "      <td>45561</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2022</td>\n",
       "      <td>October</td>\n",
       "      <td>183602</td>\n",
       "      <td>183602</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2022</td>\n",
       "      <td>September</td>\n",
       "      <td>46261</td>\n",
       "      <td>46261</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2023</td>\n",
       "      <td>April</td>\n",
       "      <td>181424</td>\n",
       "      <td>181424</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2023</td>\n",
       "      <td>August</td>\n",
       "      <td>44999</td>\n",
       "      <td>44999</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2023</td>\n",
       "      <td>December</td>\n",
       "      <td>44141</td>\n",
       "      <td>44141</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2023</td>\n",
       "      <td>February</td>\n",
       "      <td>47044</td>\n",
       "      <td>47044</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2023</td>\n",
       "      <td>January</td>\n",
       "      <td>184113</td>\n",
       "      <td>184113</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2023</td>\n",
       "      <td>July</td>\n",
       "      <td>718567</td>\n",
       "      <td>718567</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2023</td>\n",
       "      <td>June</td>\n",
       "      <td>46060</td>\n",
       "      <td>46060</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2023</td>\n",
       "      <td>March</td>\n",
       "      <td>46212</td>\n",
       "      <td>46212</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2023</td>\n",
       "      <td>May</td>\n",
       "      <td>45505</td>\n",
       "      <td>45505</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2023</td>\n",
       "      <td>November</td>\n",
       "      <td>44609</td>\n",
       "      <td>44609</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2023</td>\n",
       "      <td>October</td>\n",
       "      <td>179173</td>\n",
       "      <td>179173</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2023</td>\n",
       "      <td>September</td>\n",
       "      <td>44659</td>\n",
       "      <td>44659</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2024</td>\n",
       "      <td>April</td>\n",
       "      <td>175511</td>\n",
       "      <td>175511</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2024</td>\n",
       "      <td>August</td>\n",
       "      <td>43375</td>\n",
       "      <td>43375</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2024</td>\n",
       "      <td>February</td>\n",
       "      <td>44598</td>\n",
       "      <td>44598</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2024</td>\n",
       "      <td>January</td>\n",
       "      <td>707981</td>\n",
       "      <td>707981</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2024</td>\n",
       "      <td>July</td>\n",
       "      <td>173259</td>\n",
       "      <td>173259</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2024</td>\n",
       "      <td>June</td>\n",
       "      <td>43074</td>\n",
       "      <td>43074</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2024</td>\n",
       "      <td>March</td>\n",
       "      <td>44063</td>\n",
       "      <td>44063</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2024</td>\n",
       "      <td>May</td>\n",
       "      <td>43717</td>\n",
       "      <td>43717</td>\n",
       "      <td>PASS</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year      Month  Raw Total Records  Decoded Total Records Integrity Status\n",
       "0   2018      April             179815                 179815             PASS\n",
       "1   2018    January             180262                 180262             PASS\n",
       "2   2018       July             182956                 182956             PASS\n",
       "3   2018    October             179204                 179204             PASS\n",
       "4   2019      April             172284                 172284             PASS\n",
       "5   2019    January             181233                 181233             PASS\n",
       "6   2019       July             175438                 175438             PASS\n",
       "7   2019    October             178067                 178067             PASS\n",
       "8   2022      April             184237                 184237             PASS\n",
       "9   2022     August              45054                  45054             PASS\n",
       "10  2022   December              45687                  45687             PASS\n",
       "11  2022   February              45889                  45889             PASS\n",
       "12  2022    January             736746                 736746             PASS\n",
       "13  2022       July             183856                 183856             PASS\n",
       "14  2022       June              45894                  45894             PASS\n",
       "15  2022      March              46154                  46154             PASS\n",
       "16  2022        May              46264                  46264             PASS\n",
       "17  2022   November              45561                  45561             PASS\n",
       "18  2022    October             183602                 183602             PASS\n",
       "19  2022  September              46261                  46261             PASS\n",
       "20  2023      April             181424                 181424             PASS\n",
       "21  2023     August              44999                  44999             PASS\n",
       "22  2023   December              44141                  44141             PASS\n",
       "23  2023   February              47044                  47044             PASS\n",
       "24  2023    January             184113                 184113             PASS\n",
       "25  2023       July             718567                 718567             PASS\n",
       "26  2023       June              46060                  46060             PASS\n",
       "27  2023      March              46212                  46212             PASS\n",
       "28  2023        May              45505                  45505             PASS\n",
       "29  2023   November              44609                  44609             PASS\n",
       "30  2023    October             179173                 179173             PASS\n",
       "31  2023  September              44659                  44659             PASS\n",
       "32  2024      April             175511                 175511             PASS\n",
       "33  2024     August              43375                  43375             PASS\n",
       "34  2024   February              44598                  44598             PASS\n",
       "35  2024    January             707981                 707981             PASS\n",
       "36  2024       July             173259                 173259             PASS\n",
       "37  2024       June              43074                  43074             PASS\n",
       "38  2024      March              44063                  44063             PASS\n",
       "39  2024        May              43717                  43717             PASS"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "record_integrity_df = verify_decoded_record_integrity(base_path)\n",
    "record_integrity_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b7d8ab8",
   "metadata": {},
   "source": [
    "### Coverage Scanner in Metadata and Survey "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32510426",
   "metadata": {},
   "source": [
    "To check whether columns with values not found in metadata stayed unchanged:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "02a4e198",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFICATION: APRIL 2018\n",
      "======================================================================\n",
      "Total Columns:      50\n",
      "Successful Decodes: 40\n",
      "Correctly Numeric:  10\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JANUARY 2018\n",
      "======================================================================\n",
      "Total Columns:      50\n",
      "Successful Decodes: 41\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JULY 2018\n",
      "======================================================================\n",
      "Total Columns:      51\n",
      "Successful Decodes: 40\n",
      "Correctly Numeric:  11\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: OCTOBER 2018\n",
      "======================================================================\n",
      "Total Columns:      51\n",
      "Successful Decodes: 41\n",
      "Correctly Numeric:  10\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: APRIL 2019\n",
      "======================================================================\n",
      "Total Columns:      49\n",
      "Successful Decodes: 41\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JANUARY 2019\n",
      "======================================================================\n",
      "Total Columns:      49\n",
      "Successful Decodes: 41\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JULY 2019\n",
      "======================================================================\n",
      "Total Columns:      49\n",
      "Successful Decodes: 41\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: OCTOBER 2019\n",
      "======================================================================\n",
      "Total Columns:      49\n",
      "Successful Decodes: 41\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: APRIL 2022\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 45\n",
      "Correctly Numeric:  7\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: AUGUST 2022\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: DECEMBER 2022\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: FEBRUARY 2022\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  8\n",
      "Failures:           1\n",
      "\n",
      "WARNING: 1 columns failed to decode:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column</th>\n",
       "      <th>In_Metadata</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Survey Month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>FAILED (Should be Text)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFICATION: JANUARY 2022\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 44\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JULY 2022\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 45\n",
      "Correctly Numeric:  7\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JUNE 2022\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: MARCH 2022\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 31\n",
      "Correctly Numeric:  9\n",
      "Failures:           1\n",
      "\n",
      "WARNING: 1 columns failed to decode:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>Column</th>\n",
       "      <th>In_Metadata</th>\n",
       "      <th>Data_Type</th>\n",
       "      <th>Status</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Survey Month</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Numeric</td>\n",
       "      <td>FAILED (Should be Text)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "======================================================================\n",
      "VERIFICATION: MAY 2022\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: NOVEMBER 2022\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 34\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: OCTOBER 2022\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 44\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: SEPTEMBER 2022\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: APRIL 2023\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 44\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: AUGUST 2023\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: DECEMBER 2023\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: FEBRUARY 2023\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 34\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JANUARY 2023\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 44\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JULY 2023\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 45\n",
      "Correctly Numeric:  7\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JUNE 2023\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: MARCH 2023\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: MAY 2023\n",
      "======================================================================\n",
      "Total Columns:      42\n",
      "Successful Decodes: 33\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: NOVEMBER 2023\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: OCTOBER 2023\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 44\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: SEPTEMBER 2023\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: APRIL 2024\n",
      "======================================================================\n",
      "Total Columns:      51\n",
      "Successful Decodes: 43\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: AUGUST 2024\n",
      "======================================================================\n",
      "Total Columns:      40\n",
      "Successful Decodes: 31\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: FEBRUARY 2024\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JANUARY 2024\n",
      "======================================================================\n",
      "Total Columns:      52\n",
      "Successful Decodes: 44\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JULY 2024\n",
      "======================================================================\n",
      "Total Columns:      51\n",
      "Successful Decodes: 43\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: JUNE 2024\n",
      "======================================================================\n",
      "Total Columns:      40\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: MARCH 2024\n",
      "======================================================================\n",
      "Total Columns:      41\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  9\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n",
      "\n",
      "======================================================================\n",
      "VERIFICATION: MAY 2024\n",
      "======================================================================\n",
      "Total Columns:      40\n",
      "Successful Decodes: 32\n",
      "Correctly Numeric:  8\n",
      "Failures:           0\n",
      "\n",
      "PASSED: All columns accounted for.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "from IPython.display import display, HTML\n",
    "\n",
    "def check_value_decoding_integrity_smart(base_path):\n",
    "    \"\"\"\n",
    "    Verifies if variables were decoded correctly.\n",
    "    \n",
    "    IMPROVEMENT:\n",
    "    - Distinguishes between \"Failed Decoding\" vs \"Quantitative Variables\" (e.g. Household Size).\n",
    "    - If a variable is in metadata but the labels are numbers (or 0), it marks it as OK.\n",
    "    \"\"\"\n",
    "    input_folder = os.path.join(base_path, \"Fully Decoded Surveys\")\n",
    "    meta_root = os.path.join(base_path, \"Metadata Sheet 2 CSV's\")\n",
    "\n",
    "    month_pattern = re.compile(\n",
    "        r\"(JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)\",\n",
    "        re.IGNORECASE\n",
    "    )\n",
    "\n",
    "    all_results = []\n",
    "\n",
    "    # Ensure input folder exists\n",
    "    if not os.path.exists(input_folder):\n",
    "        print(f\"Folder not found: {input_folder}\")\n",
    "        return\n",
    "\n",
    "    for year in sorted(os.listdir(input_folder)):\n",
    "        year_path = os.path.join(input_folder, year)\n",
    "        if not os.path.isdir(year_path): continue\n",
    "\n",
    "        for file in sorted(os.listdir(year_path)):\n",
    "            if not file.lower().endswith(\".csv\"): continue\n",
    "\n",
    "            match = month_pattern.search(file)\n",
    "            if not match: continue\n",
    "\n",
    "            month = match.group(1).capitalize()\n",
    "            survey_path = os.path.join(year_path, file)\n",
    "\n",
    "            # 1. Load Survey\n",
    "            # Read as object (string) initially to check for numeric-ness accurately\n",
    "            df_survey = pd.read_csv(survey_path, low_memory=False)\n",
    "\n",
    "            # 2. Load Metadata\n",
    "            meta_path = os.path.join(meta_root, year, f\"Sheet2_{month}_{year}.csv\")\n",
    "            if not os.path.exists(meta_path):\n",
    "                print(f\"[SKIP] Metadata missing for {month} {year}\")\n",
    "                continue\n",
    "\n",
    "            df_meta = pd.read_csv(meta_path, dtype=str)\n",
    "            \n",
    "            # Create a clean lookup for Description -> Variable Logic\n",
    "            # We need to know WHICH metadata rows correspond to WHICH survey column\n",
    "            # Clean descriptions to match survey headers\n",
    "            df_meta['Description_Clean'] = df_meta['Description'].fillna('').astype(str).str.strip()\n",
    "            \n",
    "            # Get set of descriptions present in metadata\n",
    "            meta_descriptions = set(df_meta[\"Description_Clean\"].unique())\n",
    "\n",
    "            sheet_results = []\n",
    "            decoded_count = 0\n",
    "            unchanged_count = 0 # Correctly unchanged\n",
    "            failed_count = 0    # Should have decoded but didn't\n",
    "\n",
    "            # 3. Check Columns\n",
    "            for col in df_survey.columns:\n",
    "                # A. Check if Data is Numeric\n",
    "                # We drop NA and check if the remaining values look like numbers\n",
    "                col_values = df_survey[col].dropna().astype(str)\n",
    "                if col_values.empty:\n",
    "                    is_numeric_data = False # Empty columns are ambiguous\n",
    "                else:\n",
    "                    # Check if all values are digits (allowing for .0 decimals)\n",
    "                    is_numeric_data = col_values.str.replace(r'\\.0$', '', regex=True).str.isnumeric().all()\n",
    "\n",
    "                # B. Check if in Metadata\n",
    "                # We check if the column header exists in the Metadata Descriptions\n",
    "                exists_in_metadata = col in meta_descriptions\n",
    "\n",
    "                status = \"\"\n",
    "                \n",
    "                if not exists_in_metadata:\n",
    "                    status = \"OK (No Metadata)\"\n",
    "                    unchanged_count += 1\n",
    "                \n",
    "                elif not is_numeric_data:\n",
    "                    # It's in metadata AND it's text (e.g. \"Male\"). Success.\n",
    "                    status = \"OK (Decoded)\"\n",
    "                    decoded_count += 1\n",
    "                    \n",
    "                elif is_numeric_data and exists_in_metadata:\n",
    "                    # --- SMART CHECK: Is it SUPPOSED to be numeric? ---\n",
    "                    # Get the labels for this specific variable\n",
    "                    subset = df_meta[df_meta['Description_Clean'] == col]\n",
    "                    \n",
    "                    # Check labels: Are they '0', empty, or purely numeric strings?\n",
    "                    labels = subset['Label'].astype(str).replace(['0', '0.0', 'nan', 'None'], '')\n",
    "                    \n",
    "                    # Filter out empty labels\n",
    "                    real_labels = labels[labels != '']\n",
    "                    \n",
    "                    if real_labels.empty:\n",
    "                        # All labels are '0' -> Quantitative (e.g., Hours)\n",
    "                        status = \"OK (Quantitative - No Labels)\"\n",
    "                        unchanged_count += 1\n",
    "                    elif real_labels.str.isnumeric().all():\n",
    "                        # All labels are numbers (e.g., \"2018\", \"1\") -> Quantitative (e.g., Year, HH Size)\n",
    "                        status = \"OK (Quantitative - Numeric Labels)\"\n",
    "                        unchanged_count += 1\n",
    "                    else:\n",
    "                        # Labels contain Text (e.g., \"Single\"), but Data is Numeric (1) -> FAIL\n",
    "                        status = \"FAILED (Should be Text)\"\n",
    "                        failed_count += 1\n",
    "\n",
    "                sheet_results.append({\n",
    "                    \"Column\": col,\n",
    "                    \"In_Metadata\": \"Yes\" if exists_in_metadata else \"No\",\n",
    "                    \"Data_Type\": \"Numeric\" if is_numeric_data else \"Text\",\n",
    "                    \"Status\": status\n",
    "                })\n",
    "\n",
    "            # ========== REPORT ==========\n",
    "            print(\"\\n\" + \"=\"*70)\n",
    "            print(f\"VERIFICATION: {month.upper()} {year}\")\n",
    "            print(\"=\"*70)\n",
    "            \n",
    "            # Filter for failures to show them clearly\n",
    "            failures = [res for res in sheet_results if \"FAILED\" in res['Status']]\n",
    "            \n",
    "            print(f\"Total Columns:      {len(df_survey.columns)}\")\n",
    "            print(f\"Successful Decodes: {decoded_count}\")\n",
    "            print(f\"Correctly Numeric:  {unchanged_count}\")\n",
    "            print(f\"Failures:           {failed_count}\")\n",
    "            \n",
    "            if failures:\n",
    "                print(f\"\\nWARNING: {len(failures)} columns failed to decode:\")\n",
    "                df_fail = pd.DataFrame(failures)\n",
    "                display(HTML(df_fail.to_html(index=False)))\n",
    "            else:\n",
    "                print(\"\\nPASSED: All columns accounted for.\")\n",
    "\n",
    "            all_results.extend(sheet_results)\n",
    "\n",
    "    return pd.DataFrame(all_results)\n",
    "\n",
    "# ===================== RUN =====================\n",
    "# Run this in your notebook\n",
    "df_integrity_check = check_value_decoding_integrity_smart(base_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15a6fd14",
   "metadata": {},
   "source": [
    "### Identical Variable Detector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "bc3e0ffa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "============================================================\n",
      "      GROUPS WITH DETAILED LABEL + MONTH DIFFERENCE CHECK      \n",
      "============================================================\n",
      "\n",
      "\n",
      "----- Group 1 -----\n",
      "Variables:\n",
      "- 2010Urban-RuralFIES (8 months)\n",
      "- 2015Urban-RuralFIES (13 months)\n",
      "\n",
      "Variable: 2010Urban-RuralFIES\n",
      "  January 2018: Rural, Urban\n",
      "  April 2018: Rural, Urban\n",
      "  July 2018: Rural, Urban\n",
      "  October 2018: Rural, Urban\n",
      "  January 2019: Rural, Urban\n",
      "  April 2019: Rural, Urban\n",
      "  July 2019: Rural, Urban\n",
      "  October 2019: Rural, Urban\n",
      "\n",
      "Variable: 2015Urban-RuralFIES\n",
      "  July 2022: Rural, Urban\n",
      "  August 2022: Rural, Urban\n",
      "  September 2022: Rural, Urban\n",
      "  October 2022: Rural, Urban\n",
      "  November 2022: Rural, Urban\n",
      "  December 2022: Rural, Urban\n",
      "  January 2023: Rural, Urban\n",
      "  February 2023: Rural, Urban\n",
      "  March 2023: Rural, Urban\n",
      "  April 2023: Rural, Urban\n",
      "  May 2023: Rural, Urban\n",
      "  June 2023: Rural, Urban\n",
      "  July 2023: Rural, Urban\n",
      "\n",
      "Identical coding scheme?: YES\n",
      "\n",
      "----- Group 2 -----\n",
      "Variables:\n",
      "- C08-Overseas Filipino Indicator (17 months)\n",
      "- C10-Overseas Filipino Indicator (17 months)\n",
      "\n",
      "Variable: C08-Overseas Filipino Indicator\n",
      "  August 2022: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  September 2022: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  November 2022: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  December 2022: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  February 2023: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  March 2023: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  May 2023: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  June 2023: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  August 2023: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  September 2023: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  November 2023: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  December 2023: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  February 2024: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  March 2024: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  May 2024: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  June 2024: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "  August 2024: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Residents, Students abroad/Tourists, Workers other than OCW\n",
      "\n",
      "Variable: C10-Overseas Filipino Indicator\n",
      "  January 2018: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Others, Overseas Contract Workers, Students abroad/Tourists, Workers other than OCW\n",
      "  April 2018: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  July 2018: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  October 2018: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  January 2019: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  April 2019: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  July 2019: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  October 2019: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  July 2022: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  October 2022: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  January 2023: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  April 2023: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  July 2023: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  October 2023: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  January 2024: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  April 2024: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "  July 2024: Employees in Philippine Embassy, Consulates & other Missions, Less than 15 Years Old, Overseas Contract Workers, Resident, Students abroad/Tourists, Workers other than OCW\n",
      "\n",
      "Identical coding scheme?: NO\n",
      "Differences found:\n",
      ">> TEMPORAL INCONSISTENCIES (Labels missing in specific months):\n",
      "- C10-Overseas Filipino Indicator in October 2022 is missing: Others\n",
      "- C10-Overseas Filipino Indicator in July 2023 is missing: Others\n",
      "- C10-Overseas Filipino Indicator in January 2023 is missing: Others\n",
      "- C10-Overseas Filipino Indicator in April 2019 is missing: Others\n",
      "- C10-Overseas Filipino Indicator in July 2019 is missing: Others\n",
      "- C10-Overseas Filipino Indicator in April 2024 is missing: Others\n",
      "- C10-Overseas Filipino Indicator in January 2019 is missing: Others\n",
      "- C10-Overseas Filipino Indicator in April 2023 is missing: Others\n",
      "- C10-Overseas Filipino Indicator in July 2018 is missing: Others\n",
      "- C10-Overseas Filipino Indicator in January 2018 is missing: Resident\n",
      "... and 7 more months.\n",
      "- C10-Overseas Filipino Indicator has EXTRA overall labels: Others, Resident\n",
      "- C10-Overseas Filipino Indicator is MISSING overall labels: Residents\n",
      "\n",
      "----- Group 3 -----\n",
      "Variables:\n",
      "- C09-Work Indicator (17 months)\n",
      "- C09A-Work Indicator (6 months)\n",
      "- C11-Work Indicator (17 months)\n",
      "\n",
      "Variable: C09-Work Indicator\n",
      "  August 2022: no, yes\n",
      "  September 2022: no, yes\n",
      "  November 2022: no, yes\n",
      "  December 2022: no, yes\n",
      "  February 2023: no, yes\n",
      "  March 2023: no, yes\n",
      "  May 2023: no, yes\n",
      "  June 2023: no, yes\n",
      "  August 2023: no, yes\n",
      "  September 2023: no, yes\n",
      "  November 2023: no, yes\n",
      "  December 2023: no, yes\n",
      "  February 2024: no, yes\n",
      "  March 2024: no, yes\n",
      "  May 2024: no, yes\n",
      "  June 2024: no, yes\n",
      "  August 2024: no, yes\n",
      "\n",
      "Variable: C09A-Work Indicator\n",
      "  August 2022: Home-based work, On a mixed mode working arrangement, On job rotation, On reduced hours, Telecommuting/work from home, Working in the default place of work except home\n",
      "  September 2022: Home-based work, On a mixed mode working arrangement, On job rotation, On reduced hours, Telecommuting/work from home, Working in the default place of work except home\n",
      "  November 2022: Home-based work, On a mixed mode working arrangement, On job rotation, On reduced hours, Telecommuting/work from home, Working in the default place of work except home\n",
      "  December 2022: Home-based work, On a mixed mode working arrangement, On job rotation, On reduced hours, Telecommuting/work from home, Working in the default place of work except home\n",
      "  February 2023: Home-based work, On a mixed mode working arrangement, On job rotation, On reduced hours, Telecommuting/work from home, Working in the default place of work except home\n",
      "  March 2023: Home-based work, On a mixed mode working arrangement, On job rotation, On reduced hours, Telecommuting/work from home, Working in the default place of work except home\n",
      "\n",
      "Variable: C11-Work Indicator\n",
      "  January 2018: no, yes\n",
      "  April 2018: no, yes\n",
      "  July 2018: no, yes\n",
      "  October 2018: no, yes\n",
      "  January 2019: no, yes\n",
      "  April 2019: no, yes\n",
      "  July 2019: no, yes\n",
      "  October 2019: no, yes\n",
      "  July 2022: NO, YES\n",
      "  October 2022: NO, YES\n",
      "  January 2023: NO, YES\n",
      "  April 2023: NO, YES\n",
      "  July 2023: NO, YES\n",
      "  October 2023: NO, YES\n",
      "  January 2024: NO, YES\n",
      "  April 2024: NO, YES\n",
      "  July 2024: NO, YES\n",
      "\n",
      "Identical coding scheme?: NO\n",
      "Differences found:\n",
      "- C09A-Work Indicator has EXTRA overall labels: Home-based work, On a mixed mode working arrangement, On job rotation, On reduced hours, Telecommuting/work from home, Working in the default place of work except home\n",
      "- C09A-Work Indicator is MISSING overall labels: no, yes\n",
      "\n",
      "----- Group 4 -----\n",
      "Variables:\n",
      "- C10-Job Indicator (17 months)\n",
      "- C12-Job Indicator (17 months)\n",
      "\n",
      "Variable: C10-Job Indicator\n",
      "  August 2022: No, No, Temporarily, Yes\n",
      "  September 2022: No, No, Temporarily, Yes\n",
      "  November 2022: No, No, Temporarily, Yes\n",
      "  December 2022: No, No, Temporarily, Yes\n",
      "  February 2023: No, No, Temporarily, Yes\n",
      "  March 2023: No, No, Temporarily, Yes\n",
      "  May 2023: No, No, Temporarily, Yes\n",
      "  June 2023: No, No, Temporarily, Yes\n",
      "  August 2023: No, No, Temporarily, Yes\n",
      "  September 2023: No, No, Temporarily, Yes\n",
      "  November 2023: No, No, Temporarily, Yes\n",
      "  December 2023: No, No, Temporarily, Yes\n",
      "  February 2024: No, No, Temporarily, Yes\n",
      "  March 2024: No, No, Temporarily, Yes\n",
      "  May 2024: No, No, Temporarily, Yes\n",
      "  June 2024: No, No, Temporarily, Yes\n",
      "  August 2024: No, No, Temporarily, Yes\n",
      "\n",
      "Variable: C12-Job Indicator\n",
      "  January 2018: no, yes\n",
      "  April 2018: no, yes\n",
      "  July 2018: no, yes\n",
      "  October 2018: no, yes\n",
      "  January 2019: no, yes\n",
      "  April 2019: no, yes\n",
      "  July 2019: no, yes\n",
      "  October 2019: no, yes\n",
      "  July 2022: no, no, temporarily, yes\n",
      "  October 2022: no, no, temporarily, yes\n",
      "  January 2023: no, no, temporarily, yes\n",
      "  April 2023: no, no, temporarily, yes\n",
      "  July 2023: No, No, temporarily, Yes\n",
      "  October 2023: no, no, temporarily, yes\n",
      "  January 2024: no, no, temporarily, yes\n",
      "  April 2024: no, no, temporarily, yes\n",
      "  July 2024: no, no, temporarily, yes\n",
      "\n",
      "Identical coding scheme?: NO\n",
      "Differences found:\n",
      ">> TEMPORAL INCONSISTENCIES (Labels missing in specific months):\n",
      "- C12-Job Indicator in April 2019 is missing: No, temporarily\n",
      "- C12-Job Indicator in July 2019 is missing: No, temporarily\n",
      "- C12-Job Indicator in January 2019 is missing: No, temporarily\n",
      "- C12-Job Indicator in July 2018 is missing: No, temporarily\n",
      "- C12-Job Indicator in January 2018 is missing: No, temporarily\n",
      "- C12-Job Indicator in October 2019 is missing: No, temporarily\n",
      "- C12-Job Indicator in April 2018 is missing: No, temporarily\n",
      "- C12-Job Indicator in October 2018 is missing: No, temporarily\n",
      "\n",
      "----- Group 5 -----\n",
      "Variables:\n",
      "- C11 - Location of Work (Province, Municipality) (16 months)\n",
      "- C11-Location of Work (Province, Municipality) (1 months)\n",
      "- C12A - Location of Work (Province, Municipality) (9 months)\n",
      "\n",
      "Variable: C11 - Location of Work (Province, Municipality)\n",
      "  August 2022: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  September 2022: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  November 2022: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  December 2022: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  February 2023: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  March 2023: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  June 2023: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  August 2023: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  September 2023: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  November 2023: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  December 2023: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  February 2024: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  March 2024: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  May 2024: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  June 2024: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  August 2024: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "\n",
      "Variable: C11-Location of Work (Province, Municipality)\n",
      "  May 2023: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "\n",
      "Variable: C12A - Location of Work (Province, Municipality)\n",
      "  July 2022: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  October 2022: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  January 2023: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  April 2023: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  July 2023: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  October 2023: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  January 2024: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  April 2024: 0101   ABRA - Bangued (Capital), 0102   ABRA - Boliney, 0103   ABRA - Bucay, 0104   ABRA - Bucloc, 0105   ABRA - Daguioman, 0106   ABRA - Danglas, 0107   ABRA - Dolores, 0108   ABRA - La Paz, 0109   ABRA - Lacub, 0110   ABRA - Lagangilang, ... (+1637 more)\n",
      "  July 2024: 0101 ABRA - Bangued (Capital), 0102 ABRA - Boliney, 0103 ABRA - Bucay, 0104 ABRA - Bucloc, 0105 ABRA - Daguioman, 0106 ABRA - Danglas, 0107 ABRA - Dolores, 0108 ABRA - La Paz, 0109 ABRA - Lacub, 0110 ABRA - Lagangilang, ... (+1637 more)\n",
      "\n",
      "Identical coding scheme?: YES\n",
      "\n",
      "----- Group 6 -----\n",
      "Variables:\n",
      "- C16-Nature of Employment (Primary Occupation) (17 months)\n",
      "- C17-Nature of Employment (Primary Occupation) (17 months)\n",
      "\n",
      "Variable: C16-Nature of Employment (Primary Occupation)\n",
      "  August 2022: Different Employer, Permanent Job, Short_term\n",
      "  September 2022: Different Employer, Permanent Job, Short_term\n",
      "  November 2022: Different Employer, Permanent Job, Short_term\n",
      "  December 2022: Different Employer, Permanent Job, Short_term\n",
      "  February 2023: Different Employer, Permanent Job, Short_term\n",
      "  March 2023: Different Employer, Permanent Job, Short_term\n",
      "  May 2023: Different Employer, Permanent Job, Short_term\n",
      "  June 2023: Different Employer, Permanent Job, Short_term\n",
      "  August 2023: Different Employer, Permanent Job, Short_term\n",
      "  September 2023: Different Employer, Permanent Job, Short_term\n",
      "  November 2023: Different Employer, Permanent Job, Short_term\n",
      "  December 2023: Different Employer, Permanent Job, Short_term\n",
      "  February 2024: Different Employer, Permanent Job, Short_term\n",
      "  March 2024: Different Employer, Permanent Job, Short_term\n",
      "  May 2024: Different Employer, Permanent Job, Short_term\n",
      "  June 2024: Different Employer, Permanent Job, Short_term\n",
      "  August 2024: Different Employer, Permanent Job, Short_term\n",
      "\n",
      "Variable: C17-Nature of Employment (Primary Occupation)\n",
      "  January 2018: Different Employer, Permanent Job, Short_term\n",
      "  April 2018: Different Employer, Permanent Job, Short_term\n",
      "  July 2018: Different Employer, Permanent Job, Short_term\n",
      "  October 2018: Different Employer, Permanent Job, Short_term\n",
      "  January 2019: Different Employer, Permanent Job, Short_term\n",
      "  April 2019: Different Employer, Permanent Job, Short_term\n",
      "  July 2019: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "  October 2019: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "  July 2022: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "  October 2022: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "  January 2023: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "  April 2023: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "  July 2023: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "  October 2023: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "  January 2024: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "  April 2024: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "  July 2024: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "\n",
      "Identical coding scheme?: NO\n",
      "Differences found:\n",
      ">> TEMPORAL INCONSISTENCIES (Labels missing in specific months):\n",
      "- C17-Nature of Employment (Primary Occupation) in October 2022 is missing: Different Employer, Permanent Job, Short_term\n",
      "- C17-Nature of Employment (Primary Occupation) in July 2023 is missing: Different Employer, Permanent Job, Short_term\n",
      "- C17-Nature of Employment (Primary Occupation) in January 2023 is missing: Different Employer, Permanent Job, Short_term\n",
      "- C17-Nature of Employment (Primary Occupation) in April 2019 is missing: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "- C17-Nature of Employment (Primary Occupation) in July 2019 is missing: Different Employer, Permanent Job, Short_term\n",
      "- C17-Nature of Employment (Primary Occupation) in April 2024 is missing: Different Employer, Permanent Job, Short_term\n",
      "- C17-Nature of Employment (Primary Occupation) in January 2019 is missing: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "- C17-Nature of Employment (Primary Occupation) in April 2023 is missing: Different Employer, Permanent Job, Short_term\n",
      "- C17-Nature of Employment (Primary Occupation) in July 2018 is missing: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "- C17-Nature of Employment (Primary Occupation) in January 2018 is missing: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "... and 7 more months.\n",
      "- C17-Nature of Employment (Primary Occupation) has EXTRA overall labels: Permanent Job/Business/Unpaid Family Work, Short-Term/Seasonal Job/Business/Unpaid Family Work, Worked for Different Employers on Day to Day or Week to Week Basis\n",
      "\n",
      "----- Group 7 -----\n",
      "Variables:\n",
      "- C17-Normal Working Hours per Day (17 months)\n",
      "- C18-Normal Working Hours per Day (17 months)\n",
      "\n",
      "Variable: C17-Normal Working Hours per Day\n",
      "  August 2022: 0\n",
      "  September 2022: 0\n",
      "  November 2022: 0\n",
      "  December 2022: 0\n",
      "  February 2023: 0\n",
      "  March 2023: 0\n",
      "  May 2023: 0\n",
      "  June 2023: 0\n",
      "  August 2023: 0\n",
      "  September 2023: 0\n",
      "  November 2023: 0\n",
      "  December 2023: 0\n",
      "  February 2024: 0\n",
      "  March 2024: 0\n",
      "  May 2024: 0\n",
      "  June 2024: 0\n",
      "  August 2024: 0\n",
      "\n",
      "Variable: C18-Normal Working Hours per Day\n",
      "  January 2018: 0\n",
      "  April 2018: 0\n",
      "  July 2018: 0\n",
      "  October 2018: 0\n",
      "  January 2019: 0\n",
      "  April 2019: 0\n",
      "  July 2019: 0\n",
      "  October 2019: 0\n",
      "  July 2022: 0\n",
      "  October 2022: 0\n",
      "  January 2023: 0\n",
      "  April 2023: 0\n",
      "  July 2023: 0\n",
      "  October 2023: 0\n",
      "  January 2024: 0\n",
      "  April 2024: 0\n",
      "  July 2024: 0\n",
      "\n",
      "Identical coding scheme?: YES\n",
      "\n",
      "----- Group 8 -----\n",
      "Variables:\n",
      "- C18-Total Number of Hours Worked during the past week (17 months)\n",
      "- C19-Total Number of Hours Worked during the past week (17 months)\n",
      "\n",
      "Variable: C18-Total Number of Hours Worked during the past week\n",
      "  August 2022: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  September 2022: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  November 2022: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  December 2022: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  February 2023: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  March 2023: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  May 2023: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  June 2023: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  August 2023: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  September 2023: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  November 2023: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  December 2023: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  February 2024: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  March 2024: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  May 2024: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  June 2024: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "  August 2024: 20 to 29, 30 to 39, 40 and over, Did not work, Less than 20\n",
      "\n",
      "Variable: C19-Total Number of Hours Worked during the past week\n",
      "  January 2018: 0\n",
      "  April 2018: 0\n",
      "  July 2018: 0\n",
      "  October 2018: 0\n",
      "  January 2019: 0\n",
      "  April 2019: 0\n",
      "  July 2019: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "  October 2019: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "  July 2022: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "  October 2022: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "  January 2023: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "  April 2023: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "  July 2023: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "  October 2023: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "  January 2024: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "  April 2024: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "  July 2024: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "\n",
      "Identical coding scheme?: NO\n",
      "Differences found:\n",
      ">> TEMPORAL INCONSISTENCIES (Labels missing in specific months):\n",
      "- C19-Total Number of Hours Worked during the past week in October 2022 is missing: 0\n",
      "- C19-Total Number of Hours Worked during the past week in July 2023 is missing: 0\n",
      "- C19-Total Number of Hours Worked during the past week in January 2023 is missing: 0\n",
      "- C19-Total Number of Hours Worked during the past week in April 2019 is missing: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "- C19-Total Number of Hours Worked during the past week in July 2019 is missing: 0\n",
      "- C19-Total Number of Hours Worked during the past week in April 2024 is missing: 0\n",
      "- C19-Total Number of Hours Worked during the past week in January 2019 is missing: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "- C19-Total Number of Hours Worked during the past week in April 2023 is missing: 0\n",
      "- C19-Total Number of Hours Worked during the past week in July 2018 is missing: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "- C19-Total Number of Hours Worked during the past week in January 2018 is missing: 20 to 29, 30 to 39, 40 and over, Did not work, Less thnan 20\n",
      "... and 7 more months.\n",
      "- C19-Total Number of Hours Worked during the past week has EXTRA overall labels: 0, Less thnan 20\n",
      "- C19-Total Number of Hours Worked during the past week is MISSING overall labels: Less than 20\n",
      "\n",
      "----- Group 9 -----\n",
      "Variables:\n",
      "- C19-Want More Hours of Work (17 months)\n",
      "- C20-Want More Hours of Work (17 months)\n",
      "\n",
      "Variable: C19-Want More Hours of Work\n",
      "  August 2022: no, yes\n",
      "  September 2022: no, yes\n",
      "  November 2022: no, yes\n",
      "  December 2022: no, yes\n",
      "  February 2023: no, yes\n",
      "  March 2023: no, yes\n",
      "  May 2023: no, yes\n",
      "  June 2023: no, yes\n",
      "  August 2023: no, yes\n",
      "  September 2023: no, yes\n",
      "  November 2023: no, yes\n",
      "  December 2023: no, yes\n",
      "  February 2024: no, yes\n",
      "  March 2024: no, yes\n",
      "  May 2024: no, yes\n",
      "  June 2024: no, yes\n",
      "  August 2024: no, yes\n",
      "\n",
      "Variable: C20-Want More Hours of Work\n",
      "  January 2018: no, yes\n",
      "  April 2018: no, yes\n",
      "  July 2018: no, yes\n",
      "  October 2018: no, yes\n",
      "  January 2019: no, yes\n",
      "  April 2019: no, yes\n",
      "  July 2019: no, yes\n",
      "  October 2019: no, yes\n",
      "  July 2022: no, yes\n",
      "  October 2022: no, yes\n",
      "  January 2023: no, yes\n",
      "  April 2023: no, yes\n",
      "  July 2023: No, Yes\n",
      "  October 2023: no, yes\n",
      "  January 2024: no, yes\n",
      "  April 2024: no, yes\n",
      "  July 2024: no, yes\n",
      "\n",
      "Identical coding scheme?: YES\n",
      "\n",
      "----- Group 10 -----\n",
      "Variables:\n",
      "- C20-Look for Additional Work (17 months)\n",
      "- C21-Look for Additional Work (17 months)\n",
      "\n",
      "Variable: C20-Look for Additional Work\n",
      "  August 2022: no, yes\n",
      "  September 2022: no, yes\n",
      "  November 2022: no, yes\n",
      "  December 2022: no, yes\n",
      "  February 2023: no, yes\n",
      "  March 2023: no, yes\n",
      "  May 2023: no, yes\n",
      "  June 2023: no, yes\n",
      "  August 2023: no, yes\n",
      "  September 2023: no, yes\n",
      "  November 2023: no, yes\n",
      "  December 2023: no, yes\n",
      "  February 2024: no, yes\n",
      "  March 2024: no, yes\n",
      "  May 2024: no, yes\n",
      "  June 2024: no, yes\n",
      "  August 2024: no, yes\n",
      "\n",
      "Variable: C21-Look for Additional Work\n",
      "  January 2018: no, yes\n",
      "  April 2018: no, yes\n",
      "  July 2018: no, yes\n",
      "  October 2018: no, yes\n",
      "  January 2019: no, yes\n",
      "  April 2019: no, yes\n",
      "  July 2019: no, yes\n",
      "  October 2019: no, yes\n",
      "  July 2022: no, yes\n",
      "  October 2022: no, yes\n",
      "  January 2023: no, yes\n",
      "  April 2023: no, yes\n",
      "  July 2023: No, Yes\n",
      "  October 2023: no, yes\n",
      "  January 2024: no, yes\n",
      "  April 2024: no, yes\n",
      "  July 2024: no, yes\n",
      "\n",
      "Identical coding scheme?: YES\n",
      "\n",
      "----- Group 11 -----\n",
      "Variables:\n",
      "- C21-Class of Worker (Primary Occupation) (17 months)\n",
      "- C23-Class of Worker (Primary Occupation) (17 months)\n",
      "\n",
      "Variable: C21-Class of Worker (Primary Occupation)\n",
      "  August 2022: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  September 2022: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  November 2022: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  December 2022: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  February 2023: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  March 2023: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  May 2023: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  June 2023: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  August 2023: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  September 2023: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  November 2023: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  December 2023: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  February 2024: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  March 2024: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  May 2024: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  June 2024: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  August 2024: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "\n",
      "Variable: C23-Class of Worker (Primary Occupation)\n",
      "  January 2018: Employer, Gov't/Gov't Corporation, Not Reported, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  April 2018: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  July 2018: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  October 2018: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  January 2019: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  April 2019: Employer, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, With pay (Family owned Business), Without Pay (Family owned Business)\n",
      "  July 2019: 0, Employer, Employer on own family-operated farm or business, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, Self Employed without any paid employee, Wage and salary workers, With pay (Family owned Business), ... (+6 more)\n",
      "  October 2019: 0, Employer, Employer on own family-operated farm or business, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, Self Employed without any paid employee, Wage and salary workers, With pay (Family owned Business), ... (+6 more)\n",
      "  July 2022: 0, Employer, Employer on own family-operated farm or business, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, Self Employed without any paid employee, Wage and salary workers, With pay (Family owned Business), ... (+6 more)\n",
      "  October 2022: 0, Employer, Employer on own family-operated farm or business, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, Self Employed without any paid employee, Wage and salary workers, With pay (Family owned Business), ... (+6 more)\n",
      "  January 2023: 0, Employer, Employer on own family-operated farm or business, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, Self Employed without any paid employee, Wage and salary workers, With pay (Family owned Business), ... (+6 more)\n",
      "  April 2023: 0, Employer, Employer on own family-operated farm or business, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, Self Employed without any paid employee, Wage and salary workers, With pay (Family owned Business), ... (+6 more)\n",
      "  July 2023: 0, Employer, Employer on own family-operated farm or business, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, Self Employed without any paid employee, Wage and salary workers, With pay (Family owned Business), ... (+6 more)\n",
      "  October 2023: 0, Employer, Employer on own family-operated farm or business, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, Self Employed without any paid employee, Wage and salary workers, With pay (Family owned Business), ... (+6 more)\n",
      "  January 2024: 0, Employer, Employer on own family-operated farm or business, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, Self Employed without any paid employee, Wage and salary workers, With pay (Family owned Business), ... (+6 more)\n",
      "  April 2024: 0, Employer, Employer on own family-operated farm or business, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, Self Employed without any paid employee, Wage and salary workers, With pay (Family owned Business), ... (+6 more)\n",
      "  July 2024: 0, Employer, Employer on own family-operated farm or business, Gov't/Gov't Corporation, Private Establishment, Private Household, Self Employed, Self Employed without any paid employee, Wage and salary workers, With pay (Family owned Business), ... (+6 more)\n",
      "\n",
      "Identical coding scheme?: NO\n",
      "Differences found:\n",
      ">> TEMPORAL INCONSISTENCIES (Labels missing in specific months):\n",
      "- C23-Class of Worker (Primary Occupation) in October 2022 is missing: Not Reported\n",
      "- C23-Class of Worker (Primary Occupation) in July 2023 is missing: Not Reported\n",
      "- C23-Class of Worker (Primary Occupation) in January 2023 is missing: Not Reported\n",
      "- C23-Class of Worker (Primary Occupation) in April 2019 is missing: 0, Employer on own family-operated farm or business, Not Reported, Self Employed without any paid employee, Wage and salary workers...\n",
      "- C23-Class of Worker (Primary Occupation) in July 2019 is missing: Not Reported\n",
      "- C23-Class of Worker (Primary Occupation) in April 2024 is missing: Not Reported\n",
      "- C23-Class of Worker (Primary Occupation) in January 2019 is missing: 0, Employer on own family-operated farm or business, Not Reported, Self Employed without any paid employee, Wage and salary workers...\n",
      "- C23-Class of Worker (Primary Occupation) in April 2023 is missing: Not Reported\n",
      "- C23-Class of Worker (Primary Occupation) in July 2018 is missing: 0, Employer on own family-operated farm or business, Not Reported, Self Employed without any paid employee, Wage and salary workers...\n",
      "- C23-Class of Worker (Primary Occupation) in January 2018 is missing: 0, Employer on own family-operated farm or business, Self Employed without any paid employee, Wage and salary workers, Worked for government or government-controlled corporation...\n",
      "... and 7 more months.\n",
      "- C23-Class of Worker (Primary Occupation) has EXTRA overall labels: 0, Employer on own family-operated farm or business, Not Reported, Self Employed without any paid employee, Wage and salary workers, Worked for government or government-controlled corporation, Worked for private establishment, Worked for private household, Worked with pay in own family-operated farm or business, Worked without pay in own family-operated farm or business\n",
      "\n",
      "----- Group 12 -----\n",
      "Variables:\n",
      "- C22-Other Job Indicator (17 months)\n",
      "- C26-Other Job Indicator (17 months)\n",
      "\n",
      "Variable: C22-Other Job Indicator\n",
      "  August 2022: No, Yes\n",
      "  September 2022: No, Yes\n",
      "  November 2022: No, Yes\n",
      "  December 2022: No, Yes\n",
      "  February 2023: No, Yes\n",
      "  March 2023: No, Yes\n",
      "  May 2023: No, Yes\n",
      "  June 2023: No, Yes\n",
      "  August 2023: No, Yes\n",
      "  September 2023: No, Yes\n",
      "  November 2023: No, Yes\n",
      "  December 2023: No, Yes\n",
      "  February 2024: No, Yes\n",
      "  March 2024: No, Yes\n",
      "  May 2024: No, Yes\n",
      "  June 2024: No, Yes\n",
      "  August 2024: No, Yes\n",
      "\n",
      "Variable: C26-Other Job Indicator\n",
      "  January 2018: No, Yes\n",
      "  April 2018: No, Yes\n",
      "  July 2018: No, Yes\n",
      "  October 2018: No, Yes\n",
      "  January 2019: No, Yes\n",
      "  April 2019: No, Yes\n",
      "  July 2019: No, Yes\n",
      "  October 2019: No, Yes\n",
      "  July 2022: No, Yes\n",
      "  October 2022: No, Yes\n",
      "  January 2023: No, Yes\n",
      "  April 2023: No, Yes\n",
      "  July 2023: No, Yes\n",
      "  October 2023: No, Yes\n",
      "  January 2024: No, Yes\n",
      "  April 2024: No, Yes\n",
      "  July 2024: No, Yes\n",
      "\n",
      "Identical coding scheme?: YES\n",
      "\n",
      "----- Group 13 -----\n",
      "Variables:\n",
      "- C23-Total Hours Worked for all Jobs (17 months)\n",
      "- C28-Total Hours Worked for all Jobs (17 months)\n",
      "\n",
      "Variable: C23-Total Hours Worked for all Jobs\n",
      "  August 2022: 0\n",
      "  September 2022: 0\n",
      "  November 2022: 0\n",
      "  December 2022: 0\n",
      "  February 2023: 0\n",
      "  March 2023: 0\n",
      "  May 2023: 0\n",
      "  June 2023: 0\n",
      "  August 2023: 0\n",
      "  September 2023: 0\n",
      "  November 2023: 0\n",
      "  December 2023: 0\n",
      "  February 2024: 0\n",
      "  March 2024: 0\n",
      "  May 2024: 0\n",
      "  June 2024: 0\n",
      "  August 2024: 0\n",
      "\n",
      "Variable: C28-Total Hours Worked for all Jobs\n",
      "  January 2018: 0\n",
      "  April 2018: 0\n",
      "  July 2018: 0\n",
      "  October 2018: 0\n",
      "  January 2019: 0\n",
      "  April 2019: 0\n",
      "  July 2019: 0\n",
      "  October 2019: 0\n",
      "  July 2022: 0\n",
      "  October 2022: 0\n",
      "  January 2023: 0\n",
      "  April 2023: 0\n",
      "  July 2023: 0\n",
      "  October 2023: 0\n",
      "  January 2024: 0\n",
      "  April 2024: 0\n",
      "  July 2024: 0\n",
      "\n",
      "Identical coding scheme?: YES\n",
      "\n",
      "----- Group 14 -----\n",
      "Variables:\n",
      "- C24-Reasons for Working More than 48 Hours during the past week (17 months)\n",
      "- C29-Reasons for Working More than 48 Hours during the past week (17 months)\n",
      "\n",
      "Variable: C24-Reasons for Working More than 48 Hours during the past week\n",
      "  August 2022: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  September 2022: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  November 2022: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  December 2022: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  February 2023: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  March 2023: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  May 2023: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  June 2023: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  August 2023: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  September 2023: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  November 2023: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  December 2023: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  February 2024: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  March 2024: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  May 2024: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  June 2024: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "  August 2024: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Personal / family reasons, Poor business condition, ... (+9 more)\n",
      "\n",
      "Variable: C29-Reasons for Working More than 48 Hours during the past week\n",
      "  January 2018: Ambition, passion for job, Exceptional week, Other reasons, Requirements of the job, Wanted more earnings\n",
      "  April 2018: Ambition, passion for job, Bad weather, natural disaster, Could only find pat time work, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons for working less than 40 hours, Other reasons for working more than 48 hours, Personal / family reasons, ... (+8 more)\n",
      "  July 2018: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, Personal / family reasons, ... (+8 more)\n",
      "  October 2018: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, Personal / family reasons, ... (+8 more)\n",
      "  January 2019: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, Personal / family reasons, ... (+8 more)\n",
      "  April 2019: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, Personal / family reasons, ... (+8 more)\n",
      "  July 2019: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, Personal / family reasons, ... (+8 more)\n",
      "  October 2019: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, Personal / family reasons, ... (+8 more)\n",
      "  July 2022: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, ... (+9 more)\n",
      "  October 2022: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, ... (+9 more)\n",
      "  January 2023: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, ... (+9 more)\n",
      "  April 2023: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, ... (+9 more)\n",
      "  July 2023: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, ... (+9 more)\n",
      "  October 2023: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, ... (+9 more)\n",
      "  January 2024: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, ... (+9 more)\n",
      "  April 2024: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, ... (+9 more)\n",
      "  July 2024: Ambition, passion for job, Bad weather, natural disaster, Could only find part time work, ECQ/Lockdown/Covid-19 Pandemic, Exceptional week, Health / medical limitations, Holidays, Low or off season, Other reasons, Other reasons, specify, ... (+9 more)\n",
      "\n",
      "Identical coding scheme?: NO\n",
      "Differences found:\n",
      ">> TEMPORAL INCONSISTENCIES (Labels missing in specific months):\n",
      "- C29-Reasons for Working More than 48 Hours during the past week in October 2022 is missing: Could only find pat time work, Other reasons for working less than 40 hours, Other reasons for working more than 48 hours\n",
      "- C29-Reasons for Working More than 48 Hours during the past week in July 2023 is missing: Could only find pat time work, Other reasons for working less than 40 hours, Other reasons for working more than 48 hours\n",
      "- C29-Reasons for Working More than 48 Hours during the past week in January 2023 is missing: Could only find pat time work, Other reasons for working less than 40 hours, Other reasons for working more than 48 hours\n",
      "- C29-Reasons for Working More than 48 Hours during the past week in April 2019 is missing: Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Other reasons for working less than 40 hours, Other reasons for working more than 48 hours\n",
      "- C29-Reasons for Working More than 48 Hours during the past week in July 2019 is missing: Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Other reasons for working less than 40 hours, Other reasons for working more than 48 hours\n",
      "- C29-Reasons for Working More than 48 Hours during the past week in April 2024 is missing: Could only find pat time work, Other reasons for working less than 40 hours, Other reasons for working more than 48 hours\n",
      "- C29-Reasons for Working More than 48 Hours during the past week in January 2019 is missing: Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Other reasons for working less than 40 hours, Other reasons for working more than 48 hours\n",
      "- C29-Reasons for Working More than 48 Hours during the past week in April 2023 is missing: Could only find pat time work, Other reasons for working less than 40 hours, Other reasons for working more than 48 hours\n",
      "- C29-Reasons for Working More than 48 Hours during the past week in July 2018 is missing: Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Other reasons for working less than 40 hours, Other reasons for working more than 48 hours\n",
      "- C29-Reasons for Working More than 48 Hours during the past week in January 2018 is missing: Bad weather, natural disaster, Could only find part time work, Could only find pat time work, ECQ/Lockdown/Covid-19 Pandemic, Health / medical limitations...\n",
      "... and 7 more months.\n",
      "- C29-Reasons for Working More than 48 Hours during the past week has EXTRA overall labels: Could only find part time work, Other reasons, Other reasons for working less than 40 hours, Other reasons for working more than 48 hours, Other reasons, specify\n",
      "- C29-Reasons for Working More than 48 Hours during the past week is MISSING overall labels: With Other reasons for working less than 40 hours, With Other reasons for working more than 48 hours\n",
      "\n",
      "----- Group 15 -----\n",
      "Variables:\n",
      "- C25-Looked for Work or Tried to Establish Business during the past week (17 months)\n",
      "- C30-Looked for Work or Tried to Establish Business during the past week (17 months)\n",
      "\n",
      "Variable: C25-Looked for Work or Tried to Establish Business during the past week\n",
      "  August 2022: no, yes\n",
      "  September 2022: no, yes\n",
      "  November 2022: no, yes\n",
      "  December 2022: no, yes\n",
      "  February 2023: no, yes\n",
      "  March 2023: no, yes\n",
      "  May 2023: no, yes\n",
      "  June 2023: no, yes\n",
      "  August 2023: no, yes\n",
      "  September 2023: no, yes\n",
      "  November 2023: no, yes\n",
      "  December 2023: no, yes\n",
      "  February 2024: no, yes\n",
      "  March 2024: no, yes\n",
      "  May 2024: no, yes\n",
      "  June 2024: no, yes\n",
      "  August 2024: no, yes\n",
      "\n",
      "Variable: C30-Looked for Work or Tried to Establish Business during the past week\n",
      "  January 2018: no, yes\n",
      "  April 2018: no, yes\n",
      "  July 2018: no, yes\n",
      "  October 2018: no, yes\n",
      "  January 2019: no, yes\n",
      "  April 2019: no, yes\n",
      "  July 2019: no, yes\n",
      "  October 2019: no, yes\n",
      "  July 2022: no, yes\n",
      "  October 2022: no, yes\n",
      "  January 2023: no, yes\n",
      "  April 2023: no, yes\n",
      "  July 2023: No, Yes\n",
      "  October 2023: no, yes\n",
      "  January 2024: no, yes\n",
      "  April 2024: no, yes\n",
      "  July 2024: no, yes\n",
      "\n",
      "Identical coding scheme?: YES\n",
      "\n",
      "----- Group 16 -----\n",
      "Variables:\n",
      "- C25B - First time to look for work (17 months)\n",
      "- C31-First Time to Look for Work (17 months)\n",
      "\n",
      "Variable: C25B - First time to look for work\n",
      "  August 2022: No, Yes\n",
      "  September 2022: No, Yes\n",
      "  November 2022: No, Yes\n",
      "  December 2022: No, Yes\n",
      "  February 2023: No, Yes\n",
      "  March 2023: No, Yes\n",
      "  May 2023: No, Yes\n",
      "  June 2023: No, Yes\n",
      "  August 2023: No, Yes\n",
      "  September 2023: No, Yes\n",
      "  November 2023: No, Yes\n",
      "  December 2023: No, Yes\n",
      "  February 2024: No, Yes\n",
      "  March 2024: No, Yes\n",
      "  May 2024: No, Yes\n",
      "  June 2024: No, Yes\n",
      "  August 2024: No, Yes\n",
      "\n",
      "Variable: C31-First Time to Look for Work\n",
      "  January 2018: no, yes\n",
      "  April 2018: no, yes\n",
      "  July 2018: no, yes\n",
      "  October 2018: no, yes\n",
      "  January 2019: no, yes\n",
      "  April 2019: no, yes\n",
      "  July 2019: no, yes\n",
      "  October 2019: no, yes\n",
      "  July 2022: no, yes\n",
      "  October 2022: no, yes\n",
      "  January 2023: no, yes\n",
      "  April 2023: no, yes\n",
      "  July 2023: No, Yes\n",
      "  October 2023: no, yes\n",
      "  January 2024: no, yes\n",
      "  April 2024: no, yes\n",
      "  July 2024: no, yes\n",
      "\n",
      "Identical coding scheme?: YES\n",
      "\n",
      "----- Group 17 -----\n",
      "Variables:\n",
      "- C26-Reason for not Looking for Work (17 months)\n",
      "- C34-Reason for not Looking for Work (17 months)\n",
      "\n",
      "Variable: C26-Reason for not Looking for Work\n",
      "  August 2022: 61  Too young/old, 62 Retired, 63 Permanent disability, Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Schooling, Temporary Illness/Disability, ... (+2 more)\n",
      "  September 2022: Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Permanent disability, Retired, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, ... (+2 more)\n",
      "  November 2022: 61  Too young/old, 62 Retired, 63 Permanent disability, Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Schooling, Temporary Illness/Disability, ... (+2 more)\n",
      "  December 2022: 61  Too young/old, 62 Retired, 63 Permanent disability, Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Schooling, Temporary Illness/Disability, ... (+2 more)\n",
      "  February 2023: 61  Too young/old, 62 Retired, 63 Permanent disability, Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Schooling, Temporary Illness/Disability, ... (+2 more)\n",
      "  March 2023: Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Permanent disability, Retired, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, ... (+2 more)\n",
      "  May 2023: Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Permanent disability, Retired, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, ... (+2 more)\n",
      "  June 2023: Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Permanent disability, Retired, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, ... (+2 more)\n",
      "  August 2023: Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Permanent disability, Retired, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, ... (+2 more)\n",
      "  September 2023: Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Permanent disability, Retired, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, ... (+2 more)\n",
      "  November 2023: Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Permanent disability, Retired, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, ... (+2 more)\n",
      "  December 2023: Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Permanent disability, Retired, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, ... (+2 more)\n",
      "  February 2024: Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Permanent disability, Retired, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, ... (+2 more)\n",
      "  March 2024: Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Permanent disability, Retired, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, ... (+2 more)\n",
      "  May 2024: Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Permanent disability, Retired, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, ... (+2 more)\n",
      "  June 2024: Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Permanent disability, Retired, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, ... (+2 more)\n",
      "  August 2024: Awaiting Results of Previous Job Application, Bad Weather, ECQ/Lockdown/Covid-19 Pandemic, Household, family duties, Others, Permanent disability, Retired, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, ... (+2 more)\n",
      "\n",
      "Variable: C34-Reason for not Looking for Work\n",
      "  January 2018: Awaiting Results of Previous Job Application, Bad Weather, Household, family duties, Others, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, Too young/old or Retired/Permanent Disability, Wait for rehire/Job Recall\n",
      "  April 2018: Awaiting Results of Previous Job Application, Bad Weather, Household, family duties, Others, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, Too young/old or Retired/Permanent Disability, Wait for rehire/Job Recall\n",
      "  July 2018: Awaiting Results of Previous Job Application, Bad Weather, Household, family duties, Others, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, Too young/old or Retired/Permanent Disability, Wait for rehire/Job Recall\n",
      "  October 2018: Awaiting Results of Previous Job Application, Bad Weather, Household, family duties, Others, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, Too young/old or Retired/Permanent Disability, Wait for rehire/Job Recall\n",
      "  January 2019: Awaiting Results of Previous Job Application, Bad Weather, Household, family duties, Others, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, Too young/old or Retired/Permanent Disability, Wait for rehire/Job Recall\n",
      "  April 2019: Awaiting Results of Previous Job Application, Bad Weather, Household, family duties, Others, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, Too young/old or Retired/Permanent Disability, Wait for rehire/Job Recall\n",
      "  July 2019: Awaiting Results of Previous Job Application, Bad Weather, Household, family duties, Others, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, Too young/old or Retired/Permanent Disability, Wait for rehire/Job Recall\n",
      "  October 2019: Awaiting Results of Previous Job Application, Bad Weather, Household, family duties, Others, Schooling, Temporary Illness/Disability, Tired/Believe no Work Available, Too young/old or Retired/Permanent Disability, Wait for rehire/Job Recall\n",
      "  July 2022: 00 - Covid19 pandemic-related, 01 - Tired/believed no work available, 02 - Awaiting results of previous job application, 03 - Temporary illness/disability, 04 - Bad weather, 05 - Waiting for rehire/job recall, 07 - Household or family duties, specify, 08 - Schooling, 09 - Others, specify, 61  Too young / old, ... (+2 more)\n",
      "  October 2022: 00 - Covid19 pandemic-related, 01 - Tired/believed no work available, 02 - Awaiting results of previous job application, 03 - Temporary illness/disability, 04 - Bad weather, 05 - Waiting for rehire/job recall, 07 - Household or family duties, specify, 08 - Schooling, 09 - Others, specify, 61  Too young / old, ... (+2 more)\n",
      "  January 2023: 00 - Covid19 pandemic-related, 01 - Tired/believed no work available, 02 - Awaiting results of previous job application, 03 - Temporary illness/disability, 04 - Bad weather, 05 - Waiting for rehire/job recall, 07 - Household or family duties, specify, 08 - Schooling, 09 - Others, specify, 61  Too young / old, ... (+2 more)\n",
      "  April 2023: 00 - Covid19 pandemic-related, 01 - Tired/believed no work available, 02 - Awaiting results of previous job application, 03 - Temporary illness/disability, 04 - Bad weather, 05 - Waiting for rehire/job recall, 07 - Household or family duties, specify, 08 - Schooling, 09 - Others, specify, 61  Too young / old, ... (+2 more)\n",
      "  July 2023: 00 - Covid19 pandemic-related, 01 - Tired/believed no work available, 02 - Awaiting results of previous job application, 03 - Temporary illness/disability, 04 - Bad weather, 05 - Waiting for rehire/job recall, 07 - Household or family duties, specify, 08 - Schooling, 09 - Others, specify, 61  Too young / old, ... (+2 more)\n",
      "  October 2023: 00 - Covid19 pandemic-related, 01 - Tired/believed no work available, 02 - Awaiting results of previous job application, 03 - Temporary illness/disability, 04 - Bad weather, 05 - Waiting for rehire/job recall, 07 - Household or family duties, specify, 08 - Schooling, 09 - Others, specify, 61  Too young / old, ... (+2 more)\n",
      "  January 2024: 00 - Covid19 pandemic-related, 01 - Tired/believed no work available, 02 - Awaiting results of previous job application, 03 - Temporary illness/disability, 04 - Bad weather, 05 - Waiting for rehire/job recall, 07 - Household or family duties, specify, 08 - Schooling, 09 - Others, specify, 61  Too young / old, ... (+2 more)\n",
      "  April 2024: 00 - Covid19 pandemic-related, 01 - Tired/believed no work available, 02 - Awaiting results of previous job application, 03 - Temporary illness/disability, 04 - Bad weather, 05 - Waiting for rehire/job recall, 07 - Household or family duties, specify, 08 - Schooling, 09 - Others, specify, 61  Too young / old, ... (+2 more)\n",
      "  July 2024: 00 - Covid19 pandemic-related, 01 - Tired/believed no work available, 02 - Awaiting results of previous job application, 03 - Temporary illness/disability, 04 - Bad weather, 05 - Waiting for rehire/job recall, 07 - Household or family duties, specify, 08 - Schooling, 09 - Others, specify, 61 Too young / old, ... (+2 more)\n",
      "\n",
      "Identical coding scheme?: NO\n",
      "Differences found:\n",
      ">> TEMPORAL INCONSISTENCIES (Labels missing in specific months):\n",
      "- C26-Reason for not Looking for Work in September 2022 is missing: 61  Too young/old, 62  Retired, 63  Permanent disability\n",
      "- C26-Reason for not Looking for Work in March 2024 is missing: 61  Too young/old, 62  Retired, 63  Permanent disability\n",
      "- C26-Reason for not Looking for Work in September 2023 is missing: 61  Too young/old, 62  Retired, 63  Permanent disability\n",
      "- C26-Reason for not Looking for Work in November 2022 is missing: Permanent disability, Retired, Too young/old\n",
      "- C26-Reason for not Looking for Work in August 2024 is missing: 61  Too young/old, 62  Retired, 63  Permanent disability\n",
      "- C26-Reason for not Looking for Work in June 2023 is missing: 61  Too young/old, 62  Retired, 63  Permanent disability\n",
      "- C26-Reason for not Looking for Work in March 2023 is missing: 61  Too young/old, 62  Retired, 63  Permanent disability\n",
      "- C26-Reason for not Looking for Work in August 2022 is missing: Permanent disability, Retired, Too young/old\n",
      "- C26-Reason for not Looking for Work in December 2023 is missing: 61  Too young/old, 62  Retired, 63  Permanent disability\n",
      "- C26-Reason for not Looking for Work in December 2022 is missing: Permanent disability, Retired, Too young/old\n",
      "... and 24 more months.\n",
      "- C34-Reason for not Looking for Work has EXTRA overall labels: 00 - Covid19 pandemic-related, 01 - Tired/believed no work available, 02 - Awaiting results of previous job application, 03 - Temporary illness/disability, 04 - Bad weather, 05 - Waiting for rehire/job recall, 07 - Household or family duties, specify, 08 - Schooling, 09 - Others, specify, 61  Too young / old, Too young/old or Retired/Permanent Disability\n",
      "- C34-Reason for not Looking for Work is MISSING overall labels: 61  Too young/old, ECQ/Lockdown/Covid-19 Pandemic, Permanent disability, Retired, Too young/old\n",
      "\n",
      "----- Group 18 -----\n",
      "Variables:\n",
      "- C27-Available for Work (17 months)\n",
      "- C36-Available for Work (17 months)\n",
      "\n",
      "Variable: C27-Available for Work\n",
      "  August 2022: no, yes\n",
      "  September 2022: no, yes\n",
      "  November 2022: no, yes\n",
      "  December 2022: no, yes\n",
      "  February 2023: no, yes\n",
      "  March 2023: no, yes\n",
      "  May 2023: no, yes\n",
      "  June 2023: no, yes\n",
      "  August 2023: no, yes\n",
      "  September 2023: no, yes\n",
      "  November 2023: no, yes\n",
      "  December 2023: no, yes\n",
      "  February 2024: no, yes\n",
      "  March 2024: no, yes\n",
      "  May 2024: no, yes\n",
      "  June 2024: no, yes\n",
      "  August 2024: no, yes\n",
      "\n",
      "Variable: C36-Available for Work\n",
      "  January 2018: not available, yes available\n",
      "  April 2018: not available, yes available\n",
      "  July 2018: not available, yes available\n",
      "  October 2018: not available, yes available\n",
      "  January 2019: not available, yes available\n",
      "  April 2019: not available, yes available\n",
      "  July 2019: not available, yes available\n",
      "  October 2019: not available, yes available\n",
      "  July 2022: not available, yes available\n",
      "  October 2022: not available, yes available\n",
      "  January 2023: not available, yes available\n",
      "  April 2023: not available, yes available\n",
      "  July 2023: not available, yes available\n",
      "  October 2023: not available, yes available\n",
      "  January 2024: not available, yes available\n",
      "  April 2024: not available, yes available\n",
      "  July 2024: not available, yes available\n",
      "\n",
      "Identical coding scheme?: NO\n",
      "Differences found:\n",
      "- C36-Available for Work has EXTRA overall labels: not available, yes available\n",
      "- C36-Available for Work is MISSING overall labels: no, yes\n",
      "\n",
      "----- Group 19 -----\n",
      "Variables:\n",
      "- C28-Previous Job Indicator (17 months)\n",
      "- C38-Previous Job Indicator (17 months)\n",
      "\n",
      "Variable: C28-Previous Job Indicator\n",
      "  August 2022: no, yes\n",
      "  September 2022: no, yes\n",
      "  November 2022: no, yes\n",
      "  December 2022: no, yes\n",
      "  February 2023: no, yes\n",
      "  March 2023: no, yes\n",
      "  May 2023: no, yes\n",
      "  June 2023: no, yes\n",
      "  August 2023: no, yes\n",
      "  September 2023: no, yes\n",
      "  November 2023: no, yes\n",
      "  December 2023: no, yes\n",
      "  February 2024: no, yes\n",
      "  March 2024: no, yes\n",
      "  May 2024: no, yes\n",
      "  June 2024: no, yes\n",
      "  August 2024: no, yes\n",
      "\n",
      "Variable: C38-Previous Job Indicator\n",
      "  January 2018: no, yes\n",
      "  April 2018: no, yes\n",
      "  July 2018: no, yes\n",
      "  October 2018: no, yes\n",
      "  January 2019: no, yes\n",
      "  April 2019: no, yes\n",
      "  July 2019: no, yes\n",
      "  October 2019: no, yes\n",
      "  July 2022: no, yes\n",
      "  October 2022: no, yes\n",
      "  January 2023: no, yes\n",
      "  April 2023: no, yes\n",
      "  July 2023: No, Yes\n",
      "  October 2023: no, yes\n",
      "  January 2024: no, yes\n",
      "  April 2024: no, yes\n",
      "  July 2024: no, yes\n",
      "\n",
      "Identical coding scheme?: YES\n",
      "\n",
      "----- Group 20 -----\n",
      "Variables:\n",
      "- C29 - Last worked (Month) (17 months)\n",
      "- C39 - Last worked (Month) (9 months)\n",
      "\n",
      "Variable: C29 - Last worked (Month)\n",
      "  August 2022: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  September 2022: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  November 2022: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  December 2022: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  February 2023: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  March 2023: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  May 2023: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  June 2023: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  August 2023: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  September 2023: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  November 2023: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  December 2023: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  February 2024: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  March 2024: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  May 2024: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  June 2024: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "  August 2024: April, August, December, Don't Know, February, January, July, June, March, May, ... (+3 more)\n",
      "\n",
      "Variable: C39 - Last worked (Month)\n",
      "  July 2022: 2023-01-01 00:00:00, 2023-02-02 00:00:00, 2023-03-03 00:00:00, 2023-04-04 00:00:00, 2023-05-05 00:00:00, 2023-06-06 00:00:00, 2023-07-07 00:00:00, 2023-08-08 00:00:00, 2023-09-09 00:00:00, 2023-10-10 00:00:00, ... (+3 more)\n",
      "  October 2022: 2023-01-01 00:00:00, 2023-02-02 00:00:00, 2023-03-03 00:00:00, 2023-04-04 00:00:00, 2023-05-05 00:00:00, 2023-06-06 00:00:00, 2023-07-07 00:00:00, 2023-08-08 00:00:00, 2023-09-09 00:00:00, 2023-10-10 00:00:00, ... (+3 more)\n",
      "  January 2023: 2025-01-01 00:00:00, 2025-02-02 00:00:00, 2025-03-03 00:00:00, 2025-04-04 00:00:00, 2025-05-05 00:00:00, 2025-06-06 00:00:00, 2025-07-07 00:00:00, 2025-08-08 00:00:00, 2025-09-09 00:00:00, 2025-10-10 00:00:00, ... (+3 more)\n",
      "  April 2023: 2025-01-01 00:00:00, 2025-02-02 00:00:00, 2025-03-03 00:00:00, 2025-04-04 00:00:00, 2025-05-05 00:00:00, 2025-06-06 00:00:00, 2025-07-07 00:00:00, 2025-08-08 00:00:00, 2025-09-09 00:00:00, 2025-10-10 00:00:00, ... (+3 more)\n",
      "  July 2023: 2025-01-01 00:00:00, 2025-02-02 00:00:00, 2025-03-03 00:00:00, 2025-04-04 00:00:00, 2025-05-05 00:00:00, 2025-06-06 00:00:00, 2025-07-07 00:00:00, 2025-08-08 00:00:00, 2025-09-09 00:00:00, 2025-10-10 00:00:00, ... (+3 more)\n",
      "  October 2023: 2025-01-01 00:00:00, 2025-02-02 00:00:00, 2025-03-03 00:00:00, 2025-04-04 00:00:00, 2025-05-05 00:00:00, 2025-06-06 00:00:00, 2025-07-07 00:00:00, 2025-08-08 00:00:00, 2025-09-09 00:00:00, 2025-10-10 00:00:00, ... (+3 more)\n",
      "  January 2024: 2025-01-01 00:00:00, 2025-02-02 00:00:00, 2025-03-03 00:00:00, 2025-04-04 00:00:00, 2025-05-05 00:00:00, 2025-06-06 00:00:00, 2025-07-07 00:00:00, 2025-08-08 00:00:00, 2025-09-09 00:00:00, 2025-10-10 00:00:00, ... (+3 more)\n",
      "  April 2024: 2025-01-01 00:00:00, 2025-02-02 00:00:00, 2025-03-03 00:00:00, 2025-04-04 00:00:00, 2025-05-05 00:00:00, 2025-06-06 00:00:00, 2025-07-07 00:00:00, 2025-08-08 00:00:00, 2025-09-09 00:00:00, 2025-10-10 00:00:00, ... (+3 more)\n",
      "  July 2024: 2025-01-01 00:00:00, 2025-02-02 00:00:00, 2025-03-03 00:00:00, 2025-04-04 00:00:00, 2025-05-05 00:00:00, 2025-06-06 00:00:00, 2025-07-07 00:00:00, 2025-08-08 00:00:00, 2025-09-09 00:00:00, 2025-10-10 00:00:00, ... (+3 more)\n",
      "\n",
      "Identical coding scheme?: NO\n",
      "Differences found:\n",
      ">> TEMPORAL INCONSISTENCIES (Labels missing in specific months):\n",
      "- C39 - Last worked (Month) in October 2022 is missing: 2025-01-01 00:00:00, 2025-02-02 00:00:00, 2025-03-03 00:00:00, 2025-04-04 00:00:00, 2025-05-05 00:00:00...\n",
      "- C39 - Last worked (Month) in July 2023 is missing: 2023-01-01 00:00:00, 2023-02-02 00:00:00, 2023-03-03 00:00:00, 2023-04-04 00:00:00, 2023-05-05 00:00:00...\n",
      "- C39 - Last worked (Month) in January 2023 is missing: 2023-01-01 00:00:00, 2023-02-02 00:00:00, 2023-03-03 00:00:00, 2023-04-04 00:00:00, 2023-05-05 00:00:00...\n",
      "- C39 - Last worked (Month) in April 2024 is missing: 2023-01-01 00:00:00, 2023-02-02 00:00:00, 2023-03-03 00:00:00, 2023-04-04 00:00:00, 2023-05-05 00:00:00...\n",
      "- C39 - Last worked (Month) in April 2023 is missing: 2023-01-01 00:00:00, 2023-02-02 00:00:00, 2023-03-03 00:00:00, 2023-04-04 00:00:00, 2023-05-05 00:00:00...\n",
      "- C39 - Last worked (Month) in July 2022 is missing: 2025-01-01 00:00:00, 2025-02-02 00:00:00, 2025-03-03 00:00:00, 2025-04-04 00:00:00, 2025-05-05 00:00:00...\n",
      "- C39 - Last worked (Month) in January 2024 is missing: 2023-01-01 00:00:00, 2023-02-02 00:00:00, 2023-03-03 00:00:00, 2023-04-04 00:00:00, 2023-05-05 00:00:00...\n",
      "- C39 - Last worked (Month) in October 2023 is missing: 2023-01-01 00:00:00, 2023-02-02 00:00:00, 2023-03-03 00:00:00, 2023-04-04 00:00:00, 2023-05-05 00:00:00...\n",
      "- C39 - Last worked (Month) in July 2024 is missing: 2023-01-01 00:00:00, 2023-02-02 00:00:00, 2023-03-03 00:00:00, 2023-04-04 00:00:00, 2023-05-05 00:00:00...\n",
      "- C39 - Last worked (Month) has EXTRA overall labels: 2023-01-01 00:00:00, 2023-02-02 00:00:00, 2023-03-03 00:00:00, 2023-04-04 00:00:00, 2023-05-05 00:00:00, 2023-06-06 00:00:00, 2023-07-07 00:00:00, 2023-08-08 00:00:00, 2023-09-09 00:00:00, 2023-10-10 00:00:00, 2023-11-11 00:00:00, 2023-12-12 00:00:00, 2025-01-01 00:00:00, 2025-02-02 00:00:00, 2025-03-03 00:00:00, 2025-04-04 00:00:00, 2025-05-05 00:00:00, 2025-06-06 00:00:00, 2025-07-07 00:00:00, 2025-08-08 00:00:00, 2025-09-09 00:00:00, 2025-10-10 00:00:00, 2025-11-11 00:00:00, 2025-12-12 00:00:00, 99 - Don't Know\n",
      "- C39 - Last worked (Month) is MISSING overall labels: April, August, December, Don't Know, February, January, July, June, March, May, November, October, September\n",
      "\n",
      "----- Group 21 -----\n",
      "Variables:\n",
      "- C29 - Last worked (Year) (17 months)\n",
      "- C39 - Last worked (Year) (9 months)\n",
      "\n",
      "Variable: C29 - Last worked (Year)\n",
      "  August 2022: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+53 more)\n",
      "  September 2022: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+53 more)\n",
      "  November 2022: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+53 more)\n",
      "  December 2022: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+53 more)\n",
      "  February 2023: 1905-06-05 00:00:00, 1905-06-06 00:00:00, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, ... (+54 more)\n",
      "  March 2023: 1905-06-05 00:00:00, 1905-06-06 00:00:00, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, ... (+54 more)\n",
      "  May 2023: 1905-06-16 00:00:00, 1905-06-17 00:00:00, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, ... (+54 more)\n",
      "  June 2023: 1905-06-16 00:00:00, 1905-06-17 00:00:00, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, ... (+54 more)\n",
      "  August 2023: 1905-06-15 00:00:00, 1905-06-16 00:00:00, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, ... (+54 more)\n",
      "  September 2023: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+54 more)\n",
      "  November 2023: 1905-06-09 00:00:00, 1905-06-10 00:00:00, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, ... (+54 more)\n",
      "  December 2023: 1905-06-09 00:00:00, 1905-06-10 00:00:00, 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, ... (+54 more)\n",
      "  February 2024: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+55 more)\n",
      "  March 2024: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+55 more)\n",
      "  May 2024: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+55 more)\n",
      "  June 2024: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+55 more)\n",
      "  August 2024: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+55 more)\n",
      "\n",
      "Variable: C39 - Last worked (Year)\n",
      "  July 2022: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+52 more)\n",
      "  October 2022: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+53 more)\n",
      "  January 2023: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+54 more)\n",
      "  April 2023: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+54 more)\n",
      "  July 2023: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+54 more)\n",
      "  October 2023: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+54 more)\n",
      "  January 2024: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+55 more)\n",
      "  April 2024: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+55 more)\n",
      "  July 2024: 1960, 1961, 1962, 1963, 1964, 1965, 1966, 1967, 1968, 1969, ... (+55 more)\n",
      "\n",
      "Identical coding scheme?: NO\n",
      "Differences found:\n",
      ">> TEMPORAL INCONSISTENCIES (Labels missing in specific months):\n",
      "- C29 - Last worked (Year) in September 2022 is missing: 1905-06-01 00:00:00, 1905-06-02 00:00:00, 1905-06-05 00:00:00, 1905-06-06 00:00:00, 1905-06-09 00:00:00...\n",
      "- C29 - Last worked (Year) in March 2024 is missing: 1905-06-01 00:00:00, 1905-06-02 00:00:00, 1905-06-05 00:00:00, 1905-06-06 00:00:00, 1905-06-09 00:00:00...\n",
      "- C29 - Last worked (Year) in September 2023 is missing: 1905-06-01 00:00:00, 1905-06-02 00:00:00, 1905-06-05 00:00:00, 1905-06-06 00:00:00, 1905-06-09 00:00:00...\n",
      "- C29 - Last worked (Year) in November 2022 is missing: 1905-06-01 00:00:00, 1905-06-02 00:00:00, 1905-06-05 00:00:00, 1905-06-06 00:00:00, 1905-06-09 00:00:00...\n",
      "- C29 - Last worked (Year) in August 2024 is missing: 1905-06-01 00:00:00, 1905-06-02 00:00:00, 1905-06-05 00:00:00, 1905-06-06 00:00:00, 1905-06-09 00:00:00...\n",
      "- C29 - Last worked (Year) in June 2023 is missing: 1905-06-01 00:00:00, 1905-06-02 00:00:00, 1905-06-05 00:00:00, 1905-06-06 00:00:00, 1905-06-09 00:00:00...\n",
      "- C29 - Last worked (Year) in March 2023 is missing: 1905-06-01 00:00:00, 1905-06-02 00:00:00, 1905-06-09 00:00:00, 1905-06-10 00:00:00, 1905-06-14 00:00:00...\n",
      "- C29 - Last worked (Year) in August 2022 is missing: 1905-06-01 00:00:00, 1905-06-02 00:00:00, 1905-06-05 00:00:00, 1905-06-06 00:00:00, 1905-06-09 00:00:00...\n",
      "- C29 - Last worked (Year) in December 2023 is missing: 1905-06-01 00:00:00, 1905-06-02 00:00:00, 1905-06-05 00:00:00, 1905-06-06 00:00:00, 1905-06-14 00:00:00...\n",
      "- C29 - Last worked (Year) in December 2022 is missing: 1905-06-01 00:00:00, 1905-06-02 00:00:00, 1905-06-05 00:00:00, 1905-06-06 00:00:00, 1905-06-09 00:00:00...\n",
      "... and 13 more months.\n",
      "- C39 - Last worked (Year) is MISSING overall labels: 1905-06-01 00:00:00, 1905-06-02 00:00:00, 1905-06-05 00:00:00, 1905-06-06 00:00:00, 1905-06-09 00:00:00, 1905-06-10 00:00:00, 1905-06-14 00:00:00, 1905-06-15 00:00:00, 1905-06-16 00:00:00, 1905-06-17 00:00:00\n",
      "\n",
      "----- Group 22 -----\n",
      "Variables:\n",
      "- C31-Previous Occupation (17 months)\n",
      "- C40-Previous Occupation (8 months)\n",
      "\n",
      "Variable: C31-Previous Occupation\n",
      "  August 2022: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  September 2022: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  November 2022: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  December 2022: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  February 2023: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  March 2023: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  May 2023: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  June 2023: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  August 2023: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  September 2023: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  November 2023: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  December 2023: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  February 2024: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  March 2024: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  May 2024: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  June 2024: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  August 2024: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "\n",
      "Variable: C40-Previous Occupation\n",
      "  January 2018: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  April 2018: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  July 2018: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  October 2018: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  January 2019: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  April 2019: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  July 2019: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "  October 2019: Armed Forces Occupations, Clerical Support Workers, Craft and Related Trades Workers, Elementary Occupations, Managers, Plant and Machine Operators and Assemblers, Professionals, Service and Sales Workers, Skilled Agricultural, Forestry and Fishery Workers, Technicians and Associate Professionals\n",
      "\n",
      "Identical coding scheme?: YES\n",
      "\n",
      "----- Group 23 -----\n",
      "Variables:\n",
      "- C33-Kind of Business (past quarter) (16 months)\n",
      "- C43-Kind of Business (past quarter) (17 months)\n",
      "\n",
      "Variable: C33-Kind of Business (past quarter)\n",
      "  August 2022: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  September 2022: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  November 2022: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  December 2022: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  February 2023: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  March 2023: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  May 2023: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  June 2023: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  August 2023: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  September 2023: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  November 2023: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  December 2023: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  February 2024: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  March 2024: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  May 2024: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  June 2024: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "\n",
      "Variable: C43-Kind of Business (past quarter)\n",
      "  January 2018: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  April 2018: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  July 2018: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  October 2018: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  January 2019: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  April 2019: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  July 2019: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  October 2019: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  July 2022: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  October 2022: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  January 2023: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  April 2023: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  July 2023: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  October 2023: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  January 2024: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  April 2024: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "  July 2024: AGRICULTURE, Accommodation and Food Service Activities, Activities of Extraterritorial Organizations and Bodies, Activities of Households as Employers, Administrative and Support Service Activities, Agriculture and Forestry, Arts, Entertainment and Recreation, Construction, Education, Electricity, Gas, Steam and Airconditioning Supply, ... (+15 more)\n",
      "\n",
      "Identical coding scheme?: YES\n",
      "\n",
      "----- Group 24 -----\n",
      "Variables:\n",
      "- Province (3 months)\n",
      "- province (1 months)\n",
      "\n",
      "Variable: Province\n",
      "Labels: (No labels found in metadata)\n",
      "  January 2018: (empty)\n",
      "  July 2018: (empty)\n",
      "  October 2018: (empty)\n",
      "\n",
      "Variable: province\n",
      "Labels: (No labels found in metadata)\n",
      "  April 2018: (empty)\n",
      "\n",
      "Identical coding scheme?: YES\n",
      "\n",
      "----- Group 25 -----\n",
      "Variables:\n",
      "- Province Recode (3 months)\n",
      "- province_recode (1 months)\n",
      "\n",
      "Variable: Province Recode\n",
      "Labels: (No labels found in metadata)\n",
      "  January 2018: (empty)\n",
      "  July 2018: (empty)\n",
      "  October 2018: (empty)\n",
      "\n",
      "Variable: province_recode\n",
      "Labels: (No labels found in metadata)\n",
      "  April 2018: (empty)\n",
      "\n",
      "Identical coding scheme?: YES\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from rapidfuzz import fuzz\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# ===============================================================\n",
    "# PATHS\n",
    "# ===============================================================\n",
    "decoded_path = os.path.join(base_path, \"Fully Decoded Surveys\")\n",
    "metadata_path = os.path.join(base_path, \"Metadata Sheet 2 CSV's\")\n",
    "\n",
    "# Month ordering for clean display\n",
    "month_order = {\n",
    "    \"January\": 1, \"February\": 2, \"March\": 3, \"April\": 4,\n",
    "    \"May\": 5, \"June\": 6, \"July\": 7, \"August\": 8,\n",
    "    \"September\": 9, \"October\": 10, \"November\": 11, \"December\": 12\n",
    "}\n",
    "\n",
    "# ===============================================================\n",
    "# STEP 1 â€” GET ALL VARIABLES + WHERE THEY APPEAR (MONTH COUNT)\n",
    "# ===============================================================\n",
    "all_columns = []\n",
    "variable_months = defaultdict(set)\n",
    "\n",
    "for year in os.listdir(decoded_path):\n",
    "    year_folder = os.path.join(decoded_path, year)\n",
    "    if not os.path.isdir(year_folder):\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(year_folder):\n",
    "        if not file.endswith(\".CSV\"):\n",
    "            continue\n",
    "\n",
    "        month = file.split(\"_\")[0].capitalize()\n",
    "        month_year = f\"{month} {year}\"\n",
    "        file_path = os.path.join(year_folder, file)\n",
    "\n",
    "        try:\n",
    "            df = pd.read_csv(file_path, low_memory=False)\n",
    "            for col in df.columns:\n",
    "                col_clean = col.strip()\n",
    "                all_columns.append(col_clean)\n",
    "                variable_months[col_clean].add(month_year)\n",
    "        except Exception as e:\n",
    "            print(f\"[ERROR] {file} -> {e}\")\n",
    "\n",
    "all_columns = sorted(set(all_columns))\n",
    "\n",
    "# ===============================================================\n",
    "# STEP 2 â€” EXCLUSIVE CLUSTERING (Fixes Duplication Issue)\n",
    "# ===============================================================\n",
    "similarity_threshold = 85\n",
    "filtered_groups = {} # Key = Main Variable, Value = List of Similar Variables\n",
    "processed_vars = set() # Keeps track of variables already assigned to a group\n",
    "\n",
    "for i, var1 in enumerate(all_columns):\n",
    "    # If var1 is already part of another group, skip it. \n",
    "    # This prevents it from creating a duplicate subset group later.\n",
    "    if var1 in processed_vars:\n",
    "        continue\n",
    "    \n",
    "    current_group = []\n",
    "\n",
    "    # Check against all subsequent variables\n",
    "    for j in range(i + 1, len(all_columns)):\n",
    "        var2 = all_columns[j]\n",
    "        \n",
    "        # If var2 is already taken, skip it\n",
    "        if var2 in processed_vars:\n",
    "            continue\n",
    "\n",
    "        # Compare\n",
    "        similarity = fuzz.token_sort_ratio(var1.lower(), var2.lower()) \n",
    "        \n",
    "        if similarity >= similarity_threshold:\n",
    "            current_group.append(var2)\n",
    "            processed_vars.add(var2) # Mark var2 as taken\n",
    "    \n",
    "    # Only save if we found matches\n",
    "    if current_group:\n",
    "        filtered_groups[var1] = current_group\n",
    "        processed_vars.add(var1) # Mark the leader as taken\n",
    "\n",
    "# ===============================================================\n",
    "# HELPER â€” LOAD PER-MONTH LABELS\n",
    "# ===============================================================\n",
    "def load_per_month_labels(variable):\n",
    "    results = defaultdict(set)\n",
    "    for year in os.listdir(metadata_path):\n",
    "        year_folder = os.path.join(metadata_path, year)\n",
    "        if not os.path.isdir(year_folder):\n",
    "            continue\n",
    "        for file in os.listdir(year_folder):\n",
    "            if not file.startswith(\"Sheet2_\") or not file.endswith(\".csv\"):\n",
    "                continue\n",
    "            month = file.split(\"_\")[1].capitalize()\n",
    "            month_year = f\"{month} {year}\"\n",
    "            file_path = os.path.join(year_folder, file)\n",
    "            try:\n",
    "                df = pd.read_csv(file_path, dtype=str).fillna(\"\")\n",
    "            except Exception:\n",
    "                continue\n",
    "            if \"Description\" not in df.columns or \"Label\" not in df.columns:\n",
    "                continue\n",
    "            # Exact match on description\n",
    "            match = df[df[\"Description\"].astype(str).str.strip().str.lower() == variable.lower()]\n",
    "            if not match.empty:\n",
    "                # Keep original formatting here for display purposes\n",
    "                labels_raw = [str(x).strip() for x in match[\"Label\"].tolist() if str(x).strip() != \"\"]\n",
    "                results[month_year].update(labels_raw)\n",
    "    return results\n",
    "\n",
    "# ===============================================================\n",
    "# HELPER - NORMALIZE TEXT (Aggressive)\n",
    "# ===============================================================\n",
    "def normalize(text):\n",
    "    \"\"\"\n",
    "    1. Converts to lowercase.\n",
    "    2. Replaces non-breaking spaces (\\xa0) with standard spaces.\n",
    "    3. Collapses multiple spaces into one.\n",
    "    \"\"\"\n",
    "    if not isinstance(text, str):\n",
    "        text = str(text)\n",
    "    text = text.replace('\\xa0', ' ') # Handle hidden non-breaking spaces\n",
    "    text = re.sub(r'\\s+', ' ', text) # Collapse multiple spaces\n",
    "    return text.strip().lower()\n",
    "\n",
    "# ===============================================================\n",
    "# STEP 3 â€” PRINT GROUPED ANALYSIS SUMMARY\n",
    "# ===============================================================\n",
    "print(\"\\n============================================================\")\n",
    "print(\"      GROUPS WITH DETAILED LABEL + MONTH DIFFERENCE CHECK      \")\n",
    "print(\"============================================================\\n\")\n",
    "\n",
    "group_number = 1\n",
    "\n",
    "for key, group in filtered_groups.items():\n",
    "    full_group = sorted(set([key] + group))\n",
    "\n",
    "    print(f\"\\n----- Group {group_number} -----\")\n",
    "\n",
    "    # Print variable list\n",
    "    print(\"Variables:\")\n",
    "    for var in full_group:\n",
    "        month_count = len(variable_months[var])\n",
    "        print(f\"- {var} ({month_count} months)\")\n",
    "\n",
    "    # Load labels\n",
    "    group_labels = {}\n",
    "    overall_label_union = {}\n",
    "    \n",
    "    # \"Pretty Print\" Map: normalized_string -> original_string\n",
    "    pretty_print_map = {}\n",
    "\n",
    "    for var in full_group:\n",
    "        per_month = load_per_month_labels(var)\n",
    "        group_labels[var] = per_month\n",
    "\n",
    "        overall = set()\n",
    "        for labels in per_month.values():\n",
    "            overall.update(labels)\n",
    "            # Populate the pretty map\n",
    "            for label in labels:\n",
    "                pretty_print_map[normalize(label)] = label\n",
    "        \n",
    "        overall_label_union[var] = overall\n",
    "\n",
    "        print(f\"\\nVariable: {var}\")\n",
    "        if not per_month:\n",
    "            print(\"Labels: (No labels found in metadata)\")\n",
    "\n",
    "        months_to_show = sorted(\n",
    "            [m for m in per_month.keys() if m in variable_months[var]],\n",
    "            key=lambda x: (int(x.split()[-1]), month_order.get(x.split()[0], 99))\n",
    "        )\n",
    "\n",
    "        if not months_to_show:\n",
    "            for m in sorted(variable_months[var], key=lambda x: (int(x.split()[-1]), month_order.get(x.split()[0], 99))):\n",
    "                print(f\"  {m}: (empty)\")\n",
    "        else:\n",
    "            for month in months_to_show:\n",
    "                labels = per_month.get(month, set())\n",
    "                # Sort by the original text\n",
    "                sorted_labels = sorted(list(labels))\n",
    "                \n",
    "                if len(sorted_labels) > 10:\n",
    "                     label_str = \", \".join(sorted_labels[:10]) + f\", ... (+{len(sorted_labels)-10} more)\"\n",
    "                else:\n",
    "                     label_str = \", \".join(sorted_labels)\n",
    "                \n",
    "                label_str = label_str if labels else \"(empty)\"\n",
    "                print(f\"  {month}: {label_str}\")\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    # LOGIC: NORMALIZE + TEMPORAL CHECK + PRETTY PRINTING\n",
    "    # --------------------------------------------------------------\n",
    "    \n",
    "    # 1. Build Global Fingerprints\n",
    "    fingerprints = {\n",
    "        var: frozenset([normalize(s) for s in overall_label_union.get(var, set())]) \n",
    "        for var in full_group\n",
    "    }\n",
    "    \n",
    "    reference_var = full_group[0]\n",
    "    reference_set = fingerprints[reference_var]\n",
    "\n",
    "    # 2. Global Vocabulary Check\n",
    "    same_global_vocab = all(fingerprints[v] == reference_set for v in full_group)\n",
    "\n",
    "    # 3. Temporal Consistency Check\n",
    "    temporal_mismatches = []\n",
    "    is_temporally_consistent = True\n",
    "\n",
    "    for var in full_group:\n",
    "        var_global_set = fingerprints[var] \n",
    "        \n",
    "        for month in variable_months[var]:\n",
    "            month_labels_raw = group_labels[var].get(month, set())\n",
    "            month_labels_normalized = set([normalize(s) for s in month_labels_raw])\n",
    "\n",
    "            missing_in_month = var_global_set - month_labels_normalized\n",
    "            \n",
    "            if missing_in_month:\n",
    "                is_temporally_consistent = False\n",
    "                missing_readable = sorted([pretty_print_map.get(x, x) for x in missing_in_month])\n",
    "                \n",
    "                if len(missing_readable) > 5:\n",
    "                    missing_str = \", \".join(missing_readable[:5]) + \"...\"\n",
    "                else:\n",
    "                    missing_str = \", \".join(missing_readable)\n",
    "                temporal_mismatches.append(f\"- {var} in {month} is missing: {missing_str}\")\n",
    "\n",
    "    # Final Decision\n",
    "    identical = same_global_vocab and is_temporally_consistent\n",
    "\n",
    "    print(\"\\nIdentical coding scheme?: \", end=\"\")\n",
    "    print(\"YES\" if identical else \"NO\")\n",
    "\n",
    "    # --------------------------------------------------------------\n",
    "    # Difference Reporting\n",
    "    # --------------------------------------------------------------\n",
    "    if not identical:\n",
    "        print(\"Differences found:\")\n",
    "\n",
    "        # Report Temporal Inconsistencies\n",
    "        if temporal_mismatches:\n",
    "             print(\">> TEMPORAL INCONSISTENCIES (Labels missing in specific months):\")\n",
    "             for mismatch in temporal_mismatches[:10]:\n",
    "                 print(mismatch)\n",
    "             if len(temporal_mismatches) > 10:\n",
    "                 print(f\"... and {len(temporal_mismatches) - 10} more months.\")\n",
    "\n",
    "        # Report Global Differences\n",
    "        for var in full_group:\n",
    "            if var == reference_var:\n",
    "                continue\n",
    "            cur_set = fingerprints[var]\n",
    "            extra_overall = cur_set - reference_set\n",
    "            missing_overall = reference_set - cur_set\n",
    "            \n",
    "            if extra_overall:\n",
    "                readable_extra = [pretty_print_map.get(x, x) for x in extra_overall]\n",
    "                print(f\"- {var} has EXTRA overall labels: {', '.join(sorted(readable_extra))}\")\n",
    "            \n",
    "            if missing_overall:\n",
    "                readable_missing = [pretty_print_map.get(x, x) for x in missing_overall]\n",
    "                print(f\"- {var} is MISSING overall labels: {', '.join(sorted(readable_missing))}\")\n",
    "\n",
    "    group_number += 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "282b80c3",
   "metadata": {},
   "source": [
    "\n",
    "#### Special Case: \"Available for Work\" variable\n",
    "\n",
    "The variables \"C27-Available for Work\" and \"C36-Available for Work\" has labels in a binary format.\n",
    "\n",
    "    \"C27-Available for Work\" - yes/no\n",
    "    \"C36-Available for Work\" - not available/yes available\n",
    "\n",
    "However, they have different text labels. In this case, we can standardize the label to \"Yes\" and \"No\".\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "fce2fdd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variables:\n",
      "- C27-Available for Work (17 months)\n",
      "- C36-Available for Work (17 months)\n",
      "Variable: C27-Available for Work\n",
      "  August 2022: no, yes\n",
      "  September 2022: no, yes\n",
      "  November 2022: no, yes\n",
      "  December 2022: no, yes\n",
      "  February 2023: no, yes\n",
      "  March 2023: no, yes\n",
      "  May 2023: no, yes\n",
      "  June 2023: no, yes\n",
      "  August 2023: no, yes\n",
      "  September 2023: no, yes\n",
      "  November 2023: no, yes\n",
      "  December 2023: no, yes\n",
      "  February 2024: no, yes\n",
      "  March 2024: no, yes\n",
      "  May 2024: no, yes\n",
      "  June 2024: no, yes\n",
      "  August 2024: no, yes\n",
      "Variable: C36-Available for Work\n",
      "  January 2018: not available, yes available\n",
      "  April 2018: not available, yes available\n",
      "  July 2018: not available, yes available\n",
      "  October 2018: not available, yes available\n",
      "  January 2019: not available, yes available\n",
      "  April 2019: not available, yes available\n",
      "  July 2019: not available, yes available\n",
      "  October 2019: not available, yes available\n",
      "  July 2022: not available, yes available\n",
      "  October 2022: not available, yes available\n",
      "  January 2023: not available, yes available\n",
      "  April 2023: not available, yes available\n",
      "  July 2023: not available, yes available\n",
      "  October 2023: not available, yes available\n",
      "  January 2024: not available, yes available\n",
      "  April 2024: not available, yes available\n",
      "  July 2024: not available, yes available\n",
      "\n",
      "Identical coding scheme?: NO\n",
      "Differences found:\n",
      "- C36-Available for Work has EXTRA overall labels: not available, yes available\n",
      "- C36-Available for Work is MISSING overall labels: no, yes\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# ===============================================================\n",
    "# CONFIGURATION AND INPUTS (Assumed to be defined in environment)\n",
    "# ===============================================================\n",
    "# base_path = r\"G:\\...\"  # Assumed to be defined globally\n",
    "# month_order = { ... } # Assumed to be defined globally\n",
    "# variable_months = { ... } # Assumed to be defined globally after Step 1 scan\n",
    "\n",
    "# The specific variables identified for comparison\n",
    "VARIABLES_TO_COMPARE = [\n",
    "    \"C27-Available for Work\",\n",
    "    \"C36-Available for Work\"\n",
    "]\n",
    "\n",
    "# Assuming the metadata_path is derived from base_path and the folder name:\n",
    "METADATA_FOLDER = \"Metadata Sheet 2 CSV's\"\n",
    "try:\n",
    "    metadata_path = os.path.join(base_path, METADATA_FOLDER)\n",
    "except NameError:\n",
    "    print(\"ERROR: 'base_path' is not defined. Please ensure the base path is set globally.\")\n",
    "    exit()\n",
    "\n",
    "# NOTE: The helper functions load_per_month_labels() and normalize() \n",
    "# must be defined in your environment before running this block.\n",
    "\n",
    "# ===============================================================\n",
    "# CORE ANALYSIS LOGIC\n",
    "# ===============================================================\n",
    "group_labels = {}\n",
    "overall_label_union = {}\n",
    "pretty_print_map = {}\n",
    "\n",
    "# 1. Load Labels and Build Global Fingerprints\n",
    "for var in VARIABLES_TO_COMPARE:\n",
    "    try:\n",
    "        # Calls the function from your Part 5/original code\n",
    "        per_month = load_per_month_labels(var)\n",
    "    except Exception as e:\n",
    "        print(f\"Error loading labels for {var}: {e}\")\n",
    "        continue\n",
    "        \n",
    "    group_labels[var] = per_month\n",
    "\n",
    "    overall = set()\n",
    "    for labels in per_month.values():\n",
    "        overall.update(labels)\n",
    "        # Populate the pretty map\n",
    "        for label in labels:\n",
    "            pretty_print_map[normalize(label)] = label\n",
    "    \n",
    "    overall_label_union[var] = overall\n",
    "\n",
    "# 2. Print Summary in Desired Format\n",
    "print(f\"Variables:\")\n",
    "for var in VARIABLES_TO_COMPARE:\n",
    "    # Use variable_months loaded from your Step 1 scan\n",
    "    month_count = len(variable_months.get(var, set()))\n",
    "    print(f\"- {var} ({month_count} months)\")\n",
    "\n",
    "for var in VARIABLES_TO_COMPARE:\n",
    "    print(f\"Variable: {var}\")\n",
    "    per_month = group_labels.get(var, {})\n",
    "    \n",
    "    # Sort months correctly using month_order\n",
    "    months_to_show = sorted(\n",
    "        [m for m in per_month.keys() if m in variable_months.get(var, set())],\n",
    "        key=lambda x: (int(x.split()[-1]), month_order.get(x.split()[0], 99))\n",
    "    )\n",
    "    \n",
    "    for month in months_to_show:\n",
    "        labels = per_month.get(month, set())\n",
    "        # Sort labels alphabetically for consistent output\n",
    "        sorted_labels = sorted(list(labels))\n",
    "        label_str = \", \".join(sorted_labels)\n",
    "        print(f\"  {month}: {label_str}\")\n",
    "\n",
    "# 3. Consistency Checks\n",
    "\n",
    "# 3.1. Build Global Fingerprints (Normalized sets)\n",
    "fingerprints = {\n",
    "    var: frozenset([normalize(s) for s in overall_label_union.get(var, set())]) \n",
    "    for var in VARIABLES_TO_COMPARE\n",
    "}\n",
    "\n",
    "# Assume the first variable is the reference\n",
    "reference_var = VARIABLES_TO_COMPARE[0] \n",
    "reference_set = fingerprints.get(reference_var, set())\n",
    "\n",
    "# 3.2. Global Vocabulary Check (Only compares C27 vs C36)\n",
    "if len(VARIABLES_TO_COMPARE) == 2:\n",
    "    other_var = VARIABLES_TO_COMPARE[1]\n",
    "    other_set = fingerprints.get(other_var, set())\n",
    "    \n",
    "    same_global_vocab = reference_set == other_set\n",
    "    # Since we are only checking two variables, temporal check logic is simplified\n",
    "    is_temporally_consistent = True # Assuming per-month labels are subsets of global union (usually true if data pipeline worked)\n",
    "else:\n",
    "    # Generalized check for N variables\n",
    "    same_global_vocab = all(fingerprints[v] == reference_set for v in VARIABLES_TO_COMPARE)\n",
    "    is_temporally_consistent = True # Skip full temporal check for brevity, rely on global check for this comparison\n",
    "\n",
    "# Final Decision\n",
    "identical = same_global_vocab and is_temporally_consistent\n",
    "\n",
    "print(\"\\nIdentical coding scheme?: \", end=\"\")\n",
    "print(\"YES\" if identical else \"NO\")\n",
    "\n",
    "# 4. Difference Reporting (If NO)\n",
    "if not identical and len(VARIABLES_TO_COMPARE) == 2:\n",
    "    print(\"Differences found:\")\n",
    "    \n",
    "    # We compare C36 against C27 (reference_var)\n",
    "    var = other_var\n",
    "    cur_set = other_set\n",
    "    \n",
    "    extra_overall = cur_set - reference_set\n",
    "    missing_overall = reference_set - cur_set\n",
    "    \n",
    "    # Convert back to original format for display\n",
    "    if extra_overall:\n",
    "        readable_extra = [pretty_print_map.get(x, x) for x in extra_overall]\n",
    "        print(f\"- {var} has EXTRA overall labels: {', '.join(sorted(readable_extra))}\")\n",
    "    \n",
    "    if missing_overall:\n",
    "        readable_missing = [pretty_print_map.get(x, x) for x in missing_overall]\n",
    "        print(f\"- {var} is MISSING overall labels: {', '.join(sorted(readable_missing))}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61440e11",
   "metadata": {},
   "source": [
    "### Renaming Variables Code + Automated saving into a new folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "a88e0dfb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output folder created/verified: /Users/neilkeannedelavega/Library/CloudStorage/GoogleDrive-shaniakeith23@gmail.com/My Drive/Labor Force Survey/Renamed Fully Decoded Surveys\n",
      "\n",
      "--- STARTING BATCH RENAMING AND SAVING ---\n",
      "Source: Fully Decoded Surveys\n",
      "Destination: Renamed Fully Decoded Surveys\n",
      "Total variables to unify: 31\n",
      "--------------------------------------------------\n",
      "[OK] 2018/JULY_2018.CSV: Unified 14 column(s).\n",
      "[OK] 2018/OCTOBER_2018.CSV: Unified 14 column(s).\n",
      "[OK] 2018/APRIL_2018.CSV: Unified 14 column(s).\n",
      "[OK] 2018/JANUARY_2018.CSV: Unified 14 column(s).\n",
      "[OK] 2019/JULY_2019.CSV: Unified 12 column(s).\n",
      "[OK] 2019/JANUARY_2019.CSV: Unified 12 column(s).\n",
      "[OK] 2019/APRIL_2019.CSV: Unified 12 column(s).\n",
      "[OK] 2019/OCTOBER_2019.CSV: Unified 12 column(s).\n",
      "[OK] 2022/DECEMBER_2022.CSV: Unified 13 column(s).\n",
      "[OK] 2022/FEBRUARY_2022.csv: Unified 12 column(s).\n",
      "[OK] 2022/SEPTEMBER_2022.CSV: Unified 13 column(s).\n",
      "[OK] 2022/NOVEMBER_2022.CSV: Unified 13 column(s).\n",
      "[OK] 2022/JULY_2022.CSV: Unified 12 column(s).\n",
      "[OK] 2022/JUNE_2022.csv: Unified 13 column(s).\n",
      "[OK] 2022/MAY_2022.csv: Unified 13 column(s).\n",
      "[OK] 2022/AUGUST_2022.CSV: Unified 13 column(s).\n",
      "[OK] 2022/OCTOBER_2022.CSV: Unified 12 column(s).\n",
      "[OK] 2022/APRIL_2022.csv: Unified 12 column(s).\n",
      "[OK] 2022/JANUARY_2022.csv: Unified 12 column(s).\n",
      "[OK] 2022/MARCH_2022.csv: Unified 12 column(s).\n",
      "[OK] 2023/DECEMBER_2023.CSV: Unified 12 column(s).\n",
      "[OK] 2023/FEBRUARY_2023.CSV: Unified 13 column(s).\n",
      "[OK] 2023/SEPTEMBER_2023.CSV: Unified 12 column(s).\n",
      "[OK] 2023/NOVEMBER_2023.CSV: Unified 12 column(s).\n",
      "[OK] 2023/JUNE_2023.CSV: Unified 13 column(s).\n",
      "[OK] 2023/JULY_2023.CSV: Unified 12 column(s).\n",
      "[OK] 2023/MAY_2023.CSV: Unified 13 column(s).\n",
      "[OK] 2023/AUGUST_2023.CSV: Unified 12 column(s).\n",
      "[OK] 2023/JANUARY_2023.CSV: Unified 12 column(s).\n",
      "[OK] 2023/APRIL_2023.CSV: Unified 12 column(s).\n",
      "[OK] 2023/OCTOBER_2023.CSV: Unified 11 column(s).\n",
      "[OK] 2023/MARCH_2023.CSV: Unified 13 column(s).\n",
      "[OK] 2024/FEBRUARY_2024.CSV: Unified 12 column(s).\n",
      "[OK] 2024/JULY_2024.CSV: Unified 11 column(s).\n",
      "[OK] 2024/JUNE_2024.CSV: Unified 12 column(s).\n",
      "[OK] 2024/APRIL_2024.CSV: Unified 11 column(s).\n",
      "[OK] 2024/JANUARY_2024.CSV: Unified 11 column(s).\n",
      "[OK] 2024/MARCH_2024.CSV: Unified 12 column(s).\n",
      "[OK] 2024/MAY_2024.CSV: Unified 12 column(s).\n",
      "[OK] 2024/AUGUST_2024.CSV: Unified 11 column(s).\n",
      "--------------------------------------------------\n",
      "BATCH RENAMING COMPLETE.\n",
      "Total Files Processed: 40\n",
      "Total Columns Unified Across All Files: 493\n",
      "Consolidated data is ready for FMI analysis in the 'Renamed Fully Decoded Surveys' folder.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# ===============================================================\n",
    "# USER-DEFINED INPUT: THE RENAMING INSTRUCTION MAP\n",
    "# ===============================================================\n",
    "RENAMING_MAP = {\n",
    "    # --- ADDED: Available for Work Consolidation ---\n",
    "    \"Available for Work\": [\n",
    "        \"C27-Available for Work\", \n",
    "        \"C36-Available for Work\"\n",
    "    ],\n",
    "    \"Urban-RuralFIES\": [\n",
    "        \"2010Urban-RuralFIES\", \n",
    "        \"2015Urban-RuralFIES\"\n",
    "    ],\n",
    "    \"Location of Work (Province, Municipality)\": [\n",
    "        \"C11 - Location of Work (Province, Municipality)\", \n",
    "        \"C11-Location of Work (Province, Municipality)\", \n",
    "        \"C12A - Location of Work (Province, Municipality)\"\n",
    "    ],\n",
    "    \"Normal Working Hours per Day\": [\n",
    "        \"C17-Normal Working Hours per Day\", \n",
    "        \"C18-Normal Working Hours per Day\"\n",
    "    ],\n",
    "    \"Want More Hours of Work\": [\n",
    "        \"C19-Want More Hours of Work\", \n",
    "        \"C20-Want More Hours of Work\"\n",
    "    ],\n",
    "    \"Look for Additional Work\": [\n",
    "        \"C20-Look for Additional Work\", \n",
    "        \"C21-Look for Additional Work\"\n",
    "    ],\n",
    "    \"Other Job Indicator\": [\n",
    "        \"C22-Other Job Indicator\", \n",
    "        \"C26-Other Job Indicator\"\n",
    "    ],\n",
    "    \"Total Hours Worked for all Jobs\": [\n",
    "        \"C23-Total Hours Worked for all Jobs\", \n",
    "        \"C28-Total Hours Worked for all Jobs\"\n",
    "    ],\n",
    "    \"Looked for Work or Tried to Establish Business During the Past Week\": [\n",
    "        \"C25-Looked for Work or Tried to Establish Business during the past week\", \n",
    "        \"C30-Looked for Work or Tried to Establish Business during the past week\"\n",
    "    ],\n",
    "    \"First Time to Look for Work\": [\n",
    "        \"C25B - First time to look for work\", \n",
    "        \"C31-First Time to Look for Work\"\n",
    "    ],\n",
    "    \"Previous Job Indicator\": [\n",
    "        \"C28-Previous Job Indicator\", \n",
    "        \"C38-Previous Job Indicator\"\n",
    "    ],\n",
    "    \"Previous Occupation\": [\n",
    "        \"C31-Previous Occupation\", \n",
    "        \"C40-Previous Occupation\"\n",
    "    ],\n",
    "    \"Kind of Business (Past Quarter)\": [\n",
    "        \"C33-Kind of Business (past quarter)\", \n",
    "        \"C43-Kind of Business (past quarter)\"\n",
    "    ],\n",
    "    \"Province\": [\n",
    "        \"Province\", \n",
    "        \"province\"\n",
    "    ],\n",
    "    \"Province Recode\": [\n",
    "        \"Province Recode\", \n",
    "        \"province_recode\"\n",
    "    ]\n",
    "}\n",
    "\n",
    "# ===============================================================\n",
    "# VALUE HARMONIZATION DICTIONARY\n",
    "# Used to recode the cell values for 'Available for Work'\n",
    "# The keys are case-insensitive.\n",
    "# ===============================================================\n",
    "AVAILABLE_FOR_WORK_HARMONIZATION = {\n",
    "    \"no\": \"No\",\n",
    "    \"yes\": \"Yes\",\n",
    "    \"not available\": \"No\",\n",
    "    \"yes available\": \"Yes\"\n",
    "}\n",
    "\n",
    "\n",
    "# ===============================================================\n",
    "# PATHS AND CONFIGURATION (Steps 2 & 3)\n",
    "# ===============================================================\n",
    "# ASSUMPTION: 'base_path' is defined globally.\n",
    "\n",
    "SOURCE_FOLDER = \"Fully Decoded Surveys\"\n",
    "DESTINATION_FOLDER = \"Renamed Fully Decoded Surveys\"\n",
    "\n",
    "try:\n",
    "    decoded_path = os.path.join(base_path, SOURCE_FOLDER)\n",
    "    renamed_path = os.path.join(base_path, DESTINATION_FOLDER)\n",
    "except NameError:\n",
    "    # Handle case where base_path isn't defined, although it's assumed\n",
    "    print(\"Error: 'base_path' is not defined. Ensure it is set before running.\")\n",
    "    exit()\n",
    "\n",
    "os.makedirs(renamed_path, exist_ok=True)\n",
    "print(f\"Output folder created/verified: {renamed_path}\\n\")\n",
    "\n",
    "# --- 1. Renaming Map Generation ---\n",
    "REVERSE_RENAMING_MAP = {}\n",
    "for new_name, old_names in RENAMING_MAP.items():\n",
    "    for old_name in old_names:\n",
    "        REVERSE_RENAMING_MAP[old_name.strip()] = new_name.strip()\n",
    "        \n",
    "# --- 2. Renaming Function (Integrated Harmonization) ---\n",
    "\n",
    "def rename_and_save_survey(source_filepath, dest_filepath, renaming_map, harmonization_map):\n",
    "    \"\"\"\n",
    "    Loads a single survey file, performs value harmonization on 'Available for Work',\n",
    "    renames specified columns, and saves the result.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        df = pd.read_csv(source_filepath, low_memory=False) \n",
    "        columns_to_rename = {}\n",
    "        \n",
    "        # Determine the target column names for harmonization\n",
    "        available_for_work_cols = [\n",
    "            col for col in df.columns \n",
    "            if col.strip() in [\"C27-Available for Work\", \"C36-Available for Work\"]\n",
    "        ]\n",
    "        \n",
    "        # --- DATA HARMONIZATION STEP ---\n",
    "        if available_for_work_cols:\n",
    "            harmonization_lookup = {k.lower(): v for k, v in harmonization_map.items()}\n",
    "            \n",
    "            for col in available_for_work_cols:\n",
    "                # Apply the recoding based on the harmonization map\n",
    "                # .str.lower().map() ensures case-insensitivity during lookup\n",
    "                df[col] = df[col].astype(str).str.strip().str.lower().map(harmonization_lookup).fillna(df[col])\n",
    "                # Note: The .fillna(df[col]) keeps values that were not in the harmonization list (like NaNs)\n",
    "        \n",
    "        # --- COLUMN RENAMING STEP ---\n",
    "        for col in df.columns:\n",
    "            if col.strip() in renaming_map:\n",
    "                columns_to_rename[col] = renaming_map[col]\n",
    "        \n",
    "        if columns_to_rename:\n",
    "            df = df.rename(columns=columns_to_rename)\n",
    "        \n",
    "        # --- SAVING ---\n",
    "        # The file is saved with unified headers AND harmonized values\n",
    "        df.to_csv(dest_filepath, index=False)\n",
    "        \n",
    "        return len(columns_to_rename)\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"[ERROR] Processing {source_filepath}: {e}\")\n",
    "        return -1\n",
    "\n",
    "\n",
    "# --- 3. Batch Processing Automation (Step 3 Implementation) ---\n",
    "\n",
    "def run_batch_renaming(source_root, dest_root, renaming_map, harmonization_map):\n",
    "    \"\"\"\n",
    "    Iterates through all files in the source folder, applies renaming/harmonization, \n",
    "    and saves them to the destination folder.\n",
    "    \"\"\"\n",
    "    total_files_processed = 0\n",
    "    total_columns_unified = 0\n",
    "    \n",
    "    print(f\"--- STARTING BATCH RENAMING AND SAVING ---\")\n",
    "    print(f\"Source: {SOURCE_FOLDER}\")\n",
    "    print(f\"Destination: {DESTINATION_FOLDER}\")\n",
    "    print(f\"Total variables to unify: {len(REVERSE_RENAMING_MAP)}\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    for year in sorted(os.listdir(source_root)):\n",
    "        year_source_folder = os.path.join(source_root, year)\n",
    "        \n",
    "        if not os.path.isdir(year_source_folder): continue\n",
    "        \n",
    "        year_dest_folder = os.path.join(dest_root, year)\n",
    "        os.makedirs(year_dest_folder, exist_ok=True)\n",
    "        \n",
    "        for filename in os.listdir(year_source_folder):\n",
    "            if filename.lower().endswith(\".csv\"):\n",
    "                \n",
    "                source_filepath = os.path.join(year_source_folder, filename)\n",
    "                dest_filepath = os.path.join(year_dest_folder, filename)\n",
    "                \n",
    "                # Call the integrated function\n",
    "                renamed_count = rename_and_save_survey(\n",
    "                    source_filepath, dest_filepath, renaming_map=renaming_map, harmonization_map=harmonization_map\n",
    "                )\n",
    "                \n",
    "                if renamed_count >= 0:\n",
    "                    total_files_processed += 1\n",
    "                    total_columns_unified += renamed_count\n",
    "                    if renamed_count > 0:\n",
    "                        print(f\"[OK] {year}/{filename}: Unified {renamed_count} column(s).\")\n",
    "                    else:\n",
    "                        print(f\"[OK] {year}/{filename}: Saved (No unification needed in this file).\")\n",
    "                \n",
    "                else:\n",
    "                    print(f\"[FAIL] {year}/{filename}: Check error log above.\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"BATCH RENAMING COMPLETE.\")\n",
    "    print(f\"Total Files Processed: {total_files_processed}\")\n",
    "    print(f\"Total Columns Unified Across All Files: {total_columns_unified}\")\n",
    "    print(f\"Consolidated data is ready for FMI analysis in the '{DESTINATION_FOLDER}' folder.\")\n",
    "\n",
    "\n",
    "# --- EXECUTION BLOCK ---\n",
    "if __name__ == \"__main__\":\n",
    "    # Ensure base_path is defined if running outside of a notebook cell\n",
    "    # Example: base_path = r\"G:\\.shortcut-targets-by-id\\...\" \n",
    "    \n",
    "    # Run the batch processor\n",
    "    run_batch_renaming(decoded_path, renamed_path, REVERSE_RENAMING_MAP, AVAILABLE_FOR_WORK_HARMONIZATION)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27478aa",
   "metadata": {},
   "source": [
    "### Duplication check code\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "9ef681ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING DUPLICATE HEADER CHECK ---\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "DUPLICATION CHECK COMPLETE.\n",
      "Total files checked: 40\n",
      "No duplicate headers found across all files. (Ready for FMI)\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "\n",
    "# Source folder from the renaming step\n",
    "SOURCE_FOLDER = \"Renamed Fully Decoded Surveys\" \n",
    "renamed_path = os.path.join(base_path, SOURCE_FOLDER)\n",
    "\n",
    "# ===============================================================\n",
    "# HEADER DUPLICATION CHECK\n",
    "# ===============================================================\n",
    "\n",
    "def check_duplicate_headers(source_root):\n",
    "    \"\"\"\n",
    "    Iterates through all CSV files in the source_root and checks \n",
    "    each DataFrame for duplicate column headers resulting from the renaming.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(source_root):\n",
    "        print(f\"[ERROR] Source folder not found: {source_root}\")\n",
    "        return\n",
    "\n",
    "    print(\"--- STARTING DUPLICATE HEADER CHECK ---\")\n",
    "    print(\"-\" * 50)\n",
    "    \n",
    "    total_files_checked = 0\n",
    "    files_with_duplicates = 0\n",
    "    \n",
    "    for year in sorted(os.listdir(source_root)):\n",
    "        year_source_folder = os.path.join(source_root, year)\n",
    "        \n",
    "        if not os.path.isdir(year_source_folder): \n",
    "            continue\n",
    "        \n",
    "        for filename in os.listdir(year_source_folder):\n",
    "            if filename.lower().endswith(\".csv\"):\n",
    "                \n",
    "                source_filepath = os.path.join(year_source_folder, filename)\n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_csv(source_filepath, low_memory=False)\n",
    "                    total_files_checked += 1\n",
    "                    \n",
    "                    # 1. Get all column names\n",
    "                    columns = df.columns.tolist()\n",
    "                    \n",
    "                    # 2. Find duplicated column names\n",
    "                    seen = set()\n",
    "                    duplicates = set()\n",
    "                    \n",
    "                    for col in columns:\n",
    "                        if col in seen:\n",
    "                            duplicates.add(col)\n",
    "                        seen.add(col)\n",
    "                        \n",
    "                    if duplicates:\n",
    "                        files_with_duplicates += 1\n",
    "                        print(f\"[DUPLICATE FOUND] {year}/{filename}\")\n",
    "                        print(f\"    Duplicated Headers: {sorted(list(duplicates))}\")\n",
    "                    # else:\n",
    "                        # Optionally print success for every file:\n",
    "                        # print(f\"[OK] {year}/{filename}: No duplicate headers.\")\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Failed to read {year}/{filename}: {e}\")\n",
    "\n",
    "    print(\"-\" * 50)\n",
    "    print(\"DUPLICATION CHECK COMPLETE.\")\n",
    "    print(f\"Total files checked: {total_files_checked}\")\n",
    "    if files_with_duplicates > 0:\n",
    "        print(f\"Total files with duplicates: {files_with_duplicates} (REQUIRES CONSOLIDATION)\")\n",
    "    else:\n",
    "        print(\"No duplicate headers found across all files. (Ready for FMI)\")\n",
    "\n",
    "\n",
    "# --- EXECUTION BLOCK ---\n",
    "if __name__ == \"__main__\":\n",
    "    check_duplicate_headers(renamed_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "470ea072",
   "metadata": {},
   "source": [
    "#### Checking for duplicates and the labels in the \"Available for Work\" variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "d188d595",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- STARTING DUPLICATE HEADER CHECK FOR \"Available for Work\" VARIABLE ---\n",
      "--------------------------------------------------\n",
      "--------------------------------------------------\n",
      "Available for Work\n",
      "Labels: No, Yes\n",
      "\n",
      "==================================================\n",
      "Total files checked: 40\n",
      "No duplicate headers found across all files.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "from collections import defaultdict\n",
    "import re\n",
    "\n",
    "# ===============================================================\n",
    "# PATHS AND CONFIGURATION\n",
    "# ===============================================================\n",
    "# ASSUMPTION: 'base_path' is defined globally.\n",
    "\n",
    "SOURCE_FOLDER = \"Renamed Fully Decoded Surveys\" \n",
    "renamed_path = os.path.join(base_path, SOURCE_FOLDER)\n",
    "\n",
    "# The specific consolidated variable we are checking\n",
    "TARGET_VARIABLE = \"Available for Work\"\n",
    "\n",
    "# ===============================================================\n",
    "# CHECK FUNCTIONS\n",
    "# ===============================================================\n",
    "\n",
    "def validate_available_for_work(source_root):\n",
    "    \"\"\"\n",
    "    Checks all files for the consolidation integrity of the 'Available for Work'\n",
    "    variable, verifies its label set, and checks for any duplicated headers.\n",
    "    \"\"\"\n",
    "    if not os.path.exists(source_root):\n",
    "        print(f\"[ERROR] Source folder not found: {source_root}\")\n",
    "        return\n",
    "\n",
    "    # Tracking variables\n",
    "    months_with_variable_present = set() \n",
    "    global_label_set = set()\n",
    "    \n",
    "    total_files_checked = 0\n",
    "    files_with_duplicates = 0\n",
    "    \n",
    "    # --- MODIFICATION 1: Update the starting print statement ---\n",
    "    print(f\"--- STARTING DUPLICATE HEADER CHECK FOR \\\"{TARGET_VARIABLE}\\\" VARIABLE ---\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # --- 1. Iterate through files and check integrity ---\n",
    "    for year in sorted(os.listdir(source_root)):\n",
    "        year_source_folder = os.path.join(source_root, year)\n",
    "        if not os.path.isdir(year_source_folder): \n",
    "            continue\n",
    "        \n",
    "        for filename in os.listdir(year_source_folder):\n",
    "            if filename.lower().endswith(\".csv\"):\n",
    "                \n",
    "                source_filepath = os.path.join(year_source_folder, filename)\n",
    "                month_part = filename.split('_')[0].capitalize()\n",
    "                month_year = f\"{month_part} {year}\"\n",
    "                \n",
    "                try:\n",
    "                    df = pd.read_csv(source_filepath, low_memory=False)\n",
    "                    total_files_checked += 1\n",
    "                    \n",
    "                    # --- A. Duplicated Headers Check ---\n",
    "                    if len(df.columns) != len(set(df.columns)):\n",
    "                        files_with_duplicates += 1\n",
    "                    \n",
    "                    # --- B. Variable Consolidation and Label Check ---\n",
    "                    \n",
    "                    # Check for the presence of the target variable\n",
    "                    if TARGET_VARIABLE in df.columns:\n",
    "                        \n",
    "                        # Check for single consolidation: must only appear once\n",
    "                        if list(df.columns).count(TARGET_VARIABLE) == 1:\n",
    "                            \n",
    "                            # Add the month/year ONLY if the variable is present and correctly consolidated\n",
    "                            months_with_variable_present.add(month_year)\n",
    "                            \n",
    "                            # Extract unique labels (excluding NaNs and potential blanks)\n",
    "                            labels = df[TARGET_VARIABLE].dropna().unique()\n",
    "                            \n",
    "                            # Ensure labels are treated as strings and stripped for safety\n",
    "                            cleaned_labels = {str(l).strip() for l in labels if str(l).strip() != ''}\n",
    "                            \n",
    "                            global_label_set.update(cleaned_labels)\n",
    "                            \n",
    "                        elif list(df.columns).count(TARGET_VARIABLE) > 1:\n",
    "                            files_with_duplicates += 1 \n",
    "                    \n",
    "                except Exception as e:\n",
    "                    print(f\"[ERROR] Failed to read {year}/{filename}: {e}\")\n",
    "\n",
    "    # --- 2. Print Final Summary ---\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "    # Sort labels to match expected output format\n",
    "    sorted_labels = sorted(list(global_label_set))\n",
    "    \n",
    "    # --- MODIFICATION 2: Removed month count and parentheses ---\n",
    "    print(f\"{TARGET_VARIABLE}\")\n",
    "    print(f\"Labels: {', '.join(sorted_labels)}\")\n",
    "    print(\"\\n\" + \"=\" * 50)\n",
    "    \n",
    "    print(f\"Total files checked: {total_files_checked}\")\n",
    "    if files_with_duplicates > 0:\n",
    "        print(f\"WARNING: {files_with_duplicates} files contained duplicate headers (REQUIRES CONSOLIDATION STEP).\")\n",
    "    else:\n",
    "        print(\"No duplicate headers found across all files.\")\n",
    "\n",
    "\n",
    "# --- EXECUTION BLOCK ---\n",
    "if __name__ == \"__main__\":\n",
    "    try:\n",
    "        # Assumes base_path is defined globally\n",
    "        validate_available_for_work(renamed_path)\n",
    "    except NameError:\n",
    "        print(\"ERROR: 'base_path' variable not found. Please ensure it is defined before execution.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c923730e",
   "metadata": {},
   "source": [
    "### Code Automation for FMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0e178d42",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# --- Missingness detector ---\n",
    "TEXT_MISSING = {\"\", \" \", \"NA\", \"N/A\", \"NaN\", \"nan\", \".\", \"-\", \"_\"}\n",
    "NUMERIC_SENTINELS = {9, 99, 999, 9999, -9, -99, -999, -9999}\n",
    "\n",
    "def build_missing_mask(series: pd.Series,\n",
    "                       include_numeric_sentinels: bool = True) -> pd.Series:\n",
    "    \"\"\"\n",
    "    Detect missing values for FMI with decode-aware logic:\n",
    "    - NaN\n",
    "    - Empty strings / whitespace-only\n",
    "    - Explicit blanks introduced by decoding (survey value missing OR metadata missing)\n",
    "    - Common text tokens (NA, N/A, ., -, _)\n",
    "    - Optional numeric sentinels (9, 99, 999, ... and negatives)\n",
    "    \"\"\"\n",
    "    s = series.astype(str).str.strip()\n",
    "    mask = series.isna() | (s == \"\") | s.isin(TEXT_MISSING)\n",
    "\n",
    "    if include_numeric_sentinels:\n",
    "        s_num = pd.to_numeric(series, errors=\"coerce\")\n",
    "        mask |= s_num.isin(NUMERIC_SENTINELS)\n",
    "\n",
    "    return mask\n",
    "\n",
    "\n",
    "def fmi_scan_csv(file_path: str, year: str, month: str,\n",
    "                 include_numeric_sentinels: bool = True) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Compute FMI per column for a single survey CSV.\n",
    "    Duplicate headers are consolidated: only one FMI per unique column name.\n",
    "    \"\"\"\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    rows = []\n",
    "\n",
    "    # --- Consolidate duplicates ---\n",
    "    unique_columns = []\n",
    "    seen = set()\n",
    "    for col in df.columns:\n",
    "        if col not in seen:\n",
    "            unique_columns.append(col)\n",
    "            seen.add(col)\n",
    "        else:\n",
    "            # Skip duplicate header\n",
    "            continue\n",
    "\n",
    "    # --- Scan only unique columns ---\n",
    "    for col in unique_columns:\n",
    "        miss_mask = build_missing_mask(df[col], include_numeric_sentinels=include_numeric_sentinels)\n",
    "        missing = int(miss_mask.sum())\n",
    "        total = int(len(df[col]))\n",
    "        fmi = (missing / total) if total > 0 else 0.0\n",
    "\n",
    "        # Flag severity\n",
    "        if fmi < 0.05:\n",
    "            flag, rec = \"Low\", \"Keep\"\n",
    "        elif fmi < 0.20:\n",
    "            flag, rec = \"Moderate\", \"Consider imputation\"\n",
    "        elif fmi < 0.40:\n",
    "            flag, rec = \"High\", \"Strongly consider imputation\"\n",
    "        else:\n",
    "            flag, rec = \"Critical\", \"Candidate to drop (validate with business logic)\"\n",
    "\n",
    "        rows.append({\n",
    "            \"Year\": year,\n",
    "            \"Month\": month,\n",
    "            \"Column\": col,\n",
    "            \"Missing\": missing,\n",
    "            \"Total\": total,\n",
    "            \"FMI\": round(fmi, 6),\n",
    "            \"Flag\": flag,\n",
    "            \"Recommendation\": rec\n",
    "        })\n",
    "\n",
    "    return pd.DataFrame(rows)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8e72a1ce",
   "metadata": {},
   "source": [
    "### Automation tester for FMI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "405fd3f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scanned 50 variables\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Total</th>\n",
       "      <th>FMI</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Region</td>\n",
       "      <td>0</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Province</td>\n",
       "      <td>592</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.003284</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Province Recode</td>\n",
       "      <td>0</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Household Unique Sequential Number</td>\n",
       "      <td>17</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.000094</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Urban-RuralFIES</td>\n",
       "      <td>0</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Final Weight Based on Projection (provincial p...</td>\n",
       "      <td>0</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Survey Month</td>\n",
       "      <td>0</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Survey Year</td>\n",
       "      <td>0</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Psu Number</td>\n",
       "      <td>1246</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.006912</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Replicate</td>\n",
       "      <td>637</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.003534</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Household Size</td>\n",
       "      <td>7695</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.042688</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C101-Line Number</td>\n",
       "      <td>1824</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.010119</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C03-Relationship to Household Head</td>\n",
       "      <td>0</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C04-Sex</td>\n",
       "      <td>0</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C05-Age as of Last Birthday</td>\n",
       "      <td>0</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C06-Marital Status</td>\n",
       "      <td>16515</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.091617</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C07-Highest Grade Completed</td>\n",
       "      <td>16515</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.091617</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C08-Currently Attending School</td>\n",
       "      <td>106696</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.591894</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C09-Graduate of technical/vocational course</td>\n",
       "      <td>56585</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.313904</td>\n",
       "      <td>High</td>\n",
       "      <td>Strongly consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C10-Overseas Filipino Indicator</td>\n",
       "      <td>56585</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.313904</td>\n",
       "      <td>High</td>\n",
       "      <td>Strongly consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C11-Work Indicator</td>\n",
       "      <td>19878</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.110273</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C12-Job Indicator</td>\n",
       "      <td>91203</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.505947</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C14-Primary Occupation</td>\n",
       "      <td>108182</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.600138</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C16-Kind of Business (Primary Occupation)</td>\n",
       "      <td>108182</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.600138</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C17-Nature of Employment (Primary Occupation)</td>\n",
       "      <td>109450</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.607172</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Normal Working Hours per Day</td>\n",
       "      <td>111786</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.620131</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C19-Total Number of Hours Worked during the pa...</td>\n",
       "      <td>109844</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.609357</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Want More Hours of Work</td>\n",
       "      <td>109450</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.607172</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Look for Additional Work</td>\n",
       "      <td>109450</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.607172</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C22-First Time to Work</td>\n",
       "      <td>109450</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.607172</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C23-Class of Worker (Primary Occupation)</td>\n",
       "      <td>109450</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.607172</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C24-Basis of Payment (Primary Occupation)</td>\n",
       "      <td>139061</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.771438</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C25-Basic Pay per Day (Primary Occupation)</td>\n",
       "      <td>143463</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.795858</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Other Job Indicator</td>\n",
       "      <td>109450</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.607172</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C27-Number of Jobs during the past week</td>\n",
       "      <td>174516</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.968124</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Total Hours Worked for all Jobs</td>\n",
       "      <td>109805</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.609141</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C29-Reasons for Working More than 48 Hours dur...</td>\n",
       "      <td>164862</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.914569</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Looked for Work or Tried to Establish Business...</td>\n",
       "      <td>130760</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.725389</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>First Time to Look for Work</td>\n",
       "      <td>178550</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.990503</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C32-Job Search Method</td>\n",
       "      <td>178550</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.990503</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C33-Number of Weeks Spent in Looking for Work</td>\n",
       "      <td>178557</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.990542</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C34-Reason for not Looking for Work</td>\n",
       "      <td>132472</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.734886</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C35-When Last Looked for Work</td>\n",
       "      <td>178807</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.991928</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Available for Work</td>\n",
       "      <td>174448</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.967747</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C37-Willingness to take up work during the pas...</td>\n",
       "      <td>174448</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.967747</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Previous Job Indicator</td>\n",
       "      <td>130760</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.725389</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Previous Occupation</td>\n",
       "      <td>152022</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.843339</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>C41-Did work or had a job during the past quarter</td>\n",
       "      <td>81210</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.450511</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>Kind of Business (Past Quarter)</td>\n",
       "      <td>109764</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.608914</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2018</td>\n",
       "      <td>January</td>\n",
       "      <td>New Employment Criteria (jul 05, 2005)</td>\n",
       "      <td>59948</td>\n",
       "      <td>180262</td>\n",
       "      <td>0.332560</td>\n",
       "      <td>High</td>\n",
       "      <td>Strongly consider imputation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year    Month                                             Column  Missing  \\\n",
       "0   2018  January                                             Region        0   \n",
       "1   2018  January                                           Province      592   \n",
       "2   2018  January                                    Province Recode        0   \n",
       "3   2018  January                 Household Unique Sequential Number       17   \n",
       "4   2018  January                                    Urban-RuralFIES        0   \n",
       "5   2018  January  Final Weight Based on Projection (provincial p...        0   \n",
       "6   2018  January                                       Survey Month        0   \n",
       "7   2018  January                                        Survey Year        0   \n",
       "8   2018  January                                         Psu Number     1246   \n",
       "9   2018  January                                          Replicate      637   \n",
       "10  2018  January                                     Household Size     7695   \n",
       "11  2018  January                                   C101-Line Number     1824   \n",
       "12  2018  January                 C03-Relationship to Household Head        0   \n",
       "13  2018  January                                            C04-Sex        0   \n",
       "14  2018  January                        C05-Age as of Last Birthday        0   \n",
       "15  2018  January                                 C06-Marital Status    16515   \n",
       "16  2018  January                        C07-Highest Grade Completed    16515   \n",
       "17  2018  January                     C08-Currently Attending School   106696   \n",
       "18  2018  January        C09-Graduate of technical/vocational course    56585   \n",
       "19  2018  January                    C10-Overseas Filipino Indicator    56585   \n",
       "20  2018  January                                 C11-Work Indicator    19878   \n",
       "21  2018  January                                  C12-Job Indicator    91203   \n",
       "22  2018  January                             C14-Primary Occupation   108182   \n",
       "23  2018  January          C16-Kind of Business (Primary Occupation)   108182   \n",
       "24  2018  January      C17-Nature of Employment (Primary Occupation)   109450   \n",
       "25  2018  January                       Normal Working Hours per Day   111786   \n",
       "26  2018  January  C19-Total Number of Hours Worked during the pa...   109844   \n",
       "27  2018  January                            Want More Hours of Work   109450   \n",
       "28  2018  January                           Look for Additional Work   109450   \n",
       "29  2018  January                             C22-First Time to Work   109450   \n",
       "30  2018  January           C23-Class of Worker (Primary Occupation)   109450   \n",
       "31  2018  January          C24-Basis of Payment (Primary Occupation)   139061   \n",
       "32  2018  January         C25-Basic Pay per Day (Primary Occupation)   143463   \n",
       "33  2018  January                                Other Job Indicator   109450   \n",
       "34  2018  January            C27-Number of Jobs during the past week   174516   \n",
       "35  2018  January                    Total Hours Worked for all Jobs   109805   \n",
       "36  2018  January  C29-Reasons for Working More than 48 Hours dur...   164862   \n",
       "37  2018  January  Looked for Work or Tried to Establish Business...   130760   \n",
       "38  2018  January                        First Time to Look for Work   178550   \n",
       "39  2018  January                              C32-Job Search Method   178550   \n",
       "40  2018  January      C33-Number of Weeks Spent in Looking for Work   178557   \n",
       "41  2018  January                C34-Reason for not Looking for Work   132472   \n",
       "42  2018  January                      C35-When Last Looked for Work   178807   \n",
       "43  2018  January                                 Available for Work   174448   \n",
       "44  2018  January  C37-Willingness to take up work during the pas...   174448   \n",
       "45  2018  January                             Previous Job Indicator   130760   \n",
       "46  2018  January                                Previous Occupation   152022   \n",
       "47  2018  January  C41-Did work or had a job during the past quarter    81210   \n",
       "48  2018  January                    Kind of Business (Past Quarter)   109764   \n",
       "49  2018  January             New Employment Criteria (jul 05, 2005)    59948   \n",
       "\n",
       "     Total       FMI      Flag  \\\n",
       "0   180262  0.000000       Low   \n",
       "1   180262  0.003284       Low   \n",
       "2   180262  0.000000       Low   \n",
       "3   180262  0.000094       Low   \n",
       "4   180262  0.000000       Low   \n",
       "5   180262  0.000000       Low   \n",
       "6   180262  0.000000       Low   \n",
       "7   180262  0.000000       Low   \n",
       "8   180262  0.006912       Low   \n",
       "9   180262  0.003534       Low   \n",
       "10  180262  0.042688       Low   \n",
       "11  180262  0.010119       Low   \n",
       "12  180262  0.000000       Low   \n",
       "13  180262  0.000000       Low   \n",
       "14  180262  0.000000       Low   \n",
       "15  180262  0.091617  Moderate   \n",
       "16  180262  0.091617  Moderate   \n",
       "17  180262  0.591894  Critical   \n",
       "18  180262  0.313904      High   \n",
       "19  180262  0.313904      High   \n",
       "20  180262  0.110273  Moderate   \n",
       "21  180262  0.505947  Critical   \n",
       "22  180262  0.600138  Critical   \n",
       "23  180262  0.600138  Critical   \n",
       "24  180262  0.607172  Critical   \n",
       "25  180262  0.620131  Critical   \n",
       "26  180262  0.609357  Critical   \n",
       "27  180262  0.607172  Critical   \n",
       "28  180262  0.607172  Critical   \n",
       "29  180262  0.607172  Critical   \n",
       "30  180262  0.607172  Critical   \n",
       "31  180262  0.771438  Critical   \n",
       "32  180262  0.795858  Critical   \n",
       "33  180262  0.607172  Critical   \n",
       "34  180262  0.968124  Critical   \n",
       "35  180262  0.609141  Critical   \n",
       "36  180262  0.914569  Critical   \n",
       "37  180262  0.725389  Critical   \n",
       "38  180262  0.990503  Critical   \n",
       "39  180262  0.990503  Critical   \n",
       "40  180262  0.990542  Critical   \n",
       "41  180262  0.734886  Critical   \n",
       "42  180262  0.991928  Critical   \n",
       "43  180262  0.967747  Critical   \n",
       "44  180262  0.967747  Critical   \n",
       "45  180262  0.725389  Critical   \n",
       "46  180262  0.843339  Critical   \n",
       "47  180262  0.450511  Critical   \n",
       "48  180262  0.608914  Critical   \n",
       "49  180262  0.332560      High   \n",
       "\n",
       "                                      Recommendation  \n",
       "0                                               Keep  \n",
       "1                                               Keep  \n",
       "2                                               Keep  \n",
       "3                                               Keep  \n",
       "4                                               Keep  \n",
       "5                                               Keep  \n",
       "6                                               Keep  \n",
       "7                                               Keep  \n",
       "8                                               Keep  \n",
       "9                                               Keep  \n",
       "10                                              Keep  \n",
       "11                                              Keep  \n",
       "12                                              Keep  \n",
       "13                                              Keep  \n",
       "14                                              Keep  \n",
       "15                               Consider imputation  \n",
       "16                               Consider imputation  \n",
       "17  Candidate to drop (validate with business logic)  \n",
       "18                      Strongly consider imputation  \n",
       "19                      Strongly consider imputation  \n",
       "20                               Consider imputation  \n",
       "21  Candidate to drop (validate with business logic)  \n",
       "22  Candidate to drop (validate with business logic)  \n",
       "23  Candidate to drop (validate with business logic)  \n",
       "24  Candidate to drop (validate with business logic)  \n",
       "25  Candidate to drop (validate with business logic)  \n",
       "26  Candidate to drop (validate with business logic)  \n",
       "27  Candidate to drop (validate with business logic)  \n",
       "28  Candidate to drop (validate with business logic)  \n",
       "29  Candidate to drop (validate with business logic)  \n",
       "30  Candidate to drop (validate with business logic)  \n",
       "31  Candidate to drop (validate with business logic)  \n",
       "32  Candidate to drop (validate with business logic)  \n",
       "33  Candidate to drop (validate with business logic)  \n",
       "34  Candidate to drop (validate with business logic)  \n",
       "35  Candidate to drop (validate with business logic)  \n",
       "36  Candidate to drop (validate with business logic)  \n",
       "37  Candidate to drop (validate with business logic)  \n",
       "38  Candidate to drop (validate with business logic)  \n",
       "39  Candidate to drop (validate with business logic)  \n",
       "40  Candidate to drop (validate with business logic)  \n",
       "41  Candidate to drop (validate with business logic)  \n",
       "42  Candidate to drop (validate with business logic)  \n",
       "43  Candidate to drop (validate with business logic)  \n",
       "44  Candidate to drop (validate with business logic)  \n",
       "45  Candidate to drop (validate with business logic)  \n",
       "46  Candidate to drop (validate with business logic)  \n",
       "47  Candidate to drop (validate with business logic)  \n",
       "48  Candidate to drop (validate with business logic)  \n",
       "49                      Strongly consider imputation  "
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trial_path = os.path.join(base_path, \"Renamed Fully Decoded Surveys\", \"2018\", \"January_2018.csv\")\n",
    "test_report = fmi_scan_csv(trial_path, \"2018\", \"January\", include_numeric_sentinels=True)\n",
    "print(f\"Scanned {len(test_report)} variables\")\n",
    "test_report.head(50)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "4a1cba54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Year</th>\n",
       "      <th>Month</th>\n",
       "      <th>Column</th>\n",
       "      <th>Missing</th>\n",
       "      <th>Total</th>\n",
       "      <th>FMI</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Region</td>\n",
       "      <td>0</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Province</td>\n",
       "      <td>633</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.003520</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Province Recode</td>\n",
       "      <td>0</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>household_seq_number</td>\n",
       "      <td>14</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.000078</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Urban-RuralFIES</td>\n",
       "      <td>0</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Final Weight Based on Projection (provincial p...</td>\n",
       "      <td>0</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Survey Month</td>\n",
       "      <td>0</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Survey Year</td>\n",
       "      <td>0</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Psu Number</td>\n",
       "      <td>614</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.003415</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Replicate</td>\n",
       "      <td>2028</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.011278</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Household Size</td>\n",
       "      <td>8019</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.044596</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C101-Line Number</td>\n",
       "      <td>1950</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.010844</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C03-Relationship to Household Head</td>\n",
       "      <td>0</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C04-Sex</td>\n",
       "      <td>0</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C05-Age as of Last Birthday</td>\n",
       "      <td>4023</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.022373</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C06-Marital Status</td>\n",
       "      <td>15724</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.087445</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C07-Highest Grade Completed</td>\n",
       "      <td>15724</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.087445</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C08-Currently Attending School</td>\n",
       "      <td>106807</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.593983</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C09-Graduate of technical/vocational course</td>\n",
       "      <td>54835</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.304952</td>\n",
       "      <td>High</td>\n",
       "      <td>Strongly consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C10-Overseas Filipino Indicator</td>\n",
       "      <td>54835</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.304952</td>\n",
       "      <td>High</td>\n",
       "      <td>Strongly consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C11-Work Indicator</td>\n",
       "      <td>19251</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.107060</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C12-Job Indicator</td>\n",
       "      <td>89301</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.496627</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C14-Primary Occupation</td>\n",
       "      <td>109170</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.607124</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C16-Kind of Business (Primary Occupation)</td>\n",
       "      <td>109170</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.607124</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C17-Nature of Employment (Primary Occupation)</td>\n",
       "      <td>110385</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.613881</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Normal Working Hours per Day</td>\n",
       "      <td>112540</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.625865</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C19-Total Number of Hours Worked during the pa...</td>\n",
       "      <td>110691</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.615583</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Want More Hours of Work</td>\n",
       "      <td>110385</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.613881</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Look for Additional Work</td>\n",
       "      <td>110385</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.613881</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C22-First Time to Work</td>\n",
       "      <td>110385</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.613881</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C23-Class of Worker (Primary Occupation)</td>\n",
       "      <td>110385</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.613881</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C24-Basis of Payment (Primary Occupation)</td>\n",
       "      <td>138059</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.767784</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C25-Basic Pay per Day (Primary Occupation)</td>\n",
       "      <td>142120</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.790368</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Other Job Indicator</td>\n",
       "      <td>110385</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.613881</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C27-Number of Jobs during the past week</td>\n",
       "      <td>174377</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.969758</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Total Hours Worked for all Jobs</td>\n",
       "      <td>110670</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.615466</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C29-Reasons for Working More than 48 Hours dur...</td>\n",
       "      <td>142205</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.790841</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Looked for Work or Tried to Establish Business...</td>\n",
       "      <td>127792</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.710686</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>First Time to Look for Work</td>\n",
       "      <td>178201</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.991024</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C32-Job Search Method</td>\n",
       "      <td>178201</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.991024</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C33-Number of Weeks Spent in Looking for Work</td>\n",
       "      <td>178210</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.991074</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C34-Reason for not Looking for Work</td>\n",
       "      <td>129406</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.719662</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C35-When Last Looked for Work</td>\n",
       "      <td>177762</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.988583</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Available for Work</td>\n",
       "      <td>172982</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C37-Willingness to take up work during the pas...</td>\n",
       "      <td>172982</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.962000</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Previous Job Indicator</td>\n",
       "      <td>127792</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.710686</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Previous Occupation</td>\n",
       "      <td>153470</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.853488</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>C41-Did work or had a job during the past quarter</td>\n",
       "      <td>84040</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.467369</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>Kind of Business (Past Quarter)</td>\n",
       "      <td>116336</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.646976</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>2018</td>\n",
       "      <td>April</td>\n",
       "      <td>New Employment Criteria (jul 05, 2005)</td>\n",
       "      <td>58362</td>\n",
       "      <td>179815</td>\n",
       "      <td>0.324567</td>\n",
       "      <td>High</td>\n",
       "      <td>Strongly consider imputation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    Year  Month                                             Column  Missing  \\\n",
       "0   2018  April                                             Region        0   \n",
       "1   2018  April                                           Province      633   \n",
       "2   2018  April                                    Province Recode        0   \n",
       "3   2018  April                               household_seq_number       14   \n",
       "4   2018  April                                    Urban-RuralFIES        0   \n",
       "5   2018  April  Final Weight Based on Projection (provincial p...        0   \n",
       "6   2018  April                                       Survey Month        0   \n",
       "7   2018  April                                        Survey Year        0   \n",
       "8   2018  April                                         Psu Number      614   \n",
       "9   2018  April                                          Replicate     2028   \n",
       "10  2018  April                                     Household Size     8019   \n",
       "11  2018  April                                   C101-Line Number     1950   \n",
       "12  2018  April                 C03-Relationship to Household Head        0   \n",
       "13  2018  April                                            C04-Sex        0   \n",
       "14  2018  April                        C05-Age as of Last Birthday     4023   \n",
       "15  2018  April                                 C06-Marital Status    15724   \n",
       "16  2018  April                        C07-Highest Grade Completed    15724   \n",
       "17  2018  April                     C08-Currently Attending School   106807   \n",
       "18  2018  April        C09-Graduate of technical/vocational course    54835   \n",
       "19  2018  April                    C10-Overseas Filipino Indicator    54835   \n",
       "20  2018  April                                 C11-Work Indicator    19251   \n",
       "21  2018  April                                  C12-Job Indicator    89301   \n",
       "22  2018  April                             C14-Primary Occupation   109170   \n",
       "23  2018  April          C16-Kind of Business (Primary Occupation)   109170   \n",
       "24  2018  April      C17-Nature of Employment (Primary Occupation)   110385   \n",
       "25  2018  April                       Normal Working Hours per Day   112540   \n",
       "26  2018  April  C19-Total Number of Hours Worked during the pa...   110691   \n",
       "27  2018  April                            Want More Hours of Work   110385   \n",
       "28  2018  April                           Look for Additional Work   110385   \n",
       "29  2018  April                             C22-First Time to Work   110385   \n",
       "30  2018  April           C23-Class of Worker (Primary Occupation)   110385   \n",
       "31  2018  April          C24-Basis of Payment (Primary Occupation)   138059   \n",
       "32  2018  April         C25-Basic Pay per Day (Primary Occupation)   142120   \n",
       "33  2018  April                                Other Job Indicator   110385   \n",
       "34  2018  April            C27-Number of Jobs during the past week   174377   \n",
       "35  2018  April                    Total Hours Worked for all Jobs   110670   \n",
       "36  2018  April  C29-Reasons for Working More than 48 Hours dur...   142205   \n",
       "37  2018  April  Looked for Work or Tried to Establish Business...   127792   \n",
       "38  2018  April                        First Time to Look for Work   178201   \n",
       "39  2018  April                              C32-Job Search Method   178201   \n",
       "40  2018  April      C33-Number of Weeks Spent in Looking for Work   178210   \n",
       "41  2018  April                C34-Reason for not Looking for Work   129406   \n",
       "42  2018  April                      C35-When Last Looked for Work   177762   \n",
       "43  2018  April                                 Available for Work   172982   \n",
       "44  2018  April  C37-Willingness to take up work during the pas...   172982   \n",
       "45  2018  April                             Previous Job Indicator   127792   \n",
       "46  2018  April                                Previous Occupation   153470   \n",
       "47  2018  April  C41-Did work or had a job during the past quarter    84040   \n",
       "48  2018  April                    Kind of Business (Past Quarter)   116336   \n",
       "49  2018  April             New Employment Criteria (jul 05, 2005)    58362   \n",
       "\n",
       "     Total       FMI      Flag  \\\n",
       "0   179815  0.000000       Low   \n",
       "1   179815  0.003520       Low   \n",
       "2   179815  0.000000       Low   \n",
       "3   179815  0.000078       Low   \n",
       "4   179815  0.000000       Low   \n",
       "5   179815  0.000000       Low   \n",
       "6   179815  0.000000       Low   \n",
       "7   179815  0.000000       Low   \n",
       "8   179815  0.003415       Low   \n",
       "9   179815  0.011278       Low   \n",
       "10  179815  0.044596       Low   \n",
       "11  179815  0.010844       Low   \n",
       "12  179815  0.000000       Low   \n",
       "13  179815  0.000000       Low   \n",
       "14  179815  0.022373       Low   \n",
       "15  179815  0.087445  Moderate   \n",
       "16  179815  0.087445  Moderate   \n",
       "17  179815  0.593983  Critical   \n",
       "18  179815  0.304952      High   \n",
       "19  179815  0.304952      High   \n",
       "20  179815  0.107060  Moderate   \n",
       "21  179815  0.496627  Critical   \n",
       "22  179815  0.607124  Critical   \n",
       "23  179815  0.607124  Critical   \n",
       "24  179815  0.613881  Critical   \n",
       "25  179815  0.625865  Critical   \n",
       "26  179815  0.615583  Critical   \n",
       "27  179815  0.613881  Critical   \n",
       "28  179815  0.613881  Critical   \n",
       "29  179815  0.613881  Critical   \n",
       "30  179815  0.613881  Critical   \n",
       "31  179815  0.767784  Critical   \n",
       "32  179815  0.790368  Critical   \n",
       "33  179815  0.613881  Critical   \n",
       "34  179815  0.969758  Critical   \n",
       "35  179815  0.615466  Critical   \n",
       "36  179815  0.790841  Critical   \n",
       "37  179815  0.710686  Critical   \n",
       "38  179815  0.991024  Critical   \n",
       "39  179815  0.991024  Critical   \n",
       "40  179815  0.991074  Critical   \n",
       "41  179815  0.719662  Critical   \n",
       "42  179815  0.988583  Critical   \n",
       "43  179815  0.962000  Critical   \n",
       "44  179815  0.962000  Critical   \n",
       "45  179815  0.710686  Critical   \n",
       "46  179815  0.853488  Critical   \n",
       "47  179815  0.467369  Critical   \n",
       "48  179815  0.646976  Critical   \n",
       "49  179815  0.324567      High   \n",
       "\n",
       "                                      Recommendation  \n",
       "0                                               Keep  \n",
       "1                                               Keep  \n",
       "2                                               Keep  \n",
       "3                                               Keep  \n",
       "4                                               Keep  \n",
       "5                                               Keep  \n",
       "6                                               Keep  \n",
       "7                                               Keep  \n",
       "8                                               Keep  \n",
       "9                                               Keep  \n",
       "10                                              Keep  \n",
       "11                                              Keep  \n",
       "12                                              Keep  \n",
       "13                                              Keep  \n",
       "14                                              Keep  \n",
       "15                               Consider imputation  \n",
       "16                               Consider imputation  \n",
       "17  Candidate to drop (validate with business logic)  \n",
       "18                      Strongly consider imputation  \n",
       "19                      Strongly consider imputation  \n",
       "20                               Consider imputation  \n",
       "21  Candidate to drop (validate with business logic)  \n",
       "22  Candidate to drop (validate with business logic)  \n",
       "23  Candidate to drop (validate with business logic)  \n",
       "24  Candidate to drop (validate with business logic)  \n",
       "25  Candidate to drop (validate with business logic)  \n",
       "26  Candidate to drop (validate with business logic)  \n",
       "27  Candidate to drop (validate with business logic)  \n",
       "28  Candidate to drop (validate with business logic)  \n",
       "29  Candidate to drop (validate with business logic)  \n",
       "30  Candidate to drop (validate with business logic)  \n",
       "31  Candidate to drop (validate with business logic)  \n",
       "32  Candidate to drop (validate with business logic)  \n",
       "33  Candidate to drop (validate with business logic)  \n",
       "34  Candidate to drop (validate with business logic)  \n",
       "35  Candidate to drop (validate with business logic)  \n",
       "36  Candidate to drop (validate with business logic)  \n",
       "37  Candidate to drop (validate with business logic)  \n",
       "38  Candidate to drop (validate with business logic)  \n",
       "39  Candidate to drop (validate with business logic)  \n",
       "40  Candidate to drop (validate with business logic)  \n",
       "41  Candidate to drop (validate with business logic)  \n",
       "42  Candidate to drop (validate with business logic)  \n",
       "43  Candidate to drop (validate with business logic)  \n",
       "44  Candidate to drop (validate with business logic)  \n",
       "45  Candidate to drop (validate with business logic)  \n",
       "46  Candidate to drop (validate with business logic)  \n",
       "47  Candidate to drop (validate with business logic)  \n",
       "48  Candidate to drop (validate with business logic)  \n",
       "49                      Strongly consider imputation  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Quick check if it works on other datasets\n",
    "apr_path = os.path.join(base_path, \"Renamed Fully Decoded Surveys\", \"2018\", \"APRIL_2018.CSV\")\n",
    "apr_2018_report = fmi_scan_csv(apr_path, \"2018\", \"April\", base_path)\n",
    "apr_2018_report.head(50)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "43201439",
   "metadata": {},
   "source": [
    "### Batch/Automation Runner - Redirect in Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "7bf7bbc9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "STARTING BATCH FMI REPORTS\n",
      "Source: /Users/neilkeannedelavega/Library/CloudStorage/GoogleDrive-shaniakeith23@gmail.com/My Drive/Labor Force Survey/Renamed Fully Decoded Surveys\n",
      "Dest:   /Users/neilkeannedelavega/Library/CloudStorage/GoogleDrive-shaniakeith23@gmail.com/My Drive/Labor Force Survey/FMI Reports\n",
      "===============================================\n",
      "\n",
      "Processing: December 2022...\n",
      "   [OK] Scanned 42 variables.\n",
      "   [SAVED] FMI_December_2022.csv\n",
      "----------------------------------------\n",
      "Processing: September 2022...\n",
      "   [OK] Scanned 42 variables.\n",
      "   [SAVED] FMI_September_2022.csv\n",
      "----------------------------------------\n",
      "Processing: November 2022...\n",
      "   [OK] Scanned 42 variables.\n",
      "   [SAVED] FMI_November_2022.csv\n",
      "----------------------------------------\n",
      "Processing: July 2022...\n",
      "   [OK] Scanned 52 variables.\n",
      "   [SAVED] FMI_July_2022.csv\n",
      "----------------------------------------\n",
      "Processing: August 2022...\n",
      "   [OK] Scanned 42 variables.\n",
      "   [SAVED] FMI_August_2022.csv\n",
      "----------------------------------------\n",
      "Processing: October 2022...\n",
      "   [OK] Scanned 52 variables.\n",
      "   [SAVED] FMI_October_2022.csv\n",
      "----------------------------------------\n",
      "Processing: February 2024...\n",
      "   [OK] Scanned 41 variables.\n",
      "   [SAVED] FMI_February_2024.csv\n",
      "----------------------------------------\n",
      "Processing: July 2024...\n",
      "   [OK] Scanned 51 variables.\n",
      "   [SAVED] FMI_July_2024.csv\n",
      "----------------------------------------\n",
      "Processing: June 2024...\n",
      "   [OK] Scanned 40 variables.\n",
      "   [SAVED] FMI_June_2024.csv\n",
      "----------------------------------------\n",
      "Processing: April 2024...\n",
      "   [OK] Scanned 51 variables.\n",
      "   [SAVED] FMI_April_2024.csv\n",
      "----------------------------------------\n",
      "Processing: January 2024...\n",
      "   [OK] Scanned 52 variables.\n",
      "   [SAVED] FMI_January_2024.csv\n",
      "----------------------------------------\n",
      "Processing: March 2024...\n",
      "   [OK] Scanned 41 variables.\n",
      "   [SAVED] FMI_March_2024.csv\n",
      "----------------------------------------\n",
      "Processing: May 2024...\n",
      "   [OK] Scanned 40 variables.\n",
      "   [SAVED] FMI_May_2024.csv\n",
      "----------------------------------------\n",
      "Processing: August 2024...\n",
      "   [OK] Scanned 40 variables.\n",
      "   [SAVED] FMI_August_2024.csv\n",
      "----------------------------------------\n",
      "Processing: December 2023...\n",
      "   [OK] Scanned 41 variables.\n",
      "   [SAVED] FMI_December_2023.csv\n",
      "----------------------------------------\n",
      "Processing: February 2023...\n",
      "   [OK] Scanned 42 variables.\n",
      "   [SAVED] FMI_February_2023.csv\n",
      "----------------------------------------\n",
      "Processing: September 2023...\n",
      "   [OK] Scanned 41 variables.\n",
      "   [SAVED] FMI_September_2023.csv\n",
      "----------------------------------------\n",
      "Processing: November 2023...\n",
      "   [OK] Scanned 41 variables.\n",
      "   [SAVED] FMI_November_2023.csv\n",
      "----------------------------------------\n",
      "Processing: June 2023...\n",
      "   [OK] Scanned 42 variables.\n",
      "   [SAVED] FMI_June_2023.csv\n",
      "----------------------------------------\n",
      "Processing: July 2023...\n",
      "   [OK] Scanned 52 variables.\n",
      "   [SAVED] FMI_July_2023.csv\n",
      "----------------------------------------\n",
      "Processing: May 2023...\n",
      "   [OK] Scanned 42 variables.\n",
      "   [SAVED] FMI_May_2023.csv\n",
      "----------------------------------------\n",
      "Processing: August 2023...\n",
      "   [OK] Scanned 41 variables.\n",
      "   [SAVED] FMI_August_2023.csv\n",
      "----------------------------------------\n",
      "Processing: January 2023...\n",
      "   [OK] Scanned 52 variables.\n",
      "   [SAVED] FMI_January_2023.csv\n",
      "----------------------------------------\n",
      "Processing: April 2023...\n",
      "   [OK] Scanned 52 variables.\n",
      "   [SAVED] FMI_April_2023.csv\n",
      "----------------------------------------\n",
      "Processing: October 2023...\n",
      "   [OK] Scanned 52 variables.\n",
      "   [SAVED] FMI_October_2023.csv\n",
      "----------------------------------------\n",
      "Processing: March 2023...\n",
      "   [OK] Scanned 42 variables.\n",
      "   [SAVED] FMI_March_2023.csv\n",
      "----------------------------------------\n",
      "Processing: July 2019...\n",
      "   [OK] Scanned 49 variables.\n",
      "   [SAVED] FMI_July_2019.csv\n",
      "----------------------------------------\n",
      "Processing: January 2019...\n",
      "   [OK] Scanned 49 variables.\n",
      "   [SAVED] FMI_January_2019.csv\n",
      "----------------------------------------\n",
      "Processing: April 2019...\n",
      "   [OK] Scanned 49 variables.\n",
      "   [SAVED] FMI_April_2019.csv\n",
      "----------------------------------------\n",
      "Processing: October 2019...\n",
      "   [OK] Scanned 49 variables.\n",
      "   [SAVED] FMI_October_2019.csv\n",
      "----------------------------------------\n",
      "Processing: July 2018...\n",
      "   [OK] Scanned 51 variables.\n",
      "   [SAVED] FMI_July_2018.csv\n",
      "----------------------------------------\n",
      "Processing: October 2018...\n",
      "   [OK] Scanned 51 variables.\n",
      "   [SAVED] FMI_October_2018.csv\n",
      "----------------------------------------\n",
      "Processing: April 2018...\n",
      "   [OK] Scanned 50 variables.\n",
      "   [SAVED] FMI_April_2018.csv\n",
      "----------------------------------------\n",
      "Processing: January 2018...\n",
      "   [OK] Scanned 50 variables.\n",
      "   [SAVED] FMI_January_2018.csv\n",
      "----------------------------------------\n",
      "\n",
      "COMPLETED. Success: 34 | Errors: 0\n"
     ]
    }
   ],
   "source": [
    "decoded_path = os.path.join(base_path, \"Renamed Fully Decoded Surveys\")\n",
    "output_root = os.path.join(base_path, \"FMI Reports\")\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"STARTING BATCH FMI REPORTS\")\n",
    "print(f\"Source: {decoded_path}\")\n",
    "print(f\"Dest:   {output_root}\")\n",
    "print(\"===============================================\\n\")\n",
    "\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "\n",
    "for year in os.listdir(decoded_path):\n",
    "    year_folder = os.path.join(decoded_path, year)\n",
    "    if not os.path.isdir(year_folder):\n",
    "        continue\n",
    "\n",
    "    output_year_folder = os.path.join(output_root, year)\n",
    "    os.makedirs(output_year_folder, exist_ok=True)\n",
    "\n",
    "    for file in os.listdir(year_folder):\n",
    "        if not file.endswith(\".CSV\"):\n",
    "            continue\n",
    "\n",
    "        month = file.split(\"_\")[0].capitalize()\n",
    "        file_path = os.path.join(year_folder, file)\n",
    "\n",
    "        print(f\"Processing: {month} {year}...\")\n",
    "\n",
    "        try:\n",
    "            report = fmi_scan_csv(file_path, year, month)\n",
    "            out_file = os.path.join(output_year_folder, f\"FMI_{month}_{year}.csv\")\n",
    "            report.to_csv(out_file, index=False)\n",
    "\n",
    "            print(f\"   [OK] Scanned {len(report)} variables.\")\n",
    "            print(f\"   [SAVED] FMI_{month}_{year}.csv\")\n",
    "            print(\"----------------------------------------\")\n",
    "            success_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   [ERROR] {file} â†’ {e}\")\n",
    "            print(\"----------------------------------------\")\n",
    "            error_count += 1\n",
    "\n",
    "print(f\"\\nCOMPLETED. Success: {success_count} | Errors: {error_count}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c380eccd",
   "metadata": {},
   "source": [
    "### Weighted Average of FMI across datasets, per variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "c500b6ca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Column</th>\n",
       "      <th>TotalMissing</th>\n",
       "      <th>TotalRows</th>\n",
       "      <th>AvgFMI</th>\n",
       "      <th>MonthsObserved</th>\n",
       "      <th>OverallFMI</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Recommendation</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Available for Work</td>\n",
       "      <td>4712321</td>\n",
       "      <td>4881364</td>\n",
       "      <td>0.967968</td>\n",
       "      <td>34</td>\n",
       "      <td>0.965370</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C03-Relationship to Household Head</td>\n",
       "      <td>0</td>\n",
       "      <td>4881364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C04-Sex</td>\n",
       "      <td>0</td>\n",
       "      <td>4881364</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>34</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C05-Age as of Last Birthday</td>\n",
       "      <td>82751</td>\n",
       "      <td>4881364</td>\n",
       "      <td>0.019262</td>\n",
       "      <td>34</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C05B - Ethnicity</td>\n",
       "      <td>0</td>\n",
       "      <td>707981</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>C06-Marital Status</td>\n",
       "      <td>358820</td>\n",
       "      <td>4881364</td>\n",
       "      <td>0.069921</td>\n",
       "      <td>34</td>\n",
       "      <td>0.073508</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>C07-Highest Grade Completed</td>\n",
       "      <td>361914</td>\n",
       "      <td>4881364</td>\n",
       "      <td>0.071961</td>\n",
       "      <td>34</td>\n",
       "      <td>0.074142</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>C08-Currently Attending School</td>\n",
       "      <td>2281910</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.567432</td>\n",
       "      <td>17</td>\n",
       "      <td>0.554300</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>C08-Overseas Filipino Indicator</td>\n",
       "      <td>203920</td>\n",
       "      <td>764619</td>\n",
       "      <td>0.266685</td>\n",
       "      <td>17</td>\n",
       "      <td>0.266695</td>\n",
       "      <td>High</td>\n",
       "      <td>Strongly consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>C09-Graduate of technical/vocational course</td>\n",
       "      <td>1162929</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.285236</td>\n",
       "      <td>17</td>\n",
       "      <td>0.282487</td>\n",
       "      <td>High</td>\n",
       "      <td>Strongly consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>C09-Work Indicator</td>\n",
       "      <td>64311</td>\n",
       "      <td>764619</td>\n",
       "      <td>0.084135</td>\n",
       "      <td>17</td>\n",
       "      <td>0.084109</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>C09A-Work Arrangement</td>\n",
       "      <td>268713</td>\n",
       "      <td>488800</td>\n",
       "      <td>0.549719</td>\n",
       "      <td>11</td>\n",
       "      <td>0.549740</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>C09A-Work Indicator</td>\n",
       "      <td>150866</td>\n",
       "      <td>275819</td>\n",
       "      <td>0.546968</td>\n",
       "      <td>6</td>\n",
       "      <td>0.546975</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>C09a - Currently Attending Non-formal Training...</td>\n",
       "      <td>1051509</td>\n",
       "      <td>3756668</td>\n",
       "      <td>0.282010</td>\n",
       "      <td>15</td>\n",
       "      <td>0.279905</td>\n",
       "      <td>High</td>\n",
       "      <td>Strongly consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>C10-Job Indicator</td>\n",
       "      <td>409351</td>\n",
       "      <td>764619</td>\n",
       "      <td>0.535387</td>\n",
       "      <td>17</td>\n",
       "      <td>0.535366</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>C10-Overseas Filipino Indicator</td>\n",
       "      <td>1162929</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.285236</td>\n",
       "      <td>17</td>\n",
       "      <td>0.282487</td>\n",
       "      <td>High</td>\n",
       "      <td>Strongly consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>C101-Line Number</td>\n",
       "      <td>42235</td>\n",
       "      <td>4881364</td>\n",
       "      <td>0.008199</td>\n",
       "      <td>34</td>\n",
       "      <td>0.008652</td>\n",
       "      <td>Low</td>\n",
       "      <td>Keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>C11-Work Indicator</td>\n",
       "      <td>375100</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.093127</td>\n",
       "      <td>17</td>\n",
       "      <td>0.091116</td>\n",
       "      <td>Moderate</td>\n",
       "      <td>Consider imputation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>C11A - Working Arrangement</td>\n",
       "      <td>1551120</td>\n",
       "      <td>2687486</td>\n",
       "      <td>0.567196</td>\n",
       "      <td>9</td>\n",
       "      <td>0.577164</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>C12-Job Indicator</td>\n",
       "      <td>2071068</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.506553</td>\n",
       "      <td>17</td>\n",
       "      <td>0.503084</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>C13-Major Occupation Group</td>\n",
       "      <td>416222</td>\n",
       "      <td>764619</td>\n",
       "      <td>0.544376</td>\n",
       "      <td>17</td>\n",
       "      <td>0.544352</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>C14-Primary Occupation</td>\n",
       "      <td>2409128</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.583287</td>\n",
       "      <td>17</td>\n",
       "      <td>0.585202</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>C15-Major Industry Group</td>\n",
       "      <td>416222</td>\n",
       "      <td>764619</td>\n",
       "      <td>0.544376</td>\n",
       "      <td>17</td>\n",
       "      <td>0.544352</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>C16-Kind of Business (Primary Occupation)</td>\n",
       "      <td>2409128</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.583287</td>\n",
       "      <td>17</td>\n",
       "      <td>0.585202</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>C16-Nature of Employment (Primary Occupation)</td>\n",
       "      <td>419786</td>\n",
       "      <td>764619</td>\n",
       "      <td>0.549015</td>\n",
       "      <td>17</td>\n",
       "      <td>0.549013</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>C17-Nature of Employment (Primary Occupation)</td>\n",
       "      <td>2423329</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.587537</td>\n",
       "      <td>17</td>\n",
       "      <td>0.588652</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>C18-Total Number of Hours Worked during the pa...</td>\n",
       "      <td>419786</td>\n",
       "      <td>764619</td>\n",
       "      <td>0.549015</td>\n",
       "      <td>17</td>\n",
       "      <td>0.549013</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>C19-Total Number of Hours Worked during the pa...</td>\n",
       "      <td>2422541</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.587284</td>\n",
       "      <td>17</td>\n",
       "      <td>0.588460</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>C19B - Time of work during the past week</td>\n",
       "      <td>99990</td>\n",
       "      <td>179173</td>\n",
       "      <td>0.558064</td>\n",
       "      <td>1</td>\n",
       "      <td>0.558064</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>C20B - First time to do any work</td>\n",
       "      <td>419786</td>\n",
       "      <td>764619</td>\n",
       "      <td>0.549015</td>\n",
       "      <td>17</td>\n",
       "      <td>0.549013</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>C21-Class of Worker (Primary Occupation)</td>\n",
       "      <td>419786</td>\n",
       "      <td>764619</td>\n",
       "      <td>0.549015</td>\n",
       "      <td>17</td>\n",
       "      <td>0.549013</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>31</th>\n",
       "      <td>C22-First Time to Work</td>\n",
       "      <td>2423330</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.587537</td>\n",
       "      <td>17</td>\n",
       "      <td>0.588652</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>32</th>\n",
       "      <td>C23-Class of Worker (Primary Occupation)</td>\n",
       "      <td>2420727</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.586689</td>\n",
       "      <td>17</td>\n",
       "      <td>0.588020</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>C24-Basis of Payment (Primary Occupation)</td>\n",
       "      <td>3090303</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.753847</td>\n",
       "      <td>17</td>\n",
       "      <td>0.750667</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>34</th>\n",
       "      <td>C24-Reasons for Working More than 48 Hours dur...</td>\n",
       "      <td>586735</td>\n",
       "      <td>764619</td>\n",
       "      <td>0.767586</td>\n",
       "      <td>17</td>\n",
       "      <td>0.767356</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35</th>\n",
       "      <td>C25-Basic Pay per Day (Primary Occupation)</td>\n",
       "      <td>3229562</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.787998</td>\n",
       "      <td>17</td>\n",
       "      <td>0.784494</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>36</th>\n",
       "      <td>C26-Reason for not Looking for Work</td>\n",
       "      <td>570516</td>\n",
       "      <td>764619</td>\n",
       "      <td>0.746114</td>\n",
       "      <td>17</td>\n",
       "      <td>0.746144</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>37</th>\n",
       "      <td>C27-Number of Jobs during the past week</td>\n",
       "      <td>3969850</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.964375</td>\n",
       "      <td>17</td>\n",
       "      <td>0.964318</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>38</th>\n",
       "      <td>C29 - Last worked (Month)</td>\n",
       "      <td>664028</td>\n",
       "      <td>764619</td>\n",
       "      <td>0.868570</td>\n",
       "      <td>17</td>\n",
       "      <td>0.868443</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>39</th>\n",
       "      <td>C29 - Last worked (Year)</td>\n",
       "      <td>664028</td>\n",
       "      <td>764619</td>\n",
       "      <td>0.868570</td>\n",
       "      <td>17</td>\n",
       "      <td>0.868443</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>C29-Reasons for Working More than 48 Hours dur...</td>\n",
       "      <td>3261931</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.789809</td>\n",
       "      <td>17</td>\n",
       "      <td>0.792357</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>41</th>\n",
       "      <td>C32-Job Search Method</td>\n",
       "      <td>4074439</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.990070</td>\n",
       "      <td>17</td>\n",
       "      <td>0.989723</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>42</th>\n",
       "      <td>C33-Kind of Business (previous occupation)</td>\n",
       "      <td>37916</td>\n",
       "      <td>43375</td>\n",
       "      <td>0.874144</td>\n",
       "      <td>1</td>\n",
       "      <td>0.874144</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>43</th>\n",
       "      <td>C33-Number of Weeks Spent in Looking for Work</td>\n",
       "      <td>4074488</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.990086</td>\n",
       "      <td>17</td>\n",
       "      <td>0.989735</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>44</th>\n",
       "      <td>C34-Reason for not Looking for Work</td>\n",
       "      <td>2963387</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.724277</td>\n",
       "      <td>17</td>\n",
       "      <td>0.719837</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>45</th>\n",
       "      <td>C35-When Last Looked for Work</td>\n",
       "      <td>4073352</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.990214</td>\n",
       "      <td>17</td>\n",
       "      <td>0.989459</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>46</th>\n",
       "      <td>C37-Willingness to take up work during the pas...</td>\n",
       "      <td>3970097</td>\n",
       "      <td>4116745</td>\n",
       "      <td>0.965181</td>\n",
       "      <td>17</td>\n",
       "      <td>0.964378</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>47</th>\n",
       "      <td>C39 - Last worked (Month)</td>\n",
       "      <td>2346568</td>\n",
       "      <td>2687486</td>\n",
       "      <td>0.868394</td>\n",
       "      <td>9</td>\n",
       "      <td>0.873146</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>48</th>\n",
       "      <td>C39 - Last worked (Year)</td>\n",
       "      <td>2346568</td>\n",
       "      <td>2687486</td>\n",
       "      <td>0.868394</td>\n",
       "      <td>9</td>\n",
       "      <td>0.873146</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>49</th>\n",
       "      <td>C41- Previous Occupation</td>\n",
       "      <td>2346568</td>\n",
       "      <td>2687486</td>\n",
       "      <td>0.868394</td>\n",
       "      <td>9</td>\n",
       "      <td>0.873146</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Candidate to drop (validate with business logic)</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Column  TotalMissing  \\\n",
       "0                                  Available for Work       4712321   \n",
       "1                  C03-Relationship to Household Head             0   \n",
       "2                                             C04-Sex             0   \n",
       "3                         C05-Age as of Last Birthday         82751   \n",
       "4                                    C05B - Ethnicity             0   \n",
       "5                                  C06-Marital Status        358820   \n",
       "6                         C07-Highest Grade Completed        361914   \n",
       "7                      C08-Currently Attending School       2281910   \n",
       "8                     C08-Overseas Filipino Indicator        203920   \n",
       "9         C09-Graduate of technical/vocational course       1162929   \n",
       "10                                 C09-Work Indicator         64311   \n",
       "11                              C09A-Work Arrangement        268713   \n",
       "12                                C09A-Work Indicator        150866   \n",
       "13  C09a - Currently Attending Non-formal Training...       1051509   \n",
       "14                                  C10-Job Indicator        409351   \n",
       "15                    C10-Overseas Filipino Indicator       1162929   \n",
       "16                                   C101-Line Number         42235   \n",
       "17                                 C11-Work Indicator        375100   \n",
       "18                         C11A - Working Arrangement       1551120   \n",
       "19                                  C12-Job Indicator       2071068   \n",
       "20                         C13-Major Occupation Group        416222   \n",
       "21                             C14-Primary Occupation       2409128   \n",
       "22                           C15-Major Industry Group        416222   \n",
       "23          C16-Kind of Business (Primary Occupation)       2409128   \n",
       "24      C16-Nature of Employment (Primary Occupation)        419786   \n",
       "25      C17-Nature of Employment (Primary Occupation)       2423329   \n",
       "26  C18-Total Number of Hours Worked during the pa...        419786   \n",
       "27  C19-Total Number of Hours Worked during the pa...       2422541   \n",
       "28           C19B - Time of work during the past week         99990   \n",
       "29                   C20B - First time to do any work        419786   \n",
       "30           C21-Class of Worker (Primary Occupation)        419786   \n",
       "31                             C22-First Time to Work       2423330   \n",
       "32           C23-Class of Worker (Primary Occupation)       2420727   \n",
       "33          C24-Basis of Payment (Primary Occupation)       3090303   \n",
       "34  C24-Reasons for Working More than 48 Hours dur...        586735   \n",
       "35         C25-Basic Pay per Day (Primary Occupation)       3229562   \n",
       "36                C26-Reason for not Looking for Work        570516   \n",
       "37            C27-Number of Jobs during the past week       3969850   \n",
       "38                          C29 - Last worked (Month)        664028   \n",
       "39                           C29 - Last worked (Year)        664028   \n",
       "40  C29-Reasons for Working More than 48 Hours dur...       3261931   \n",
       "41                              C32-Job Search Method       4074439   \n",
       "42         C33-Kind of Business (previous occupation)         37916   \n",
       "43      C33-Number of Weeks Spent in Looking for Work       4074488   \n",
       "44                C34-Reason for not Looking for Work       2963387   \n",
       "45                      C35-When Last Looked for Work       4073352   \n",
       "46  C37-Willingness to take up work during the pas...       3970097   \n",
       "47                          C39 - Last worked (Month)       2346568   \n",
       "48                           C39 - Last worked (Year)       2346568   \n",
       "49                           C41- Previous Occupation       2346568   \n",
       "\n",
       "    TotalRows    AvgFMI  MonthsObserved  OverallFMI      Flag  \\\n",
       "0     4881364  0.967968              34    0.965370  Critical   \n",
       "1     4881364  0.000000              34    0.000000       Low   \n",
       "2     4881364  0.000000              34    0.000000       Low   \n",
       "3     4881364  0.019262              34    0.016952       Low   \n",
       "4      707981  0.000000               1    0.000000       Low   \n",
       "5     4881364  0.069921              34    0.073508  Moderate   \n",
       "6     4881364  0.071961              34    0.074142  Moderate   \n",
       "7     4116745  0.567432              17    0.554300  Critical   \n",
       "8      764619  0.266685              17    0.266695      High   \n",
       "9     4116745  0.285236              17    0.282487      High   \n",
       "10     764619  0.084135              17    0.084109  Moderate   \n",
       "11     488800  0.549719              11    0.549740  Critical   \n",
       "12     275819  0.546968               6    0.546975  Critical   \n",
       "13    3756668  0.282010              15    0.279905      High   \n",
       "14     764619  0.535387              17    0.535366  Critical   \n",
       "15    4116745  0.285236              17    0.282487      High   \n",
       "16    4881364  0.008199              34    0.008652       Low   \n",
       "17    4116745  0.093127              17    0.091116  Moderate   \n",
       "18    2687486  0.567196               9    0.577164  Critical   \n",
       "19    4116745  0.506553              17    0.503084  Critical   \n",
       "20     764619  0.544376              17    0.544352  Critical   \n",
       "21    4116745  0.583287              17    0.585202  Critical   \n",
       "22     764619  0.544376              17    0.544352  Critical   \n",
       "23    4116745  0.583287              17    0.585202  Critical   \n",
       "24     764619  0.549015              17    0.549013  Critical   \n",
       "25    4116745  0.587537              17    0.588652  Critical   \n",
       "26     764619  0.549015              17    0.549013  Critical   \n",
       "27    4116745  0.587284              17    0.588460  Critical   \n",
       "28     179173  0.558064               1    0.558064  Critical   \n",
       "29     764619  0.549015              17    0.549013  Critical   \n",
       "30     764619  0.549015              17    0.549013  Critical   \n",
       "31    4116745  0.587537              17    0.588652  Critical   \n",
       "32    4116745  0.586689              17    0.588020  Critical   \n",
       "33    4116745  0.753847              17    0.750667  Critical   \n",
       "34     764619  0.767586              17    0.767356  Critical   \n",
       "35    4116745  0.787998              17    0.784494  Critical   \n",
       "36     764619  0.746114              17    0.746144  Critical   \n",
       "37    4116745  0.964375              17    0.964318  Critical   \n",
       "38     764619  0.868570              17    0.868443  Critical   \n",
       "39     764619  0.868570              17    0.868443  Critical   \n",
       "40    4116745  0.789809              17    0.792357  Critical   \n",
       "41    4116745  0.990070              17    0.989723  Critical   \n",
       "42      43375  0.874144               1    0.874144  Critical   \n",
       "43    4116745  0.990086              17    0.989735  Critical   \n",
       "44    4116745  0.724277              17    0.719837  Critical   \n",
       "45    4116745  0.990214              17    0.989459  Critical   \n",
       "46    4116745  0.965181              17    0.964378  Critical   \n",
       "47    2687486  0.868394               9    0.873146  Critical   \n",
       "48    2687486  0.868394               9    0.873146  Critical   \n",
       "49    2687486  0.868394               9    0.873146  Critical   \n",
       "\n",
       "                                      Recommendation  \n",
       "0   Candidate to drop (validate with business logic)  \n",
       "1                                               Keep  \n",
       "2                                               Keep  \n",
       "3                                               Keep  \n",
       "4                                               Keep  \n",
       "5                                Consider imputation  \n",
       "6                                Consider imputation  \n",
       "7   Candidate to drop (validate with business logic)  \n",
       "8                       Strongly consider imputation  \n",
       "9                       Strongly consider imputation  \n",
       "10                               Consider imputation  \n",
       "11  Candidate to drop (validate with business logic)  \n",
       "12  Candidate to drop (validate with business logic)  \n",
       "13                      Strongly consider imputation  \n",
       "14  Candidate to drop (validate with business logic)  \n",
       "15                      Strongly consider imputation  \n",
       "16                                              Keep  \n",
       "17                               Consider imputation  \n",
       "18  Candidate to drop (validate with business logic)  \n",
       "19  Candidate to drop (validate with business logic)  \n",
       "20  Candidate to drop (validate with business logic)  \n",
       "21  Candidate to drop (validate with business logic)  \n",
       "22  Candidate to drop (validate with business logic)  \n",
       "23  Candidate to drop (validate with business logic)  \n",
       "24  Candidate to drop (validate with business logic)  \n",
       "25  Candidate to drop (validate with business logic)  \n",
       "26  Candidate to drop (validate with business logic)  \n",
       "27  Candidate to drop (validate with business logic)  \n",
       "28  Candidate to drop (validate with business logic)  \n",
       "29  Candidate to drop (validate with business logic)  \n",
       "30  Candidate to drop (validate with business logic)  \n",
       "31  Candidate to drop (validate with business logic)  \n",
       "32  Candidate to drop (validate with business logic)  \n",
       "33  Candidate to drop (validate with business logic)  \n",
       "34  Candidate to drop (validate with business logic)  \n",
       "35  Candidate to drop (validate with business logic)  \n",
       "36  Candidate to drop (validate with business logic)  \n",
       "37  Candidate to drop (validate with business logic)  \n",
       "38  Candidate to drop (validate with business logic)  \n",
       "39  Candidate to drop (validate with business logic)  \n",
       "40  Candidate to drop (validate with business logic)  \n",
       "41  Candidate to drop (validate with business logic)  \n",
       "42  Candidate to drop (validate with business logic)  \n",
       "43  Candidate to drop (validate with business logic)  \n",
       "44  Candidate to drop (validate with business logic)  \n",
       "45  Candidate to drop (validate with business logic)  \n",
       "46  Candidate to drop (validate with business logic)  \n",
       "47  Candidate to drop (validate with business logic)  \n",
       "48  Candidate to drop (validate with business logic)  \n",
       "49  Candidate to drop (validate with business logic)  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "reports_root = os.path.join(base_path, \"FMI Reports\")\n",
    "\n",
    "# --- Load all monthly FMI reports ---\n",
    "all_reports = []\n",
    "for year in os.listdir(reports_root):\n",
    "    year_folder = os.path.join(reports_root, year)\n",
    "    if not os.path.isdir(year_folder):\n",
    "        continue\n",
    "    for file in os.listdir(year_folder):\n",
    "        if not file.endswith(\".csv\"):\n",
    "            continue\n",
    "        file_path = os.path.join(year_folder, file)\n",
    "        df = pd.read_csv(file_path)\n",
    "        all_reports.append(df)\n",
    "\n",
    "# Combine all months into one DataFrame\n",
    "combined = pd.concat(all_reports, ignore_index=True)\n",
    "\n",
    "# --- Aggregate per variable across all years/months ---\n",
    "FMI_summary = (\n",
    "    combined.groupby(\"Column\")\n",
    "    .agg(\n",
    "        TotalMissing=(\"Missing\", \"sum\"),\n",
    "        TotalRows=(\"Total\", \"sum\"),\n",
    "        AvgFMI=(\"FMI\", \"mean\"),\n",
    "        MonthsObserved=(\"Year\", \"count\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Compute overall FMI (weighted by total rows)\n",
    "FMI_summary[\"OverallFMI\"] = FMI_summary[\"TotalMissing\"] / FMI_summary[\"TotalRows\"]\n",
    "\n",
    "# Flag severity based on OverallFMI\n",
    "def flag_and_rec(fmi):\n",
    "    if fmi < 0.05:\n",
    "        return \"Low\", \"Keep\"\n",
    "    elif fmi < 0.20:\n",
    "        return \"Moderate\", \"Consider imputation\"\n",
    "    elif fmi < 0.40:\n",
    "        return \"High\", \"Strongly consider imputation\"\n",
    "    else:\n",
    "        return \"Critical\", \"Candidate to drop (validate with business logic)\"\n",
    "\n",
    "FMI_summary[[\"Flag\", \"Recommendation\"]] = FMI_summary[\"OverallFMI\"].apply(\n",
    "    lambda x: pd.Series(flag_and_rec(x))\n",
    ")\n",
    "\n",
    "FMI_summary.head(50)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10394f0b",
   "metadata": {},
   "source": [
    "### Weighted Avg of FMI - Redirect to Drive"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "711cbf26",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "===============================================\n",
      "STARTING OVERALL FMI SUMMARY (2018â€“2024)\n",
      "Source: /Users/neilkeannedelavega/Library/CloudStorage/GoogleDrive-shaniakeith23@gmail.com/My Drive/Labor Force Survey/FMI Reports\n",
      "Dest:   /Users/neilkeannedelavega/Library/CloudStorage/GoogleDrive-shaniakeith23@gmail.com/My Drive/Labor Force Survey/FMI Reports\n",
      "===============================================\n",
      "\n",
      "Processing: FMI_July_2022.csv...\n",
      "   [OK] Loaded 52 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_December_2022.csv...\n",
      "   [OK] Loaded 42 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_September_2022.csv...\n",
      "   [OK] Loaded 42 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_August_2022.csv...\n",
      "   [OK] Loaded 42 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_October_2022.csv...\n",
      "   [OK] Loaded 52 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_November_2022.csv...\n",
      "   [OK] Loaded 42 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_June_2024.csv...\n",
      "   [OK] Loaded 40 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_July_2024.csv...\n",
      "   [OK] Loaded 51 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_April_2024.csv...\n",
      "   [OK] Loaded 51 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_February_2024.csv...\n",
      "   [OK] Loaded 41 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_March_2024.csv...\n",
      "   [OK] Loaded 41 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_May_2024.csv...\n",
      "   [OK] Loaded 40 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_August_2024.csv...\n",
      "   [OK] Loaded 40 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_January_2024.csv...\n",
      "   [OK] Loaded 52 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_July_2023.csv...\n",
      "   [OK] Loaded 52 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_June_2023.csv...\n",
      "   [OK] Loaded 42 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_May_2023.csv...\n",
      "   [OK] Loaded 42 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_December_2023.csv...\n",
      "   [OK] Loaded 41 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_September_2023.csv...\n",
      "   [OK] Loaded 41 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_February_2023.csv...\n",
      "   [OK] Loaded 42 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_April_2023.csv...\n",
      "   [OK] Loaded 52 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_March_2023.csv...\n",
      "   [OK] Loaded 42 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_August_2023.csv...\n",
      "   [OK] Loaded 41 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_October_2023.csv...\n",
      "   [OK] Loaded 52 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_January_2023.csv...\n",
      "   [OK] Loaded 52 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_November_2023.csv...\n",
      "   [OK] Loaded 41 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_July_2019.csv...\n",
      "   [OK] Loaded 49 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_April_2019.csv...\n",
      "   [OK] Loaded 49 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_October_2019.csv...\n",
      "   [OK] Loaded 49 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_January_2019.csv...\n",
      "   [OK] Loaded 49 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_July_2018.csv...\n",
      "   [OK] Loaded 51 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_April_2018.csv...\n",
      "   [OK] Loaded 50 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_January_2018.csv...\n",
      "   [OK] Loaded 50 rows.\n",
      "----------------------------------------\n",
      "Processing: FMI_October_2018.csv...\n",
      "   [OK] Loaded 51 rows.\n",
      "----------------------------------------\n",
      "\n",
      "COMPLETED. Success: 34 | Errors: 0\n",
      "[SAVED] FMI_Summary_2018_2024.csv\n"
     ]
    }
   ],
   "source": [
    "\n",
    "reports_root = os.path.join(base_path, \"FMI Reports\")\n",
    "\n",
    "print(\"===============================================\")\n",
    "print(\"STARTING OVERALL FMI SUMMARY (2018â€“2024)\")\n",
    "print(f\"Source: {reports_root}\")\n",
    "print(f\"Dest:   {reports_root}\")\n",
    "print(\"===============================================\\n\")\n",
    "\n",
    "success_count = 0\n",
    "error_count = 0\n",
    "\n",
    "# --- Load all monthly FMI reports ---\n",
    "all_reports = []\n",
    "for year in os.listdir(reports_root):\n",
    "    year_folder = os.path.join(reports_root, year)\n",
    "    if not os.path.isdir(year_folder):\n",
    "        continue\n",
    "\n",
    "    for file in os.listdir(year_folder):\n",
    "        if not file.endswith(\".csv\"):\n",
    "            continue\n",
    "        file_path = os.path.join(year_folder, file)\n",
    "        try:\n",
    "            df = pd.read_csv(file_path)\n",
    "            all_reports.append(df)\n",
    "            print(f\"Processing: {file}...\")\n",
    "            print(f\"   [OK] Loaded {len(df)} rows.\")\n",
    "            print(\"----------------------------------------\")\n",
    "            success_count += 1\n",
    "        except Exception as e:\n",
    "            print(f\"   [ERROR] {file} â†’ {e}\")\n",
    "            print(\"----------------------------------------\")\n",
    "            error_count += 1\n",
    "\n",
    "# --- Combine all reports ---\n",
    "combined = pd.concat(all_reports, ignore_index=True)\n",
    "\n",
    "# --- Aggregate per variable across all years/months ---\n",
    "FMI_summary = (\n",
    "    combined.groupby(\"Column\")\n",
    "    .agg(\n",
    "        TotalMissing=(\"Missing\", \"sum\"),\n",
    "        TotalRows=(\"Total\", \"sum\"),\n",
    "        AvgFMI=(\"FMI\", \"mean\"),\n",
    "        MonthsObserved=(\"Year\", \"count\")\n",
    "    )\n",
    "    .reset_index()\n",
    ")\n",
    "\n",
    "# Compute overall FMI (weighted by total rows)\n",
    "FMI_summary[\"OverallFMI\"] = FMI_summary[\"TotalMissing\"] / FMI_summary[\"TotalRows\"]\n",
    "\n",
    "# Flag severity based on OverallFMI\n",
    "def flag_and_rec(fmi):\n",
    "    if fmi < 0.05:\n",
    "        return \"Low\", \"Keep\"\n",
    "    elif fmi < 0.20:\n",
    "        return \"Moderate\", \"Consider imputation\"\n",
    "    elif fmi < 0.40:\n",
    "        return \"High\", \"Strongly consider imputation\"\n",
    "    else:\n",
    "        return \"Critical\", \"Candidate to drop (validate with business logic)\"\n",
    "\n",
    "FMI_summary[[\"Flag\", \"Recommendation\"]] = FMI_summary[\"OverallFMI\"].apply(\n",
    "    lambda x: pd.Series(flag_and_rec(x))\n",
    ")\n",
    "\n",
    "# --- Save overall summary to Drive ---\n",
    "out_file = os.path.join(reports_root, \"FMI_Summary_2018_2024.csv\")\n",
    "FMI_summary.to_csv(out_file, index=False)\n",
    "\n",
    "print(f\"\\nCOMPLETED. Success: {success_count} | Errors: {error_count}\")\n",
    "print(f\"[SAVED] FMI_Summary_2018_2024.csv\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
