{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "65a8a0d8",
   "metadata": {},
   "source": [
    "\n",
    "This notebook decodes header survey datasets using metadata Sheet 1 and Sheet 2 definitions.  \n",
    "It renames raw variable codes into human‑readable descriptions, ensuring consistency across all survey files.\n",
    "\n",
    "##### Dependencies\n",
    "- Requires `00_Settings.ipynb` to be executed first (defines `inventory`, `base_path`, and global settings).\n",
    "- Requires reshaped metadata outputs from `01_Metadata_Sheet1_Reshaper.ipynb`.\n",
    "##### Outputs\n",
    "- Decoded survey CSVs saved into the folder: **NEW Header Encoded Surveys**\n",
    "- Formal translation reports per survey (coverage, untranslated codes).\n",
    "##### Notes\n",
    "- This notebook is functional and does not require reruns once executed.\n",
    "- Each notebook in the pipeline retains its function and respects assigned variables consistently.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9899899e",
   "metadata": {},
   "source": [
    "### Loader Function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b0ee8ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "def load_dataset(year, month, filetype=\"survey\"):\n",
    "    \"\"\"\n",
    "    Locate and load a dataset file (CSV or Excel) from the global inventory.\n",
    "    Relies on 'inventory' and 'base_path' defined in 00_Settings.ipynb.\n",
    "    \"\"\"\n",
    "    if year not in inventory or month not in inventory[year]:\n",
    "        raise ValueError(f\"No records found in inventory for {month} {year}.\")\n",
    "\n",
    "    files = inventory[year][month]\n",
    "    found_file = next((f for f in files if f['filetype'] == filetype), None)\n",
    "    if not found_file:\n",
    "        raise FileNotFoundError(f\"No {filetype} file found for {month} {year}.\")\n",
    "\n",
    "    file_path = os.path.join(base_path, year, found_file['filename'])\n",
    "    return pd.read_csv(file_path, low_memory=False) if filetype == \"survey\" else pd.read_excel(file_path)\n",
    "\n",
    "\n",
    "def load_clean_sheet1(year, month):\n",
    "    \"\"\"\n",
    "    Load processed variable definitions (Sheet 1) from 'Metadata Sheet 1 CSV's'.\n",
    "    \"\"\"\n",
    "    folder_name = \"Metadata Sheet 1 CSV's\"\n",
    "    filename = f\"Sheet1_{month}_{year}.csv\"\n",
    "    file_path = os.path.join(base_path, folder_name, year, filename)\n",
    "\n",
    "    if not os.path.exists(file_path):\n",
    "        raise FileNotFoundError(f\"Processed metadata file not found at {file_path}\")\n",
    "\n",
    "    return pd.read_csv(file_path)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec306f33",
   "metadata": {},
   "source": [
    "### Header translation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b1f7fdc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def apply_metadata_headers(survey_df, metadata_sheet1_df, year=\"Unknown\", month=\"Survey\"):\n",
    "    \"\"\"\n",
    "    Rename raw survey columns using metadata definitions.\n",
    "    Prints a translation report showing coverage and untranslated codes.\n",
    "    \"\"\"\n",
    "    metadata_sheet1_df['Variable'] = metadata_sheet1_df['Variable'].astype(str).str.strip()\n",
    "    metadata_sheet1_df['Description'] = metadata_sheet1_df['Description'].astype(str).str.strip()\n",
    "\n",
    "    header_map = dict(zip(metadata_sheet1_df['Variable'], metadata_sheet1_df['Description']))\n",
    "\n",
    "    original_cols = set(survey_df.columns)\n",
    "    translated_cols = original_cols.intersection(header_map.keys())\n",
    "    untranslated_cols = original_cols - header_map.keys()\n",
    "\n",
    "    renamed_df = survey_df.rename(columns=header_map)\n",
    "\n",
    "    print(\"\\n\" + \"=\"*60)\n",
    "    print(f\"METADATA TRANSLATION REPORT: {month.upper()} {year}\")\n",
    "    print(\"=\"*60)\n",
    "    print(f\"Total Columns Detected:       {len(original_cols)}\")\n",
    "    print(f\"Successfully Decoded:         {len(translated_cols)}\")\n",
    "    print(f\"Remaining as Raw Codes:       {len(untranslated_cols)}\")\n",
    "    print(\"-\" * 60)\n",
    "\n",
    "    if not untranslated_cols:\n",
    "        print(\"Status: SUCCESS (100% Metadata Coverage)\")\n",
    "    else:\n",
    "        print(\"Status: PARTIAL SUCCESS\")\n",
    "        print(\"Untranslated Codes:\", sorted(list(untranslated_cols)))\n",
    "\n",
    "    print(\"=\"*60 + \"\\n\")\n",
    "    return renamed_df\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39173b29",
   "metadata": {},
   "source": [
    "### Batch Automation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "281f2098",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
