{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4e71ee16",
   "metadata": {},
   "source": [
    "This notebook performs dimension-specific exploratory factor analysis (FA) on imputed Labor Force Survey data, following the approved theoretical framework of (Sensitivity, Resilience and Exposure).\n",
    "\n",
    "Note that **these dimensions are not discovered by FA.** They are theory-driven constructs defined in a basis paper on financial vulnerability, which argues that vulnerability cannot be captured by a single latent dimension.\n",
    "\n",
    "\n",
    "FA is used here to:\n",
    "\n",
    "- test internal coherence of variables within each dimension\n",
    "- identify possible subfactors inside Sensitivity, Resilience, or Exposure\n",
    "- validate whether assigned variables behave as expected statistically\n",
    "- FA is not used to invent or redefine Sensitivity, Resilience, or Exposure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "01591873",
   "metadata": {},
   "source": [
    "Pipeline Data Dependencies\n",
    "\n",
    "**NEW Variable Consistency Check**\n",
    "- defines which variables are eligible for FA and which dimension they belong to\n",
    "\n",
    "**Imputed Data for Analysis**\n",
    "- contains the actual numeric values to be analyzed\n",
    "\n",
    "**FA_Results**\n",
    "- purely derived outputs, always safe to delete and regenerate in shared drive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4b6661bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: factor-analyzer in c:\\users\\shania\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (0.5.1)\n",
      "Requirement already satisfied: pandas in c:\\users\\shania\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from factor-analyzer) (2.3.3)\n",
      "Requirement already satisfied: scipy in c:\\users\\shania\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from factor-analyzer) (1.16.3)\n",
      "Requirement already satisfied: numpy in c:\\users\\shania\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from factor-analyzer) (2.3.4)\n",
      "Requirement already satisfied: scikit-learn in c:\\users\\shania\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from factor-analyzer) (1.7.2)\n",
      "Requirement already satisfied: python-dateutil>=2.8.2 in c:\\users\\shania\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas->factor-analyzer) (2.9.0.post0)\n",
      "Requirement already satisfied: pytz>=2020.1 in c:\\users\\shania\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas->factor-analyzer) (2025.2)\n",
      "Requirement already satisfied: tzdata>=2022.7 in c:\\users\\shania\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from pandas->factor-analyzer) (2025.2)\n",
      "Requirement already satisfied: six>=1.5 in c:\\users\\shania\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from python-dateutil>=2.8.2->pandas->factor-analyzer) (1.17.0)\n",
      "Requirement already satisfied: joblib>=1.2.0 in c:\\users\\shania\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from scikit-learn->factor-analyzer) (1.5.2)\n",
      "Requirement already satisfied: threadpoolctl>=3.1.0 in c:\\users\\shania\\appdata\\local\\programs\\python\\python314\\lib\\site-packages (from scikit-learn->factor-analyzer) (3.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install factor-analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "43708477",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from factor_analyzer import (\n",
    "    FactorAnalyzer,\n",
    "    calculate_kmo,\n",
    "    calculate_bartlett_sphericity\n",
    ")\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import sklearn.utils.validation as suv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60131463",
   "metadata": {},
   "source": [
    "### Config loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a313c321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "with open(Path(\"./data/interim/config.json\")) as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "BASE_PATH = Path(cfg[\"BASE_PATH\"])\n",
    "\n",
    "CONSISTENCY_ROOT = BASE_PATH / \"NEW Variable Consistency Check\"\n",
    "IMPUTED_ROOT     = BASE_PATH / \"Imputed Data for Analysis\"\n",
    "DECISION_ROOT    = BASE_PATH / \"Decision Matrix for Imputation\"\n",
    "\n",
    "OUTPUT_RESULTS = BASE_PATH / \"FA_Results\"\n",
    "\n",
    "# Always recreate results directory\n",
    "if OUTPUT_RESULTS.exists():\n",
    "    for p in OUTPUT_RESULTS.iterdir():\n",
    "        if p.is_dir():\n",
    "            for f in p.iterdir():\n",
    "                f.unlink()\n",
    "            p.rmdir()\n",
    "        else:\n",
    "            p.unlink()\n",
    "OUTPUT_RESULTS.mkdir(exist_ok=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e782e635",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Variable</th>\n",
       "      <th>ConsistencyTag</th>\n",
       "      <th>OverallFMI</th>\n",
       "      <th>Flag</th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Action</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Available for Work</td>\n",
       "      <td>consistent</td>\n",
       "      <td>0.965370</td>\n",
       "      <td>Critical</td>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>consider_drop_or_advanced</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C03-Relationship to Household Head</td>\n",
       "      <td>consistent</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Resilience</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C04-Sex</td>\n",
       "      <td>consistent</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Resilience</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C05-Age as of Last Birthday</td>\n",
       "      <td>consistent</td>\n",
       "      <td>0.016952</td>\n",
       "      <td>Low</td>\n",
       "      <td>Resilience</td>\n",
       "      <td>keep</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C05B - Ethnicity</td>\n",
       "      <td>inconsistent</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>Low</td>\n",
       "      <td>Resilience</td>\n",
       "      <td>exclude_from_FA</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                             Variable ConsistencyTag  OverallFMI      Flag  \\\n",
       "0                  Available for Work     consistent    0.965370  Critical   \n",
       "1  C03-Relationship to Household Head     consistent    0.000000       Low   \n",
       "2                             C04-Sex     consistent    0.000000       Low   \n",
       "3         C05-Age as of Last Birthday     consistent    0.016952       Low   \n",
       "4                    C05B - Ethnicity   inconsistent    0.000000       Low   \n",
       "\n",
       "     Dimension                     Action  \n",
       "0  Sensitivity  consider_drop_or_advanced  \n",
       "1   Resilience                       keep  \n",
       "2   Resilience                       keep  \n",
       "3   Resilience                       keep  \n",
       "4   Resilience            exclude_from_FA  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "decision_df = pd.read_csv(DECISION_ROOT / \"Decision_Matrix.csv\")\n",
    "decision_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c80581b0",
   "metadata": {},
   "source": [
    "The Decision Matrix (built in 09_Imputation.ipynb) already encodes:\n",
    "\n",
    "- variable consistency\n",
    "- missingness severity (FMI)\n",
    "- theoretical dimension (S / R / E)\n",
    "- This notebook does not override those decisions (subject to change). \n",
    "\n",
    "Imputation (09) was performed to preserve dataset completeness and comparability across survey waves. **However, factor analysis will be restricted to variables with acceptable FMI and conceptual reliability, as documented in our Decision Matrix.** Variables with higher FMI were either excluded or treated as supporting diagnostics, not as core drivers of latent structure."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89bbeead",
   "metadata": {},
   "source": [
    "### Defining FA Eligibility Rules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "98f9ae1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "FA_ELIGIBLE_ACTIONS = [\n",
    "    \"keep\",\n",
    "    \"impute_light\",\n",
    "    \"impute_cautious\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc43b1e4",
   "metadata": {},
   "source": [
    "**Interpretation:**\n",
    "\n",
    "- exclude_from_FA - never used for factor extraction\n",
    "- sensitivity_only - diagnostic or robustness checks only\n",
    "\n",
    "high-risk variables will be  intentionally excluded at this stage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ab6a80cd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sensitivity: 2\n",
      "Resilience : 7\n",
      "Exposure   : 4\n"
     ]
    }
   ],
   "source": [
    "def get_fa_variables(dimension: str):\n",
    "    return decision_df[\n",
    "        (decision_df[\"Dimension\"] == dimension) &\n",
    "        (decision_df[\"Action\"].isin(FA_ELIGIBLE_ACTIONS))\n",
    "    ][\"Variable\"].tolist()\n",
    "\n",
    "SENSITIVITY_VARS = get_fa_variables(\"Sensitivity\")\n",
    "RESILIENCE_VARS  = get_fa_variables(\"Resilience\")\n",
    "EXPOSURE_VARS    = get_fa_variables(\"Exposure\")\n",
    "\n",
    "print(\"Sensitivity:\", len(SENSITIVITY_VARS))\n",
    "print(\"Resilience :\", len(RESILIENCE_VARS))\n",
    "print(\"Exposure   :\", len(EXPOSURE_VARS))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9398b6b3",
   "metadata": {},
   "source": [
    "This codeblock enforces the split FA by dimension rule:\n",
    "\n",
    "- FA(Sensitivity only)\n",
    "- FA(Resilience only)\n",
    "- FA(Exposure only)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "4ad6144f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_name(name: str) -> str:\n",
    "    return (\n",
    "        str(name)\n",
    "        .strip()\n",
    "        .lower()\n",
    "        .replace(\"\\xa0\", \" \")\n",
    "        .replace(\"-\", \" \")\n",
    "        .replace(\"_\", \" \")\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c8b819b",
   "metadata": {},
   "source": [
    "This codeblock normalizes column names to avoid mismatches (e.g., “Available for Work” vs “available_for_work” given that they have the same meaning). This guarantees consistent variable matching across years and pipelines. **If you tweak this, keep transformations symmetric with imputation (view 09_Imputation. I applied the same rules for 10_Factor_Analysis). Changing normalization can break matching.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "59918ede",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Final shape: (4881364, 63)\n"
     ]
    }
   ],
   "source": [
    "all_dfs = []\n",
    "\n",
    "for year_dir in IMPUTED_ROOT.iterdir():\n",
    "    if not year_dir.is_dir():\n",
    "        continue\n",
    "\n",
    "    for file in year_dir.glob(\"imputed_*.csv\"):\n",
    "        df = pd.read_csv(file)\n",
    "        df.columns = [normalize_name(c) for c in df.columns]\n",
    "        all_dfs.append(df)\n",
    "\n",
    "full_df = pd.concat(all_dfs, ignore_index=True)\n",
    "print(\"Final shape:\", full_df.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bba32571",
   "metadata": {},
   "outputs": [],
   "source": [
    "SENSITIVITY_VARS = [normalize_name(v) for v in SENSITIVITY_VARS]\n",
    "RESILIENCE_VARS  = [normalize_name(v) for v in RESILIENCE_VARS]\n",
    "EXPOSURE_VARS    = [normalize_name(v) for v in EXPOSURE_VARS]\n",
    "\n",
    "DIMENSION_MAP = {\n",
    "    \"Sensitivity\": SENSITIVITY_VARS,\n",
    "    \"Resilience\": RESILIENCE_VARS,\n",
    "    \"Exposure\": EXPOSURE_VARS\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8d40dce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_fa(df: pd.DataFrame, variables: list, dimension: str):\n",
    "    X = df[variables].copy()\n",
    "\n",
    "    # Convert non-numeric columns\n",
    "    for col in X.columns:\n",
    "        if not pd.api.types.is_numeric_dtype(X[col]):\n",
    "            X[col] = pd.Categorical(X[col]).codes\n",
    "\n",
    "    # Clean\n",
    "    X = X.replace([np.inf, -np.inf], np.nan).dropna()\n",
    "    X = X.loc[:, X.nunique() > 1]\n",
    "\n",
    "    # Diagnostics\n",
    "    kmo_all, kmo_model = calculate_kmo(X)\n",
    "    chi2, bartlett_p = calculate_bartlett_sphericity(X)\n",
    "\n",
    "    # Eigenvalues via correlation matrix (stable)\n",
    "    corr_matrix = np.corrcoef(X, rowvar=False)\n",
    "    eigenvalues = np.linalg.eigvals(corr_matrix).real\n",
    "\n",
    "    n_factors = max(1, np.sum(eigenvalues > 1))\n",
    "\n",
    "    # Final FA\n",
    "    fa = FactorAnalyzer(n_factors=n_factors, rotation=\"varimax\")\n",
    "    fa.fit(X)\n",
    "\n",
    "    loadings = pd.DataFrame(\n",
    "        fa.loadings_,\n",
    "        index=X.columns,\n",
    "        columns=[f\"Factor_{i+1}\" for i in range(n_factors)]\n",
    "    )\n",
    "\n",
    "    return {\n",
    "        \"dimension\": dimension,\n",
    "        \"n_obs\": X.shape[0],\n",
    "        \"n_vars\": X.shape[1],\n",
    "        \"kmo\": kmo_model,\n",
    "        \"bartlett_p\": bartlett_p,\n",
    "        \"n_factors\": n_factors,\n",
    "        \"eigenvalues\": eigenvalues,\n",
    "        \"loadings\": loadings\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "89ca66f7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running FA for Sensitivity\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHANIA\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n",
      "c:\\Users\\SHANIA\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\factor_analyzer\\factor_analyzer.py:663: UserWarning: No rotation will be performed when the number of factors equals 1.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running FA for Resilience\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHANIA\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Running FA for Exposure\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\SHANIA\\AppData\\Local\\Programs\\Python\\Python314\\Lib\\site-packages\\sklearn\\utils\\deprecation.py:132: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Dimension</th>\n",
       "      <th>Observations</th>\n",
       "      <th>Variables</th>\n",
       "      <th>KMO</th>\n",
       "      <th>Bartlett_p</th>\n",
       "      <th>Factors_Extracted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Sensitivity</td>\n",
       "      <td>4881364</td>\n",
       "      <td>2</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Resilience</td>\n",
       "      <td>4881364</td>\n",
       "      <td>7</td>\n",
       "      <td>0.520984</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Exposure</td>\n",
       "      <td>4881364</td>\n",
       "      <td>4</td>\n",
       "      <td>0.430576</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     Dimension  Observations  Variables       KMO  Bartlett_p  \\\n",
       "0  Sensitivity       4881364          2  0.500000         0.0   \n",
       "1   Resilience       4881364          7  0.520984         0.0   \n",
       "2     Exposure       4881364          4  0.430576         0.0   \n",
       "\n",
       "   Factors_Extracted  \n",
       "0                  1  \n",
       "1                  3  \n",
       "2                  2  "
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "summary_rows = []\n",
    "\n",
    "for dim, vars_ in DIMENSION_MAP.items():\n",
    "    print(f\"\\nRunning FA for {dim}\")\n",
    "\n",
    "    result = run_fa(full_df, vars_, dim)\n",
    "\n",
    "    dim_dir = OUTPUT_RESULTS / dim\n",
    "    dim_dir.mkdir(exist_ok=True)\n",
    "\n",
    "    # Save loadings\n",
    "    result[\"loadings\"].to_csv(dim_dir / \"factor_loadings.csv\")\n",
    "\n",
    "    # Save eigenvalues\n",
    "    pd.DataFrame({\n",
    "        \"Eigenvalue\": result[\"eigenvalues\"]\n",
    "    }).to_csv(dim_dir / \"eigenvalues.csv\", index=False)\n",
    "\n",
    "    # Collect summary\n",
    "    summary_rows.append({\n",
    "        \"Dimension\": dim,\n",
    "        \"Observations\": result[\"n_obs\"],\n",
    "        \"Variables\": result[\"n_vars\"],\n",
    "        \"KMO\": result[\"kmo\"],\n",
    "        \"Bartlett_p\": result[\"bartlett_p\"],\n",
    "        \"Factors_Extracted\": result[\"n_factors\"]\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(summary_rows)\n",
    "summary_df.head()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5deb4557",
   "metadata": {},
   "outputs": [],
   "source": [
    "summary_df.to_csv(OUTPUT_RESULTS / \"FA_Summary.csv\", index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
