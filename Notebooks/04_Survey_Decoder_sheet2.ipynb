{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06f3e89",
   "metadata": {},
   "source": [
    "\n",
    "This notebook applies metadata Sheet 2 definitions to decode survey values.  \n",
    "This notebook maps coded responses (e.g., 1, 2, 3) into human‑readable labels (e.g., Employed, Unemployed).\n",
    "\n",
    "Dependencies:\n",
    "- Run `00_Settings.ipynb` and `01_Inventory.ipynb` first.\n",
    "- Requires outputs from `03_Metadata_Decoder.ipynb` (Header Encoded Surveys).\n",
    "- Note: Survey CSVs already carry meaning from Sheet 2 reshaping. This notebook applies the final decoding logic.\n",
    "\n",
    "Output:\n",
    "\n",
    "- Fully decoded survey CSVs saved into **NEW Fully Decoded Surveys**.\n",
    "- Reports per survey showing number of columns successfully decoded.\n",
    "\n",
    "Notes:\n",
    "- **Sheet 1 metadata** → header translation (column names).  \n",
    "- **Sheet 2 metadata** → value translation (coded responses).  \n",
    "\n",
    "**INTENT:** This notebook performs the **final decoding stage** of the Labor Force Survey pipeline.  \n",
    "It applies **Sheet 2 metadata** to translate coded survey values into human‑readable labels.\n",
    "\n",
    "- Next steps: duplicate variable detection, integrity checks, coverage scanning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linter stubs (will be overwritten when 00_Settings.ipynb runs)\n",
    "BASE_PATH: str\n",
    "inventory: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f78362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure settings are loaded\n",
    "%run ./00_Settings.ipynb\n",
    "%run ./01_Inventory.ipynb\n",
    "\n",
    "# Alias for compatibility\n",
    "base_path = BASE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcfa81",
   "metadata": {},
   "source": [
    "### Interim Sample "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4684f1c",
   "metadata": {},
   "source": [
    "#### Intent: Interim Sample Decoder\n",
    "\n",
    "This interim function generates a **single sample output** (e.g., `NEW Fully Decoded Survey Sample` for **January 2018**) using the same decoding logic as the batch runner.  \n",
    "\n",
    "Unlike the full batch process, which redirects all decoded surveys to Google Drive, this sample run saves directly into the local **interim repository path**.  \n",
    "\n",
    "The purpose is to provide a quick preview of how a fully decoded CSV looks without requiring you to download the large, heavy files from Google Drive.  \n",
    "\n",
    "Use this when:\n",
    "- You want to validate decoding logic on a small subset before running the full batch.  \n",
    "- You need a lightweight example for documentation, testing, or demonstration.  \n",
    "- You want to inspect decoded values locally without waiting for the complete dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Interim sample decoder (standalone, portable)\n",
    "# ============================================================\n",
    "def run_sample_decoding(base_path,\n",
    "                        year=\"2018\",\n",
    "                        month=\"January\",\n",
    "                        interim_root=None):\n",
    "    \"\"\"\n",
    "    Decode a single survey file (e.g., January 2018) for demonstration.\n",
    "    Saves into '<base_path>/data/interim/NEW Fully Decoded Survey Sample/<year>/' by default.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    base_path : str\n",
    "        Root path defined in 00_Settings.ipynb\n",
    "    year : str\n",
    "        Year of the survey (default \"2018\")\n",
    "    month : str\n",
    "        Month of the survey (default \"January\")\n",
    "    interim_root : str, optional\n",
    "        Custom interim path. If None, defaults to '<base_path>/data/interim'.\n",
    "    \"\"\"\n",
    "\n",
    "    # Normalize month capitalization (e.g., january -> January)\n",
    "    month = month.strip().capitalize()\n",
    "    if month.upper() not in MONTHS:\n",
    "        raise ValueError(f\"Invalid month: {month}. Expected one of: {', '.join(MONTHS)}\")\n",
    "\n",
    "    # Default interim path inside repo if not provided\n",
    "    if interim_root is None:\n",
    "        interim_root = os.path.join(base_path, \"data\", \"interim\")\n",
    "\n",
    "    input_root = os.path.join(base_path, HEADER_ENCODED_FOLDER, year)\n",
    "    output_root = os.path.join(interim_root, FULLY_DECODED_SAMPLE_FOLDER, year)\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    # Find the survey file for the given month\n",
    "    if not os.path.exists(input_root):\n",
    "        print(f\"[SKIP] Input folder not found: {input_root}\")\n",
    "        return\n",
    "\n",
    "    files = [f for f in os.listdir(input_root) if f.lower().endswith(\".csv\")]\n",
    "    target_file = next((f for f in files if month.upper() in f.upper()), None)\n",
    "\n",
    "    if not target_file:\n",
    "        print(f\"[SKIP] No survey file found for {month} {year} in {input_root}.\")\n",
    "        return\n",
    "\n",
    "    print(\"================================================\")\n",
    "    print(f\"SAMPLE DECODING: {month.upper()} {year}\")\n",
    "    print(f\"Source: {input_root}\")\n",
    "    print(f\"Dest:   {output_root}\")\n",
    "    print(\"================================================\\n\")\n",
    "\n",
    "    try:\n",
    "        # 1. Load Survey\n",
    "        survey_path = os.path.join(input_root, target_file)\n",
    "        df_survey = pd.read_csv(survey_path, low_memory=False)\n",
    "\n",
    "        # 2. Load Metadata\n",
    "        df_meta = load_clean_sheet2(base_path, year, month)\n",
    "\n",
    "        # 3. Decode\n",
    "        df_final, count = decode_survey_safe(df_survey, df_meta)\n",
    "\n",
    "        # 4. Save\n",
    "        save_path = os.path.join(output_root, target_file)\n",
    "        df_final.to_csv(save_path, index=False)\n",
    "\n",
    "        print(f\"   [OK] Decoded {count} columns.\")\n",
    "        print(f\"   [SAVED] {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   [ERROR] {e}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac09abbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# EXECUTION CONTROL\n",
    "# ============================================================\n",
    "\n",
    "# Option 1: Run interim sample first (lightweight preview)\n",
    "run_sample_decoding(base_path, year=\"2018\", month=\"January\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf0f24",
   "metadata": {},
   "source": [
    "### Batch Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b008d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Full batch decoder (unchanged, uses same helpers)\n",
    "# ============================================================\n",
    "def run_batch_decoding(base_path):\n",
    "    \"\"\"\n",
    "    Batch decode all survey CSVs using Sheet 2 metadata.\n",
    "    Saves results into 'NEW Fully Decoded Surveys'.\n",
    "    \"\"\"\n",
    "    input_root = os.path.join(base_path, HEADER_ENCODED_FOLDER)\n",
    "    output_root = os.path.join(base_path, FULLY_DECODED_FOLDER)\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    print(\"================================================\")\n",
    "    print(\"STARTING BATCH VALUE DECODING\")\n",
    "    print(f\"Source: {input_root}\")\n",
    "    print(f\"Dest:   {output_root}\")\n",
    "    print(\"================================================\\n\")\n",
    "\n",
    "    if not os.path.exists(input_root):\n",
    "        print(f\"Error: Input folder not found: {input_root}\")\n",
    "        return\n",
    "\n",
    "    success, errors = 0, 0\n",
    "\n",
    "    year_folders = [f for f in os.listdir(input_root) if f.isdigit() and os.path.isdir(os.path.join(input_root, f))]\n",
    "    for year in sorted(year_folders):\n",
    "        year_in = os.path.join(input_root, year)\n",
    "        year_out = os.path.join(output_root, year)\n",
    "        os.makedirs(year_out, exist_ok=True)\n",
    "\n",
    "        files = [f for f in os.listdir(year_in) if f.lower().endswith(\".csv\")]\n",
    "        for filename in files:\n",
    "            match = MONTH_PATTERN.search(filename)\n",
    "            if not match: continue\n",
    "            month = match.group(1).capitalize()\n",
    "\n",
    "            print(f\"Processing: {month.upper()} {year}...\")\n",
    "\n",
    "            try:\n",
    "                df_survey = pd.read_csv(os.path.join(year_in, filename), low_memory=False)\n",
    "                df_meta = load_clean_sheet2(base_path, year, month)\n",
    "                df_final, count = decode_survey_safe(df_survey, df_meta)\n",
    "\n",
    "                save_path = os.path.join(year_out, filename)\n",
    "                df_final.to_csv(save_path, index=False)\n",
    "\n",
    "                print(f\"   [OK] Decoded {count} columns.\")\n",
    "                print(f\"   [SAVED] {filename}\")\n",
    "                success += 1\n",
    "\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"   [SKIP] Metadata missing: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   [ERROR] {e}\")\n",
    "                errors += 1\n",
    "\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "    print(f\"\\nCOMPLETED. Success: {success} | Errors: {errors}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ecbb013b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Option 2: Run full batch (heavy, Google Drive output)\n",
    "run_batch_decoding(base_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
