{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06f3e89",
   "metadata": {},
   "source": [
    "\n",
    "This notebook applies metadata Sheet 2 definitions to decode survey values.  \n",
    "This notebook maps coded responses (e.g., 1, 2, 3) into human‑readable labels (e.g., Employed, Unemployed).\n",
    "\n",
    "Dependencies:\n",
    "- Run `00_Settings.ipynb` and `01_Inventory.ipynb` first.\n",
    "- Requires outputs from `03_Metadata_Decoder.ipynb` (Header Encoded Surveys).\n",
    "- Note: Survey CSVs already carry meaning from Sheet 2 reshaping. This notebook applies the final decoding logic.\n",
    "\n",
    "Output:\n",
    "\n",
    "- Fully decoded survey CSVs saved into **NEW Fully Decoded Surveys**.\n",
    "- Reports per survey showing number of columns successfully decoded.\n",
    "\n",
    "Notes:\n",
    "- **Sheet 1 metadata** → header translation (column names).  \n",
    "- **Sheet 2 metadata** → value translation (coded responses).  \n",
    "\n",
    "**INTENT:** This notebook performs the **final decoding stage** of the Labor Force Survey pipeline.  \n",
    "It applies **Sheet 2 metadata** to translate coded survey values into human‑readable labels.\n",
    "\n",
    "- Next steps: duplicate variable detection, integrity checks, coverage scanning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0fa8a903",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Linter stubs (will be overwritten when 00_Settings.ipynb runs)\n",
    "BASE_PATH: str\n",
    "inventory: dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f78362",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensure settings are loaded\n",
    "%run ./00_Settings.ipynb\n",
    "%run ./01_Inventory.ipynb\n",
    "\n",
    "# Alias for compatibility\n",
    "base_path = BASE_PATH"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcfa81",
   "metadata": {},
   "source": [
    "### Interim Sample "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4684f1c",
   "metadata": {},
   "source": [
    "#### Intent: Interim Sample Decoder\n",
    "\n",
    "This interim function generates a **single sample output** (e.g., `NEW Fully Decoded Survey Sample` for **January 2018**) using the same decoding logic as the batch runner.  \n",
    "\n",
    "Unlike the full batch process, which redirects all decoded surveys to Google Drive, this sample run saves directly into the local **interim repository path**.  \n",
    "\n",
    "The purpose is to provide a quick preview of how a fully decoded CSV looks without requiring you to download the large, heavy files from Google Drive.  \n",
    "\n",
    "Use this when:\n",
    "- You want to validate decoding logic on a small subset before running the full batch.  \n",
    "- You need a lightweight example for documentation, testing, or demonstration.  \n",
    "- You want to inspect decoded values locally without waiting for the complete dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09d3f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import os, re\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Shared folder names \n",
    "# ------------------------------------------------------------\n",
    "HEADER_ENCODED_FOLDER = \"NEW Header Encoded Surveys\"\n",
    "FULLY_DECODED_FOLDER = \"NEW Fully Decoded Surveys\"\n",
    "FULLY_DECODED_SAMPLE_FOLDER = \"NEW Fully Decoded Survey Sample\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Helper: robust month parsing from filename\n",
    "# ------------------------------------------------------------\n",
    "MONTHS = [\n",
    "    \"JANUARY\",\"FEBRUARY\",\"MARCH\",\"APRIL\",\"MAY\",\"JUNE\",\n",
    "    \"JULY\",\"AUGUST\",\"SEPTEMBER\",\"OCTOBER\",\"NOVEMBER\",\"DECEMBER\"\n",
    "]\n",
    "MONTH_PATTERN = re.compile(r\"(JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)\", re.IGNORECASE)\n",
    "\n",
    "\n",
    "def load_clean_sheet2(base_path, year, month):\n",
    "    \"\"\"\n",
    "    Load the Clean Sheet 2 Metadata for value decoding.\n",
    "    \"\"\"\n",
    "    path = os.path.join(base_path, \"Metadata Sheet 2 CSV's\", year, f\"Sheet2_{month}_{year}.csv\")\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Metadata not found at: {path}\")\n",
    "    return pd.read_csv(path, dtype=str)\n",
    "\n",
    "\n",
    "def find_target_column(survey_columns, meta_desc):\n",
    "    \"\"\"\n",
    "    Smart Matcher: Align metadata descriptions with survey columns.\n",
    "    Handles cases like 'Highest Grade' vs 'C07-Highest Grade Completed'.\n",
    "    \"\"\"\n",
    "    if pd.isna(meta_desc): return None\n",
    "    meta_desc = str(meta_desc).strip()\n",
    "\n",
    "    # 1. Exact Match\n",
    "    if meta_desc in survey_columns: return meta_desc\n",
    "\n",
    "    # 2. Metadata has prefix (Meta=\"C06-Status\" -> Survey=\"Status\")\n",
    "    clean_meta = re.sub(r'^C\\d+[\\s\\-_]+', '', meta_desc, flags=re.IGNORECASE).strip()\n",
    "    if clean_meta in survey_columns: return clean_meta\n",
    "\n",
    "    # 3. Survey has prefix (Meta=\"Status\" -> Survey=\"C06-Status\")\n",
    "    for col in survey_columns:\n",
    "        if col.endswith(meta_desc):\n",
    "            prefix = col[:-len(meta_desc)].strip()\n",
    "            if re.search(r'^C\\d+[\\s\\-_]*$', prefix, re.IGNORECASE) or prefix == \"\":\n",
    "                return col\n",
    "    return None\n",
    "\n",
    "\n",
    "def decode_survey_safe(survey_df, meta_df):\n",
    "    \"\"\"\n",
    "    Decode survey values using metadata Sheet 2.\n",
    "    Applies Smart Matcher and safe mapping logic.\n",
    "    \"\"\"\n",
    "    unique_vars = meta_df['Variable'].unique()\n",
    "    decoded_count = 0\n",
    "    survey_cols = list(survey_df.columns)\n",
    "\n",
    "    for var_code in unique_vars:\n",
    "        subset = meta_df[meta_df['Variable'] == var_code].copy()\n",
    "        if subset['Description'].isnull().all(): continue\n",
    "\n",
    "        raw_desc = subset['Description'].dropna().iloc[0].strip()\n",
    "        target_col = find_target_column(survey_cols, raw_desc)\n",
    "        if not target_col: continue\n",
    "\n",
    "        # Skip if all labels are zero/nan\n",
    "        mask_zeros = subset['Label'].astype(str).isin(['0', '0.0', '0.00', 'nan', 'NaN'])\n",
    "        if mask_zeros.all(): continue\n",
    "\n",
    "        # Build lookup dictionary\n",
    "        lookup = {}\n",
    "        for _, row in subset.iterrows():\n",
    "            try:\n",
    "                label = row['Label']\n",
    "                if str(label) in ['0', '0.0', 'nan']: continue\n",
    "\n",
    "                min_v = float(row['min_value'])\n",
    "                max_v = float(row['max_value'])\n",
    "\n",
    "                if max_v > min_v and max_v != 0:\n",
    "                    for c in range(int(min_v), int(max_v) + 1):\n",
    "                        lookup[c] = label\n",
    "                else:\n",
    "                    lookup[int(min_v)] = label\n",
    "            except:\n",
    "                continue\n",
    "\n",
    "        if not lookup: continue\n",
    "\n",
    "        def safe_map(val):\n",
    "            try: return lookup.get(int(float(val)), val)\n",
    "            except: return val\n",
    "\n",
    "        survey_df[target_col] = survey_df[target_col].apply(safe_map)\n",
    "        decoded_count += 1\n",
    "\n",
    "    return survey_df, decoded_count\n",
    "\n",
    "\n",
    "# ============================================================\n",
    "# Interim sample decoder (standalone)\n",
    "# ============================================================\n",
    "def run_sample_decoding(base_path,\n",
    "                        year=\"2018\",\n",
    "                        month=\"January\",\n",
    "                        interim_root=r\"C:\\Users\\SHANIA\\Downloads\\Preprocessing\\Notebooks\\data\\interim\"):\n",
    "    \"\"\"\n",
    "    Decode a single survey file (e.g., January 2018) for demonstration.\n",
    "    Saves into 'data/interim/NEW Fully Decoded Survey Sample/<year>/'.\n",
    "    \"\"\"\n",
    "    # Normalize month capitalization (e.g., january -> January)\n",
    "    month = month.strip().capitalize()\n",
    "    if month.upper() not in MONTHS:\n",
    "        raise ValueError(f\"Invalid month: {month}. Expected one of: {', '.join(MONTHS)}\")\n",
    "\n",
    "    input_root = os.path.join(base_path, HEADER_ENCODED_FOLDER, year)\n",
    "    output_root = os.path.join(interim_root, FULLY_DECODED_SAMPLE_FOLDER, year)\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    # Find the survey file for the given month\n",
    "    if not os.path.exists(input_root):\n",
    "        print(f\"[SKIP] Input folder not found: {input_root}\")\n",
    "        return\n",
    "\n",
    "    files = [f for f in os.listdir(input_root) if f.lower().endswith(\".csv\")]\n",
    "    target_file = next((f for f in files if month.upper() in f.upper()), None)\n",
    "\n",
    "    if not target_file:\n",
    "        print(f\"[SKIP] No survey file found for {month} {year} in {input_root}.\")\n",
    "        return\n",
    "\n",
    "    print(\"================================================\")\n",
    "    print(f\"SAMPLE DECODING: {month.upper()} {year}\")\n",
    "    print(f\"Source: {input_root}\")\n",
    "    print(f\"Dest:   {output_root}\")\n",
    "    print(\"================================================\\n\")\n",
    "\n",
    "    try:\n",
    "        # 1. Load Survey\n",
    "        survey_path = os.path.join(input_root, target_file)\n",
    "        df_survey = pd.read_csv(survey_path, low_memory=False)\n",
    "\n",
    "        # 2. Load Metadata\n",
    "        df_meta = load_clean_sheet2(base_path, year, month)\n",
    "\n",
    "        # 3. Decode\n",
    "        df_final, count = decode_survey_safe(df_survey, df_meta)\n",
    "\n",
    "        # 4. Save\n",
    "        save_path = os.path.join(output_root, target_file)\n",
    "        df_final.to_csv(save_path, index=False)\n",
    "\n",
    "        print(f\"   [OK] Decoded {count} columns.\")\n",
    "        print(f\"   [SAVED] {save_path}\")\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"   [ERROR] {e}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ddf0f24",
   "metadata": {},
   "source": [
    "### Batch Runner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b008d4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ============================================================\n",
    "# Full batch decoder (unchanged, uses same helpers)\n",
    "# ============================================================\n",
    "def run_batch_decoding(base_path):\n",
    "    \"\"\"\n",
    "    Batch decode all survey CSVs using Sheet 2 metadata.\n",
    "    Saves results into 'NEW Fully Decoded Surveys'.\n",
    "    \"\"\"\n",
    "    input_root = os.path.join(base_path, HEADER_ENCODED_FOLDER)\n",
    "    output_root = os.path.join(base_path, FULLY_DECODED_FOLDER)\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    print(\"================================================\")\n",
    "    print(\"STARTING BATCH VALUE DECODING\")\n",
    "    print(f\"Source: {input_root}\")\n",
    "    print(f\"Dest:   {output_root}\")\n",
    "    print(\"================================================\\n\")\n",
    "\n",
    "    if not os.path.exists(input_root):\n",
    "        print(f\"Error: Input folder not found: {input_root}\")\n",
    "        return\n",
    "\n",
    "    success, errors = 0, 0\n",
    "\n",
    "    year_folders = [f for f in os.listdir(input_root) if f.isdigit() and os.path.isdir(os.path.join(input_root, f))]\n",
    "    for year in sorted(year_folders):\n",
    "        year_in = os.path.join(input_root, year)\n",
    "        year_out = os.path.join(output_root, year)\n",
    "        os.makedirs(year_out, exist_ok=True)\n",
    "\n",
    "        files = [f for f in os.listdir(year_in) if f.lower().endswith(\".csv\")]\n",
    "        for filename in files:\n",
    "            match = MONTH_PATTERN.search(filename)\n",
    "            if not match: continue\n",
    "            month = match.group(1).capitalize()\n",
    "\n",
    "            print(f\"Processing: {month.upper()} {year}...\")\n",
    "\n",
    "            try:\n",
    "                df_survey = pd.read_csv(os.path.join(year_in, filename), low_memory=False)\n",
    "                df_meta = load_clean_sheet2(base_path, year, month)\n",
    "                df_final, count = decode_survey_safe(df_survey, df_meta)\n",
    "\n",
    "                save_path = os.path.join(year_out, filename)\n",
    "                df_final.to_csv(save_path, index=False)\n",
    "\n",
    "                print(f\"   [OK] Decoded {count} columns.\")\n",
    "                print(f\"   [SAVED] {filename}\")\n",
    "                success += 1\n",
    "\n",
    "            except FileNotFoundError as e:\n",
    "                print(f\"   [SKIP] Metadata missing: {e}\")\n",
    "            except Exception as e:\n",
    "                print(f\"   [ERROR] {e}\")\n",
    "                errors += 1\n",
    "\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "    print(f\"\\nCOMPLETED. Success: {success} | Errors: {errors}\")\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
