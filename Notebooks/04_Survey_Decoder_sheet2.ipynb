{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b06f3e89",
   "metadata": {},
   "source": [
    "\n",
    "This notebook applies metadata Sheet 2 definitions to decode survey values.  \n",
    "This notebook maps coded responses (e.g., 1, 2, 3) into human‑readable labels (e.g., Employed, Unemployed).\n",
    "\n",
    "Dependencies:\n",
    "- Run `00_Settings.ipynb` and `01_Inventory.ipynb` first.\n",
    "- Requires outputs from `03_Metadata_Decoder.ipynb` (Header Encoded Surveys).\n",
    "- Note: Survey CSVs already carry meaning from Sheet 2 reshaping. This notebook applies the final decoding logic.\n",
    "\n",
    "Output:\n",
    "\n",
    "- Fully decoded survey CSVs saved into **NEW Fully Decoded Surveys**.\n",
    "- Reports per survey showing number of columns successfully decoded.\n",
    "\n",
    "Notes:\n",
    "- **Sheet 1 metadata** → header translation (column names).  \n",
    "- **Sheet 2 metadata** → value translation (coded responses).  \n",
    "\n",
    "**INTENT:** This notebook performs the **final decoding stage** of the Labor Force Survey pipeline.  \n",
    "It applies **Sheet 2 metadata** to translate coded survey values into human‑readable labels.\n",
    "\n",
    "- Next steps: duplicate variable detection, integrity checks, coverage scanning.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68f78362",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load settings from config.json (produced by 00_Settings.ipynb)\n",
    "# ------------------------------------------------------------\n",
    "with open(Path(\"./data/interim/config.json\")) as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "BASE_PATH = Path(cfg[\"BASE_PATH\"])\n",
    "INTERIM_DIR = Path(cfg[\"INTERIM_DIR\"])\n",
    "PROCESSED_DIR = Path(cfg[\"PROCESSED_DIR\"])\n",
    "LOG_DIR = Path(cfg[\"LOG_DIR\"])\n",
    "MONTH_ORDER = cfg[\"MONTH_ORDER\"]\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Load inventory (produced by 01_Inventory.ipynb)\n",
    "# ------------------------------------------------------------\n",
    "with open(Path(INTERIM_DIR) / \"inventory.json\") as f:\n",
    "    inventory = json.load(f)\n",
    "\n",
    "# Alias for compatibility\n",
    "base_path = str(BASE_PATH)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4dcfa81",
   "metadata": {},
   "source": [
    "### Interim Sample "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4684f1c",
   "metadata": {},
   "source": [
    "#### Intent: Interim Sample Decoder\n",
    "\n",
    "This interim function generates a **single sample output** (e.g., `NEW Fully Decoded Survey Sample` for **January 2018**) using the same decoding logic as the batch runner.  \n",
    "\n",
    "Unlike the full batch process, which redirects all decoded surveys to Google Drive, this sample run saves directly into the local **interim repository path**.  \n",
    "\n",
    "The purpose is to provide a quick preview of how a fully decoded CSV looks without requiring you to download the large, heavy files from Google Drive.  \n",
    "\n",
    "Use this when:\n",
    "- You want to validate decoding logic on a small subset before running the full batch.  \n",
    "- You need a lightweight example for documentation, testing, or demonstration.  \n",
    "- You want to inspect decoded values locally without waiting for the complete dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "09d3f68f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import re\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Shared folder names\n",
    "# ------------------------------------------------------------\n",
    "HEADER_ENCODED_FOLDER = \"NEW Header Encoded Surveys\"\n",
    "FULLY_DECODED_FOLDER = \"NEW Fully Decoded Surveys\"\n",
    "FULLY_DECODED_SAMPLE_FOLDER = \"NEW Fully Decoded Survey Sample\"\n",
    "\n",
    "# ------------------------------------------------------------\n",
    "# Month parsing\n",
    "# ------------------------------------------------------------\n",
    "MONTHS = [\n",
    "    \"JANUARY\",\"FEBRUARY\",\"MARCH\",\"APRIL\",\"MAY\",\"JUNE\",\n",
    "    \"JULY\",\"AUGUST\",\"SEPTEMBER\",\"OCTOBER\",\"NOVEMBER\",\"DECEMBER\"\n",
    "]\n",
    "\n",
    "MONTH_PATTERN = re.compile(\n",
    "    r\"(JANUARY|FEBRUARY|MARCH|APRIL|MAY|JUNE|JULY|AUGUST|SEPTEMBER|OCTOBER|NOVEMBER|DECEMBER)\",\n",
    "    re.IGNORECASE\n",
    ")\n",
    "\n",
    "# ============================================================\n",
    "# Metadata loader\n",
    "# ============================================================\n",
    "def load_clean_sheet2(base_path, year, month):\n",
    "    \"\"\"\n",
    "    Load the Clean Sheet 2 Metadata for value decoding.\n",
    "    Official folder: NEW Metadata Sheet 2 CSV's\n",
    "    \"\"\"\n",
    "    path = os.path.join(\n",
    "        base_path,\n",
    "        \"NEW Metadata Sheet 2 CSV's\",\n",
    "        str(year),\n",
    "        f\"Sheet2_{month}_{year}.csv\"\n",
    "    )\n",
    "    if not os.path.exists(path):\n",
    "        raise FileNotFoundError(f\"Metadata not found at: {path}\")\n",
    "    return pd.read_csv(path, dtype=str)\n",
    "\n",
    "# ============================================================\n",
    "# Column matching logic\n",
    "# ============================================================\n",
    "def find_target_column(survey_columns, meta_desc):\n",
    "    \"\"\"\n",
    "    Align metadata descriptions with survey columns.\n",
    "    \"\"\"\n",
    "    if pd.isna(meta_desc):\n",
    "        return None\n",
    "\n",
    "    meta_desc = str(meta_desc).strip()\n",
    "\n",
    "    # Exact match\n",
    "    if meta_desc in survey_columns:\n",
    "        return meta_desc\n",
    "\n",
    "    # Remove metadata prefix (e.g. C06-Status -> Status)\n",
    "    clean_meta = re.sub(r'^C\\d+[\\s\\-_]+', '', meta_desc, flags=re.IGNORECASE).strip()\n",
    "    if clean_meta in survey_columns:\n",
    "        return clean_meta\n",
    "\n",
    "    # Survey column has prefix\n",
    "    for col in survey_columns:\n",
    "        if col.endswith(meta_desc):\n",
    "            prefix = col[:-len(meta_desc)].strip()\n",
    "            if re.search(r'^C\\d+[\\s\\-_]*$', prefix, re.IGNORECASE) or prefix == \"\":\n",
    "                return col\n",
    "\n",
    "    return None\n",
    "\n",
    "# ============================================================\n",
    "# Safe decoder\n",
    "# ============================================================\n",
    "def decode_survey_safe(survey_df, meta_df):\n",
    "    \"\"\"\n",
    "    Decode survey values using metadata Sheet 2.\n",
    "    Uses Variable, Label, min_value, max_value, additional_value.\n",
    "    \"\"\"\n",
    "    unique_vars = meta_df['Variable'].unique()\n",
    "    decoded_count = 0\n",
    "    survey_cols = list(survey_df.columns)\n",
    "\n",
    "    for var_code in unique_vars:\n",
    "        subset = meta_df[meta_df['Variable'] == var_code].copy()\n",
    "        if subset['Description'].isnull().all():\n",
    "            continue\n",
    "\n",
    "        raw_desc = subset['Description'].dropna().iloc[0].strip()\n",
    "        target_col = find_target_column(survey_cols, raw_desc)\n",
    "        if not target_col:\n",
    "            continue\n",
    "\n",
    "        lookup = {}\n",
    "        for _, row in subset.iterrows():\n",
    "            label = str(row['Label']).strip()\n",
    "            if label in ['0', '0.0', 'nan', 'NaN', '']:\n",
    "                continue\n",
    "\n",
    "            # Collect codes\n",
    "            codes = []\n",
    "            for field in ['min_value', 'max_value', 'additional_value']:\n",
    "                val = str(row.get(field, '')).strip()\n",
    "                if val and val not in ['0', 'nan', 'NaN']:\n",
    "                    codes.append(val)\n",
    "\n",
    "            # Build mapping\n",
    "            for code in codes:\n",
    "                try:\n",
    "                    lookup[int(float(code))] = label\n",
    "                except:\n",
    "                    lookup[code] = label  # fallback for non-numeric codes\n",
    "\n",
    "        if not lookup:\n",
    "            continue\n",
    "\n",
    "        def safe_map(val):\n",
    "            try:\n",
    "                return lookup.get(int(float(val)), val)\n",
    "            except:\n",
    "                return lookup.get(str(val), val)\n",
    "\n",
    "        survey_df[target_col] = survey_df[target_col].apply(safe_map)\n",
    "        decoded_count += 1\n",
    "\n",
    "    return survey_df, decoded_count\n",
    "\n",
    "# ============================================================\n",
    "# INTERIM SAMPLE DECODER\n",
    "# ============================================================\n",
    "def run_sample_decoding(base_path, year=\"2018\", month=\"January\", interim_root=None):\n",
    "    \"\"\"\n",
    "    Decode a single survey file for demonstration purposes.\n",
    "    Output is GitHub-safe (small sample only).\n",
    "    \"\"\"\n",
    "    if interim_root is None:\n",
    "        interim_root = os.path.join(base_path, \"data\", \"interim\")\n",
    "\n",
    "    month = month.strip().capitalize()\n",
    "    if month.upper() not in MONTHS:\n",
    "        raise ValueError(f\"Invalid month: {month}\")\n",
    "\n",
    "    input_root = os.path.join(base_path, HEADER_ENCODED_FOLDER, year)\n",
    "    output_root = os.path.join(interim_root, FULLY_DECODED_SAMPLE_FOLDER, year)\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    if not os.path.exists(input_root):\n",
    "        print(f\"[SKIP] Input folder not found: {input_root}\")\n",
    "        return\n",
    "\n",
    "    files = [f for f in os.listdir(input_root) if f.lower().endswith(\".csv\")]\n",
    "    target_file = next((f for f in files if month.upper() in f.upper()), None)\n",
    "\n",
    "    if not target_file:\n",
    "        print(f\"[SKIP] No survey file found for {month} {year}\")\n",
    "        return\n",
    "\n",
    "    print(\"================================================\")\n",
    "    print(f\"SAMPLE DECODING: {month.upper()} {year}\")\n",
    "    print(f\"Source: {input_root}\")\n",
    "    print(f\"Dest:   {output_root}\")\n",
    "    print(\"================================================\\n\")\n",
    "\n",
    "    df_survey = pd.read_csv(os.path.join(input_root, target_file), low_memory=False)\n",
    "    df_meta = load_clean_sheet2(base_path, year, month)\n",
    "\n",
    "    df_final, count = decode_survey_safe(df_survey, df_meta)\n",
    "\n",
    "    save_path = os.path.join(output_root, target_file)\n",
    "    df_final.to_csv(save_path, index=False)\n",
    "\n",
    "    print(f\"[OK] Decoded {count} columns\")\n",
    "    print(f\"[SAVED] {save_path}\")\n",
    "\n",
    "# ============================================================\n",
    "# FULL BATCH DECODER\n",
    "# ============================================================\n",
    "def run_batch_decoding(base_path):\n",
    "    \"\"\"\n",
    "    Decode all survey files using Sheet 2 metadata.\n",
    "    Intended for local execution only.\n",
    "    \"\"\"\n",
    "    input_root = os.path.join(base_path, HEADER_ENCODED_FOLDER)\n",
    "    output_root = os.path.join(base_path, FULLY_DECODED_FOLDER)\n",
    "    os.makedirs(output_root, exist_ok=True)\n",
    "\n",
    "    print(\"================================================\")\n",
    "    print(\"STARTING FULL BATCH DECODING\")\n",
    "    print(f\"Source: {input_root}\")\n",
    "    print(f\"Dest:   {output_root}\")\n",
    "    print(\"================================================\\n\")\n",
    "\n",
    "    if not os.path.exists(input_root):\n",
    "        print(f\"[ERROR] Input folder not found: {input_root}\")\n",
    "        return\n",
    "\n",
    "    success, errors = 0, 0\n",
    "\n",
    "    year_folders = [\n",
    "        f for f in os.listdir(input_root)\n",
    "        if f.isdigit() and os.path.isdir(os.path.join(input_root, f))\n",
    "    ]\n",
    "\n",
    "    for year in sorted(year_folders):\n",
    "        year_in = os.path.join(input_root, year)\n",
    "        year_out = os.path.join(output_root, year)\n",
    "        os.makedirs(year_out, exist_ok=True)\n",
    "\n",
    "        files = [f for f in os.listdir(year_in) if f.lower().endswith(\".csv\")]\n",
    "        for filename in files:\n",
    "            match = MONTH_PATTERN.search(filename)\n",
    "            if not match:\n",
    "                continue\n",
    "\n",
    "            month = match.group(1).capitalize()\n",
    "            print(f\"Processing: {month.upper()} {year}...\")\n",
    "\n",
    "            try:\n",
    "                df_survey = pd.read_csv(os.path.join(year_in, filename), low_memory=False)\n",
    "                df_meta = load_clean_sheet2(base_path, year, month)\n",
    "                df_final, count = decode_survey_safe(df_survey, df_meta)\n",
    "\n",
    "                save_path = os.path.join(year_out, filename)\n",
    "                df_final.to_csv(save_path, index=False)\n",
    "\n",
    "                print(f\"[OK] Decoded {count} columns\")\n",
    "                success += 1\n",
    "\n",
    "            except Exception as e:\n",
    "                print(f\"[ERROR] {e}\")\n",
    "                errors += 1\n",
    "\n",
    "            print(\"-\" * 40)\n",
    "\n",
    "    print(f\"\\nCOMPLETED | Success: {success} | Errors: {errors}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eb106188",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==============================================\n",
      "SURVEY VALUE DECODING OPTIONS\n",
      "==============================================\n",
      "1. run_sample()      → Small GitHub-safe sample\n",
      "2. run_full_batch() → Full local decoding\n",
      "==============================================\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# ============================================================\n",
    "# PIPELINE ENTRY POINT\n",
    "# ============================================================\n",
    "\n",
    "def show_decoding_options():\n",
    "    print(\"==============================================\")\n",
    "    print(\"SURVEY VALUE DECODING OPTIONS\")\n",
    "    print(\"==============================================\")\n",
    "    print(\"1. run_sample()      → Small GitHub-safe sample\")\n",
    "    print(\"2. run_full_batch() → Full local decoding\")\n",
    "    print(\"==============================================\\n\")\n",
    "\n",
    "\n",
    "def run_sample():\n",
    "    run_sample_decoding(\n",
    "        base_path=BASE_PATH,\n",
    "        year=\"2018\",\n",
    "        month=\"January\"\n",
    "    )\n",
    "\n",
    "\n",
    "def run_full_batch():\n",
    "    run_batch_decoding(base_path=BASE_PATH)\n",
    "\n",
    "\n",
    "show_decoding_options()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4934e52a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "SAMPLE DECODING: JANUARY 2018\n",
      "Source: G:\\.shortcut-targets-by-id\\1VctTphaltRx4xcPxmTJlRTrxLalyuEt8\\Labor Force Survey\\NEW Header Encoded Surveys\\2018\n",
      "Dest:   G:\\.shortcut-targets-by-id\\1VctTphaltRx4xcPxmTJlRTrxLalyuEt8\\Labor Force Survey\\data\\interim\\NEW Fully Decoded Survey Sample\\2018\n",
      "================================================\n",
      "\n",
      "[OK] Decoded 39 columns\n",
      "[SAVED] G:\\.shortcut-targets-by-id\\1VctTphaltRx4xcPxmTJlRTrxLalyuEt8\\Labor Force Survey\\data\\interim\\NEW Fully Decoded Survey Sample\\2018\\JANUARY_2018.CSV\n"
     ]
    }
   ],
   "source": [
    "run_sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "93712b1f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================\n",
      "STARTING FULL BATCH DECODING\n",
      "Source: G:\\.shortcut-targets-by-id\\1VctTphaltRx4xcPxmTJlRTrxLalyuEt8\\Labor Force Survey\\NEW Header Encoded Surveys\n",
      "Dest:   G:\\.shortcut-targets-by-id\\1VctTphaltRx4xcPxmTJlRTrxLalyuEt8\\Labor Force Survey\\NEW Fully Decoded Surveys\n",
      "================================================\n",
      "\n",
      "Processing: APRIL 2018...\n",
      "[OK] Decoded 37 columns\n",
      "----------------------------------------\n",
      "Processing: JULY 2018...\n",
      "[OK] Decoded 37 columns\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2018...\n",
      "[OK] Decoded 39 columns\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2018...\n",
      "[OK] Decoded 39 columns\n",
      "----------------------------------------\n",
      "Processing: APRIL 2019...\n",
      "[OK] Decoded 39 columns\n",
      "----------------------------------------\n",
      "Processing: JULY 2019...\n",
      "[OK] Decoded 41 columns\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2019...\n",
      "[OK] Decoded 41 columns\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2019...\n",
      "[OK] Decoded 38 columns\n",
      "----------------------------------------\n",
      "Processing: JULY 2022...\n",
      "[OK] Decoded 44 columns\n",
      "----------------------------------------\n",
      "Processing: JUNE 2022...\n",
      "[OK] Decoded 32 columns\n",
      "----------------------------------------\n",
      "Processing: APRIL 2022...\n",
      "[OK] Decoded 44 columns\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2022...\n",
      "[OK] Decoded 32 columns\n",
      "----------------------------------------\n",
      "Processing: DECEMBER 2022...\n",
      "[OK] Decoded 32 columns\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2022...\n",
      "[OK] Decoded 31 columns\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2022...\n",
      "[OK] Decoded 44 columns\n",
      "----------------------------------------\n",
      "Processing: MARCH 2022...\n",
      "[OK] Decoded 31 columns\n",
      "----------------------------------------\n",
      "Processing: MAY 2022...\n",
      "[OK] Decoded 32 columns\n",
      "----------------------------------------\n",
      "Processing: NOVEMBER 2022...\n",
      "[OK] Decoded 32 columns\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2022...\n",
      "[OK] Decoded 44 columns\n",
      "----------------------------------------\n",
      "Processing: SEPTEMBER 2022...\n",
      "[OK] Decoded 33 columns\n",
      "----------------------------------------\n",
      "Processing: APRIL 2023...\n",
      "[OK] Decoded 44 columns\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2023...\n",
      "[OK] Decoded 33 columns\n",
      "----------------------------------------\n",
      "Processing: DECEMBER 2023...\n",
      "[OK] Decoded 32 columns\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2023...\n",
      "[OK] Decoded 33 columns\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2023...\n",
      "[OK] Decoded 44 columns\n",
      "----------------------------------------\n",
      "Processing: JULY 2023...\n",
      "[OK] Decoded 45 columns\n",
      "----------------------------------------\n",
      "Processing: JUNE 2023...\n",
      "[OK] Decoded 33 columns\n",
      "----------------------------------------\n",
      "Processing: MARCH 2023...\n",
      "[OK] Decoded 32 columns\n",
      "----------------------------------------\n",
      "Processing: NOVEMBER 2023...\n",
      "[OK] Decoded 32 columns\n",
      "----------------------------------------\n",
      "Processing: OCTOBER 2023...\n",
      "[OK] Decoded 44 columns\n",
      "----------------------------------------\n",
      "Processing: SEPTEMBER 2023...\n",
      "[OK] Decoded 32 columns\n",
      "----------------------------------------\n",
      "Processing: MAY 2023...\n",
      "[OK] Decoded 33 columns\n",
      "----------------------------------------\n",
      "Processing: FEBRUARY 2024...\n",
      "[OK] Decoded 32 columns\n",
      "----------------------------------------\n",
      "Processing: APRIL 2024...\n",
      "[OK] Decoded 43 columns\n",
      "----------------------------------------\n",
      "Processing: JANUARY 2024...\n",
      "[OK] Decoded 44 columns\n",
      "----------------------------------------\n",
      "Processing: AUGUST 2024...\n",
      "[OK] Decoded 31 columns\n",
      "----------------------------------------\n",
      "Processing: JULY 2024...\n",
      "[OK] Decoded 43 columns\n",
      "----------------------------------------\n",
      "Processing: MARCH 2024...\n",
      "[OK] Decoded 32 columns\n",
      "----------------------------------------\n",
      "Processing: MAY 2024...\n",
      "[OK] Decoded 33 columns\n",
      "----------------------------------------\n",
      "Processing: JUNE 2024...\n",
      "[OK] Decoded 32 columns\n",
      "----------------------------------------\n",
      "\n",
      "COMPLETED | Success: 40 | Errors: 0\n"
     ]
    }
   ],
   "source": [
    "run_full_batch()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
