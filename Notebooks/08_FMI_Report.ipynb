{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f1f41254",
   "metadata": {},
   "source": [
    "### Fraction of Missing Information (FMI) Analysis\n",
    "\n",
    "This notebook computes the **Fraction of Missing Information (FMI)** for all renamed and validated survey files. It quantifies missingness at the variable level across survey months and provides guidance for imputation and variable selection.\n",
    "\n",
    "The workflow builds on the outputs of previous preprocessing stages, particularly the variable consistency and harmonization audit, and serves as the final diagnostic step before imputation.\n",
    "\n",
    "---\n",
    "\n",
    "#### Overview of the Workflow\n",
    "\n",
    "The FMI process is structured into four main stages:\n",
    "\n",
    "1. **Configuration and Data Loading**  \n",
    "   Paths and parameters are dynamically loaded from `config.json`, ensuring reproducibility and eliminating hardcoded directories. Survey files are accessed using the inventory and consistency outputs from earlier notebooks.\n",
    "\n",
    "2. **Missingness Detection and FMI Computation**  \n",
    "   A unified missingness detector identifies absent values using:\n",
    "   - Standard nulls and empty strings  \n",
    "   - Text-based missing markers (e.g., \"NA\", \"-\", \"N/A\")   \n",
    "\n",
    "   For each variable and survey month, FMI is computed and classified into interpretive levels (Low, Moderate, High, Critical), with corresponding analytical recommendations.\n",
    "\n",
    "3. **Consolidation and Cross-Month Aggregation**  \n",
    "   Monthly FMI reports are combined into a consolidated profile that summarizes missingness patterns across all survey waves. Variables are aligned with their consistency tags to contextualize missingness within structural stability.\n",
    "\n",
    "4. **Integration with Stability and Harmonization Decisions**  \n",
    "   FMI results are merged with the structural stability report from Notebook 07. Only variables that passed the consistency and harmonization audit are retained in the final FMI profile, ensuring that missingness analysis is performed on conceptually stable and comparable variables.\n",
    "\n",
    "---\n",
    "\n",
    "#### Inputs\n",
    "\n",
    "- `config.json` – centralized path and parameter configuration  \n",
    "- Renamed and harmonized survey files (`FINAL Consistent Surveys`)  \n",
    "- `consistency_profile.csv` – initial variable presence/consistency tags  \n",
    "- `structural_stability_report.csv` – final retain/drop decisions and harmonizations from Notebook 07  \n",
    "\n",
    "---\n",
    "\n",
    "#### Outputs\n",
    "\n",
    "- **Monthly FMI reports**  \n",
    "\n",
    "- **Consolidated FMI profiles**  \n",
    "  - `fmi_profile_all.csv` – FMI statistics for all variables  \n",
    "  - `fmi_profile_consistent.csv` – FMI statistics for retained, harmonized, and consistent variables (temporally and value consistent) \n",
    "\n",
    "- **Log file**  \n",
    "  Detailed execution log stored in `LOG_DIR`\n",
    "\n",
    "---\n",
    "\n",
    "#### Key Contributions of This Notebook\n",
    "\n",
    "- Automatically computes FMI without using fixed (hardcoded) file paths.  \n",
    "- Detects missing values using both text-based and numeric rules.  \n",
    "- Aligns variables so they are comparable across all survey months.  \n",
    "- Combines the results of variable consistency and harmonization checks with the FMI analysis.  \n",
    "- Distinguishes between initial FMI exploration and the final set of variables used for analysis.\n",
    "\n",
    "This notebook ensures that missingness is analyzed only on variables that are consistent and properly harmonized across survey waves, making the results reliable for imputation and further analysis."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1576c7d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Cleaning existing FMI folder: H:\\.shortcut-targets-by-id\\1VctTphaltRx4xcPxmTJlRTrxLalyuEt8\\Labor Force Survey\\NEW FMI Reports\n",
      " Fresh folder created: H:\\.shortcut-targets-by-id\\1VctTphaltRx4xcPxmTJlRTrxLalyuEt8\\Labor Force Survey\\NEW FMI Reports\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "from pathlib import Path\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import shutil\n",
    "from datetime import datetime\n",
    "\n",
    "# --- Load config ---\n",
    "with open(Path(\"./data/interim/config.json\")) as f:\n",
    "    cfg = json.load(f)\n",
    "\n",
    "BASE_PATH = Path(cfg[\"BASE_PATH\"])\n",
    "LOG_DIR = Path(cfg[\"LOG_DIR\"])\n",
    "MONTH_ORDER = cfg[\"MONTH_ORDER\"]\n",
    "\n",
    "# --- Paths ---\n",
    "# UPDATED: We now point to the Consistent Surveys from Notebook 7\n",
    "CONSISTENT_ROOT = BASE_PATH / \"FINAL Consistent Surveys\"\n",
    "CONSISTENCY_ROOT = BASE_PATH / \"NEW Variable Consistency Check\"\n",
    "FMI_MONTHLY_ROOT = BASE_PATH / \"NEW FMI Reports\"\n",
    "\n",
    "# --- IDEMPOTENT CLEANUP LOGIC ---\n",
    "if FMI_MONTHLY_ROOT.exists():\n",
    "    print(f\" Cleaning existing FMI folder: {FMI_MONTHLY_ROOT}\")\n",
    "    shutil.rmtree(FMI_MONTHLY_ROOT)\n",
    "\n",
    "os.makedirs(FMI_MONTHLY_ROOT, exist_ok=True)\n",
    "print(f\" Fresh folder created: {FMI_MONTHLY_ROOT}\")\n",
    "\n",
    "# --- Load consistency profile ---\n",
    "consistency_profile_path = CONSISTENCY_ROOT / \"consistency_profile.csv\"\n",
    "if consistency_profile_path.exists():\n",
    "    consistency_df = pd.read_csv(consistency_profile_path)\n",
    "    consistency_tags = dict(zip(consistency_df[\"Variable\"], consistency_df[\"ConsistencyTag\"]))\n",
    "else:\n",
    "    print(\" Warning: consistency_profile.csv not found. Tags will be 'unknown'.\")\n",
    "    consistency_tags = {}\n",
    "\n",
    "# --- Missingness detector (REFINED) ---\n",
    "TEXT_MISSING = {\"\", \" \", \"NA\", \"N/A\", \"NaN\", \"nan\", \".\", \"-\", \"_\"}\n",
    "\n",
    "def build_missing_mask(series: pd.Series) -> pd.Series:\n",
    "    \"\"\"Identifies missingness based on blanks and explicit text markers.\"\"\"\n",
    "    s = series.astype(str).str.strip()\n",
    "    mask = series.isna() | (s == \"\") | s.isin(TEXT_MISSING)\n",
    "    return mask"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "6ab123c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] APRIL_2018.CSV scanned.\n",
      "[OK] JANUARY_2018.CSV scanned.\n",
      "[OK] JULY_2018.CSV scanned.\n",
      "[OK] OCTOBER_2018.CSV scanned.\n",
      "[OK] JULY_2019.CSV scanned.\n",
      "[OK] APRIL_2019.CSV scanned.\n",
      "[OK] JANUARY_2019.CSV scanned.\n",
      "[OK] OCTOBER_2019.CSV scanned.\n",
      "[OK] NOVEMBER_2022.CSV scanned.\n",
      "[OK] FEBRUARY_2022.csv scanned.\n",
      "[OK] MARCH_2022.csv scanned.\n",
      "[OK] MAY_2022.csv scanned.\n",
      "[OK] JANUARY_2022.csv scanned.\n",
      "[OK] APRIL_2022.csv scanned.\n",
      "[OK] OCTOBER_2022.CSV scanned.\n",
      "[OK] AUGUST_2022.CSV scanned.\n",
      "[OK] DECEMBER_2022.CSV scanned.\n",
      "[OK] SEPTEMBER_2022.CSV scanned.\n",
      "[OK] JUNE_2022.csv scanned.\n",
      "[OK] JULY_2022.CSV scanned.\n",
      "[OK] JUNE_2023.CSV scanned.\n",
      "[OK] NOVEMBER_2023.CSV scanned.\n",
      "[OK] MARCH_2023.CSV scanned.\n",
      "[OK] AUGUST_2023.CSV scanned.\n",
      "[OK] FEBRUARY_2023.CSV scanned.\n",
      "[OK] DECEMBER_2023.CSV scanned.\n",
      "[OK] JULY_2023.CSV scanned.\n",
      "[OK] JANUARY_2023.CSV scanned.\n",
      "[OK] OCTOBER_2023.CSV scanned.\n",
      "[OK] MAY_2023.CSV scanned.\n",
      "[OK] SEPTEMBER_2023.CSV scanned.\n",
      "[OK] APRIL_2023.CSV scanned.\n",
      "[OK] JANUARY_2024.CSV scanned.\n",
      "[OK] APRIL_2024.CSV scanned.\n",
      "[OK] JULY_2024.CSV scanned.\n",
      "[OK] JUNE_2024.CSV scanned.\n",
      "[OK] AUGUST_2024.CSV scanned.\n",
      "[OK] MARCH_2024.CSV scanned.\n",
      "[OK] FEBRUARY_2024.CSV scanned.\n",
      "[OK] MAY_2024.CSV scanned.\n",
      "\n",
      "COMPLETED. Success: 40 | Errors: 0\n"
     ]
    }
   ],
   "source": [
    "def fmi_scan_csv(file_path: Path, year: str, month: str) -> pd.DataFrame:\n",
    "    df = pd.read_csv(file_path, low_memory=False)\n",
    "    rows = []\n",
    "    for col in df.columns:\n",
    "        miss_mask = build_missing_mask(df[col])\n",
    "        missing = int(miss_mask.sum())\n",
    "        total = int(len(df[col]))\n",
    "        fmi = (missing / total) if total > 0 else 0.0\n",
    "\n",
    "        if fmi < 0.05:\n",
    "            flag, rec = \"Low\", \"Keep\"\n",
    "        elif fmi < 0.20:\n",
    "            flag, rec = \"Moderate\", \"Consider imputation\"\n",
    "        elif fmi < 0.40: \n",
    "            flag, rec = \"High\", \"Validate for Structural Logic\"\n",
    "        else:\n",
    "            flag, rec = \"Critical\", \"Assess Logic or Drop\"\n",
    "\n",
    "        rows.append({\n",
    "            \"Year\": year,\n",
    "            \"Month\": month,\n",
    "            \"Variable\": col.strip(),\n",
    "            \"Missing\": missing,\n",
    "            \"Total\": total,\n",
    "            \"FMI\": round(fmi, 6),\n",
    "            \"Flag\": flag,\n",
    "            \"Recommendation\": rec,\n",
    "            \"ConsistencyTag\": consistency_tags.get(col.strip(), \"unknown\"),\n",
    "        })\n",
    "    return pd.DataFrame(rows)\n",
    "\n",
    "# --- Batch runner ---\n",
    "log_file = LOG_DIR / f\"fmi_report_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log\"\n",
    "success_count, error_count = 0, 0\n",
    "all_reports = []\n",
    "\n",
    "with open(log_file, \"w\", encoding=\"utf-8\") as log:\n",
    "    log.write(\"STARTING FMI REPORT ON CONSISTENT SURVEYS\\n\")\n",
    "    log.write(f\"Source: {CONSISTENT_ROOT}\\n\")\n",
    "    log.write(\"===============================================\\n\\n\")\n",
    "\n",
    "    # Use CONSISTENT_ROOT for the loop\n",
    "    for year in sorted([d for d in os.listdir(CONSISTENT_ROOT) if (CONSISTENT_ROOT / d).is_dir()]):\n",
    "        year_folder = CONSISTENT_ROOT / year\n",
    "        year_out = FMI_MONTHLY_ROOT / year\n",
    "        os.makedirs(year_out, exist_ok=True)\n",
    "\n",
    "        for file in os.listdir(year_folder):\n",
    "            if not file.lower().endswith(\".csv\"):\n",
    "                continue\n",
    "\n",
    "            # Handles both \"January_2018.csv\" and \"January 2018.csv\"\n",
    "            month = file.split(\"_\")[0].split(\" \")[0].capitalize()\n",
    "            file_path = year_folder / file\n",
    "\n",
    "            try:\n",
    "                report = fmi_scan_csv(file_path, year, month)\n",
    "                out_file = year_out / f\"FMI_{month}_{year}.csv\"\n",
    "                report.to_csv(out_file, index=False)\n",
    "                all_reports.append(report)\n",
    "\n",
    "                success_count += 1\n",
    "                msg = f\"[OK] {file} scanned.\"\n",
    "                print(msg); log.write(msg + \"\\n\")\n",
    "            except Exception as e:\n",
    "                error_count += 1\n",
    "                msg = f\"[ERROR] {file} -> {e}\"\n",
    "                print(msg); log.write(msg + \"\\n\")\n",
    "\n",
    "    summary_msg = f\"COMPLETED. Success: {success_count} | Errors: {error_count}\"\n",
    "    print(\"\\n\" + summary_msg); log.write(\"\\n\" + summary_msg + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "460305d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[OK] FMI Audit (All Variables) saved to: H:\\.shortcut-targets-by-id\\1VctTphaltRx4xcPxmTJlRTrxLalyuEt8\\Labor Force Survey\\NEW FMI Reports\\fmi_profile_all.csv\n",
      "Total variables audited: 76\n"
     ]
    }
   ],
   "source": [
    "# --- Consolidate in-memory reports ---\n",
    "if all_reports:\n",
    "    combined = pd.concat(all_reports, ignore_index=True)\n",
    "\n",
    "    FMI_summary = (\n",
    "        combined.groupby([\"Variable\", \"ConsistencyTag\"])\n",
    "        .agg(\n",
    "            TotalMissing=(\"Missing\", \"sum\"),\n",
    "            TotalRows=(\"Total\", \"sum\"),\n",
    "            AvgFMI=(\"FMI\", \"mean\"),\n",
    "            MonthsObserved=(\"Year\", \"count\"),\n",
    "        )\n",
    "        .reset_index()\n",
    "    )\n",
    "\n",
    "    FMI_summary[\"OverallFMI\"] = FMI_summary[\"TotalMissing\"] / FMI_summary[\"TotalRows\"]\n",
    "\n",
    "    def flag_and_rec_summary(fmi):\n",
    "        if fmi < 0.05: return \"Low\", \"Keep\"\n",
    "        elif fmi < 0.20: return \"Moderate\", \"Impute/Keep\"\n",
    "        elif fmi < 0.40: return \"High\", \"Structural Skip - Logical Imputation\"\n",
    "        else: return \"Critical\", \"Validate/Drop\"\n",
    "\n",
    "    FMI_summary[[\"Flag\", \"Recommendation\"]] = FMI_summary[\"OverallFMI\"].apply(\n",
    "        lambda x: pd.Series(flag_and_rec_summary(x))\n",
    "    )\n",
    "\n",
    "    all_out_primary = FMI_MONTHLY_ROOT / \"fmi_profile_all.csv\"\n",
    "    FMI_summary.to_csv(all_out_primary, index=False)\n",
    "\n",
    "    # Cleaned printout to match your preference\n",
    "    print(f\"[OK] FMI Audit (All Variables) saved to: {all_out_primary}\")\n",
    "    print(f\"Total variables audited: {len(FMI_summary)}\")\n",
    "    \n",
    "else:\n",
    "    print(\"[ERROR] No reports were generated.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "19713b61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Consistent Variable Set Generated: fmi_profile_consistent.csv\n",
      "Total variables ready for Notebook 09: 20\n"
     ]
    }
   ],
   "source": [
    "# --- Create Consistent (Retained) Profile ---\n",
    "fmi_all = pd.read_csv(FMI_MONTHLY_ROOT / \"fmi_profile_all.csv\")\n",
    "stability_report_path = CONSISTENCY_ROOT / \"structural_stability_report.csv\"\n",
    "\n",
    "if stability_report_path.exists():\n",
    "    stability_df = pd.read_csv(stability_report_path)\n",
    "\n",
    "    fmi_merged = pd.merge(\n",
    "        fmi_all,\n",
    "        stability_df[['Variable', 'Decision']],\n",
    "        on=\"Variable\",\n",
    "        how=\"left\"\n",
    "    )\n",
    "\n",
    "    # Filter only for variables intended for the final analysis\n",
    "    fmi_consistent = fmi_merged[fmi_merged[\"Decision\"] == \"Retain\"].copy()\n",
    "    fmi_consistent = fmi_consistent.drop(columns=[\"Decision\"])\n",
    "\n",
    "    consistent_out = FMI_MONTHLY_ROOT / \"fmi_profile_consistent.csv\"\n",
    "    fmi_consistent.to_csv(consistent_out, index=False)\n",
    "\n",
    "    print(f\" Consistent Variable Set Generated: {consistent_out.name}\")\n",
    "    print(f\"Total variables ready for Notebook 09: {len(fmi_consistent)}\")\n",
    "else:\n",
    "    print(\" Error: structural_stability_report.csv not found in Consistency Root.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55053cae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "====================================================================================================\n",
      " HARMONIZATION VALIDATION: MISSINGNESS COMPARISON (20 Variables)\n",
      "====================================================================================================\n",
      " Scanning 'NEW Renamed Fully Decoded Surveys' folder (Previous Folder)...\n",
      " Scanning 'FINAL Consistent Surveys' folder (New Folder)...\n",
      "\n",
      "VARIABLE                                 | Previous Folder (%) | New Folder (%)  | STATUS\n",
      "----------------------------------------------------------------------------------------------------\n",
      "Available for Work                       |     96.23% |     96.23% | Stable\n",
      "C03-Relationship to Household Head       |      0.00% |      0.00% | Stable\n",
      "C04-Sex                                  |      0.00% |      0.00% | Stable\n",
      "C05-Age as of Last Birthday              |      0.00% |      0.00% | Stable\n",
      "C06-Marital Status                       |      7.23% |      7.23% | Stable\n",
      "C101-Line Number                         |      0.00% |      0.00% | Stable\n",
      "Household Size                           |      0.00% |      0.00% | Stable\n",
      "Look for Additional Work                 |     58.44% |     58.44% | Stable\n",
      "Looked for Work or Tried to Establish Business During the Past Week |     70.98% |     70.98% | Stable\n",
      "New Employment Criteria (jul 05, 2005)   |     29.42% |     29.42% | Stable\n",
      "Normal Working Hours per Day             |     58.44% |     58.44% | Stable\n",
      "Other Job Indicator                      |     58.40% |     58.40% | Stable\n",
      "Previous Job Indicator                   |     70.98% |     70.98% | Stable\n",
      "Psu Number                               |      0.00% |      0.00% | Stable\n",
      "Replicate                                |      0.00% |      0.00% | Stable\n",
      "Survey Month                             |      0.00% |      0.00% | Stable\n",
      "Survey Year                              |      0.00% |      0.00% | Stable\n",
      "Total Hours Worked for all Jobs          |     58.40% |     58.40% | Stable\n",
      "Want More Hours of Work                  |     58.44% |     58.44% | Stable\n",
      "Work Indicator                           |      8.80% |      8.80% | Stable\n",
      "\n",
      "====================================================================================================\n",
      " SUMMARY: 'Stable' indicates the harmonization preserved the original data structure.\n",
      "====================================================================================================\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# --- Configuration ---\n",
    "RENAMED_ROOT = BASE_PATH / \"NEW Renamed Fully Decoded Surveys\"\n",
    "CONSISTENT_ROOT = BASE_PATH / \"FINAL Consistent Surveys\"\n",
    "FMI_CONSISTENT_PATH = FMI_MONTHLY_ROOT / \"fmi_profile_consistent.csv\"\n",
    "\n",
    "def run_harmonization_comparison():\n",
    "    if not FMI_CONSISTENT_PATH.exists():\n",
    "        print(\"Error: Please run Code Block 4 first to generate the consistent variable list.\")\n",
    "        return\n",
    "\n",
    "    # 1. Get the list of the 20 consistent variables\n",
    "    fmi_cons = pd.read_csv(FMI_CONSISTENT_PATH)\n",
    "    target_vars = fmi_cons[\"Variable\"].tolist()\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(f\" HARMONIZATION VALIDATION: MISSINGNESS COMPARISON ({len(target_vars)} Variables)\")\n",
    "    print(\"=\"*100)\n",
    "    \n",
    "    results = []\n",
    "\n",
    "    def get_folder_missingness(root_path, vars_list):\n",
    "        \"\"\"Calculates total missingness for specific variables across a directory.\"\"\"\n",
    "        counts = {var: {\"missing\": 0, \"total\": 0} for var in vars_list}\n",
    "        for file_path in root_path.rglob(\"*.csv\"):\n",
    "            try:\n",
    "                # Only load columns that actually exist in the file to prevent errors\n",
    "                available = pd.read_csv(file_path, nrows=0).columns.tolist()\n",
    "                valid_cols = [v for v in vars_list if v in available]\n",
    "                \n",
    "                if valid_cols:\n",
    "                    df = pd.read_csv(file_path, usecols=valid_cols, dtype=str)\n",
    "                    for var in valid_cols:\n",
    "                        mask = build_missing_mask(df[var])\n",
    "                        counts[var][\"missing\"] += int(mask.sum())\n",
    "                        counts[var][\"total\"] += int(len(df))\n",
    "            except Exception:\n",
    "                continue\n",
    "        return counts\n",
    "\n",
    "    # 2. Run scan for both directories\n",
    "    print(\" Scanning 'NEW Renamed \" \\\n",
    "    \" Surveys' folder (Previous Folder)...\")\n",
    "    before_stats = get_folder_missingness(RENAMED_ROOT, target_vars)\n",
    "    \n",
    "    print(\" Scanning 'FINAL Consistent Surveys' folder (New Folder)...\")\n",
    "    after_stats = get_folder_missingness(CONSISTENT_ROOT, target_vars)\n",
    "\n",
    "    # 3. Format Comparison Table\n",
    "    print(f\"\\n{'VARIABLE':<40} | {'Previous Folder (%)':<15} | {'New Folder (%)':<15} | {'STATUS'}\")\n",
    "    print(\"-\" * 100)\n",
    "\n",
    "    for var in sorted(target_vars):\n",
    "        b_pct = (before_stats[var]['missing'] / before_stats[var]['total'] * 100) if before_stats[var]['total'] > 0 else 100.0\n",
    "        a_pct = (after_stats[var]['missing'] / after_stats[var]['total'] * 100) if after_stats[var]['total'] > 0 else 100.0\n",
    "        \n",
    "        # Status check: After should be <= Before (unless we intentionally preserved NaNs)\n",
    "        diff = a_pct - b_pct\n",
    "        if abs(diff) < 0.001:\n",
    "            status = \"Stable\"\n",
    "        elif diff < 0:\n",
    "            status = \"Improved\"\n",
    "        else:\n",
    "            status = \"Increased Gap\"\n",
    "\n",
    "        print(f\"{var:<40} | {b_pct:>9.2f}% | {a_pct:>9.2f}% | {status}\")\n",
    "\n",
    "    print(\"\\n\" + \"=\"*100)\n",
    "    print(\" SUMMARY: 'Stable' indicates the harmonization preserved the original data structure.\")\n",
    "    print(\"=\"*100)\n",
    "\n",
    "# Run the comparison\n",
    "run_harmonization_comparison()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
